{
 "cells": [
  {
   "cell_type": "code",
<<<<<<< HEAD
   "execution_count": 241,
   "metadata": {},
   "outputs": [],
   "source": [
    "# General imports\n",
=======
   "execution_count": 121,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
>>>>>>> 5be6589eb73edd4cf96d0baea41a7ddc63f0aa24
    "from multiprocessing import Pool\n",
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
<<<<<<< HEAD
    "import matplotlib.pyplot as plt\n",
    "from tqdm import tqdm\n",
    "import math\n",
    "import scipy.io\n",
    "\n",
    "# Image processing imports\n",
    "import cv2\n",
    "import imutils\n",
    "from imutils import face_utils\n",
    "import dlib\n",
    "\n",
    "# NN imports\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from keras.layers import Activation, Dropout, Flatten, Conv2D, MaxPooling2D, RNN"
=======
    "import matplotlib.pyplot as plt"
>>>>>>> 5be6589eb73edd4cf96d0baea41a7ddc63f0aa24
   ]
  },
  {
   "cell_type": "code",
<<<<<<< HEAD
   "execution_count": 213,
=======
   "execution_count": 163,
>>>>>>> 5be6589eb73edd4cf96d0baea41a7ddc63f0aa24
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
<<<<<<< HEAD
    "'''\n",
    "This function opens up the master lookup table and cleans the data (removing NaNs, Nones; Splitting into lists)\n",
    "'''\n",
=======
>>>>>>> 5be6589eb73edd4cf96d0baea41a7ddc63f0aa24
    "def open_data(path):\n",
    "    df1 = open(os.path.join(path), \"r\")  \n",
    "    _list = df1.readlines()\n",
    "    data = []\n",
    "    for i in range(len(_list)):\n",
    "        data.append(_list[i].split('\\t'))\n",
    "    df = pd.DataFrame(data)\n",
    "    df.columns = df.iloc[0]\n",
    "    df = df[1:]\n",
    "    \n",
    "    #remove rows without a gender\n",
    "    df['gender'].replace('', np.nan, inplace=True)\n",
    "    df['age'].replace('None', np.nan, inplace=True)\n",
    "    df.dropna(subset=['gender'], inplace=True)\n",
    "    df.dropna(subset=['age'], inplace=True)\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
<<<<<<< HEAD
   "execution_count": 214,
=======
   "execution_count": 164,
>>>>>>> 5be6589eb73edd4cf96d0baea41a7ddc63f0aa24
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
<<<<<<< HEAD
    "'''\n",
    "This function takes all the different age labels from the lookup table and changes it to categories.\n",
    "Toddler:      0->3\n",
    "Young_child:  4->6\n",
    "Child:        7->14\n",
    "Teenager:     15->20\n",
    "Adolescent:   21->24\n",
    "Young_adult:  25->32\n",
    "Adult:        33->48 \n",
    "Abraham:      49->59\n",
    "Elderly:      60+\n",
    "\n",
    "'''\n",
=======
>>>>>>> 5be6589eb73edd4cf96d0baea41a7ddc63f0aa24
    "def categorizing(df):\n",
    "    categories = ['Toddler', 'Young_Child', 'Child', 'Teenager', 'Adolescent', 'Young_Adult', 'Adult', 'Abraham', 'Elderly']\n",
    "    df['age'].replace(['(0, 2)', '2', '3'], categories[0], inplace = True)\n",
    "    df['age'].replace(['(4, 6)'], categories[1], inplace = True)\n",
    "    df['age'].replace(['(8, 12)', '13'], categories[2], inplace = True)\n",
    "    df['age'].replace(['(15, 20)'], categories[3], inplace = True)\n",
    "    df['age'].replace(['23', '22'], categories[4], inplace = True)\n",
    "    df['age'].replace(['(27, 32)', '(25, 32)', '29'], categories[5], inplace = True)\n",
    "    df['age'].replace(['35','34', '(38, 43)', '42', '46', '(38, 48)', '(38, 42)','45', '36'], categories[6], inplace = True)\n",
    "    df['age'].replace(['(48, 53)','55', '58','57'], categories[7], inplace = True)\n",
    "    df['age'].replace(['(60, 100)'], categories[8], inplace = True)\n",
    "    df['age'].replace(['(8, 23)'], np.nan, inplace = True)\n",
    "    df.dropna(subset=['age'], inplace=True)\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
<<<<<<< HEAD
   "execution_count": 215,
=======
   "execution_count": 165,
>>>>>>> 5be6589eb73edd4cf96d0baea41a7ddc63f0aa24
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
<<<<<<< HEAD
    "df = open_data('C:/Users/Arno/Desktop/Facial/Final-Project-Bletchley-02/MasterText_fold_data.txt.txt')"
=======
    "df = open_data('C:/Users/Arno/Desktop/Facial/MasterText_fold_data.txt.txt')"
>>>>>>> 5be6589eb73edd4cf96d0baea41a7ddc63f0aa24
   ]
  },
  {
   "cell_type": "code",
<<<<<<< HEAD
   "execution_count": 216,
=======
   "execution_count": 166,
>>>>>>> 5be6589eb73edd4cf96d0baea41a7ddc63f0aa24
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df = categorizing(df)"
   ]
  },
  {
   "cell_type": "code",
<<<<<<< HEAD
   "execution_count": 217,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Make ID column to match with the pictures\n",
    "df['ID'] = df['face_id']+'.'+df['original_image']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 218,
=======
   "execution_count": 167,
>>>>>>> 5be6589eb73edd4cf96d0baea41a7ddc63f0aa24
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>user_id</th>\n",
       "      <th>original_image</th>\n",
       "      <th>face_id</th>\n",
       "      <th>age</th>\n",
       "      <th>gender</th>\n",
       "      <th>x</th>\n",
       "      <th>y</th>\n",
       "      <th>dx</th>\n",
       "      <th>dy</th>\n",
       "      <th>tilt_ang</th>\n",
       "      <th>fiducial_yaw_angle</th>\n",
       "      <th>fiducial_score</th>\n",
<<<<<<< HEAD
       "      <th>ID</th>\n",
=======
>>>>>>> 5be6589eb73edd4cf96d0baea41a7ddc63f0aa24
       "    </tr>\n",
       "    <tr>\n",
       "      <th>age</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
<<<<<<< HEAD
       "      <th></th>\n",
=======
>>>>>>> 5be6589eb73edd4cf96d0baea41a7ddc63f0aa24
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Abraham</th>\n",
       "      <td>78</td>\n",
       "      <td>787</td>\n",
       "      <td>228</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>680</td>\n",
       "      <td>582</td>\n",
       "      <td>321</td>\n",
       "      <td>342</td>\n",
       "      <td>31</td>\n",
       "      <td>7</td>\n",
       "      <td>154</td>\n",
<<<<<<< HEAD
       "      <td>930</td>\n",
=======
>>>>>>> 5be6589eb73edd4cf96d0baea41a7ddc63f0aa24
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Adolescent</th>\n",
       "      <td>13</td>\n",
       "      <td>222</td>\n",
       "      <td>25</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>224</td>\n",
       "      <td>201</td>\n",
       "      <td>169</td>\n",
       "      <td>170</td>\n",
       "      <td>24</td>\n",
       "      <td>7</td>\n",
       "      <td>117</td>\n",
<<<<<<< HEAD
       "      <td>245</td>\n",
=======
>>>>>>> 5be6589eb73edd4cf96d0baea41a7ddc63f0aa24
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Adult</th>\n",
       "      <td>114</td>\n",
       "      <td>2352</td>\n",
       "      <td>462</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1333</td>\n",
       "      <td>1040</td>\n",
       "      <td>608</td>\n",
       "      <td>646</td>\n",
       "      <td>38</td>\n",
       "      <td>7</td>\n",
       "      <td>187</td>\n",
<<<<<<< HEAD
       "      <td>2889</td>\n",
=======
>>>>>>> 5be6589eb73edd4cf96d0baea41a7ddc63f0aa24
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Child</th>\n",
       "      <td>66</td>\n",
       "      <td>1673</td>\n",
       "      <td>196</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>1167</td>\n",
       "      <td>998</td>\n",
       "      <td>506</td>\n",
       "      <td>507</td>\n",
       "      <td>37</td>\n",
       "      <td>7</td>\n",
       "      <td>178</td>\n",
<<<<<<< HEAD
       "      <td>2287</td>\n",
=======
>>>>>>> 5be6589eb73edd4cf96d0baea41a7ddc63f0aa24
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Elderly</th>\n",
       "      <td>65</td>\n",
       "      <td>728</td>\n",
       "      <td>185</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>618</td>\n",
       "      <td>528</td>\n",
       "      <td>297</td>\n",
       "      <td>312</td>\n",
       "      <td>36</td>\n",
       "      <td>7</td>\n",
       "      <td>150</td>\n",
<<<<<<< HEAD
       "      <td>867</td>\n",
=======
>>>>>>> 5be6589eb73edd4cf96d0baea41a7ddc63f0aa24
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Teenager</th>\n",
       "      <td>62</td>\n",
       "      <td>1069</td>\n",
       "      <td>316</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>1023</td>\n",
       "      <td>794</td>\n",
       "      <td>485</td>\n",
       "      <td>480</td>\n",
       "      <td>30</td>\n",
       "      <td>7</td>\n",
       "      <td>164</td>\n",
<<<<<<< HEAD
       "      <td>1642</td>\n",
=======
>>>>>>> 5be6589eb73edd4cf96d0baea41a7ddc63f0aa24
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Toddler</th>\n",
       "      <td>43</td>\n",
       "      <td>2499</td>\n",
       "      <td>55</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>1081</td>\n",
       "      <td>950</td>\n",
       "      <td>884</td>\n",
       "      <td>893</td>\n",
       "      <td>48</td>\n",
       "      <td>7</td>\n",
       "      <td>167</td>\n",
<<<<<<< HEAD
       "      <td>2509</td>\n",
=======
>>>>>>> 5be6589eb73edd4cf96d0baea41a7ddc63f0aa24
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Young_Adult</th>\n",
       "      <td>123</td>\n",
       "      <td>3812</td>\n",
       "      <td>623</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>1681</td>\n",
       "      <td>1236</td>\n",
       "      <td>792</td>\n",
       "      <td>876</td>\n",
       "      <td>38</td>\n",
       "      <td>7</td>\n",
       "      <td>190</td>\n",
<<<<<<< HEAD
       "      <td>5041</td>\n",
=======
>>>>>>> 5be6589eb73edd4cf96d0baea41a7ddc63f0aa24
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Young_Child</th>\n",
       "      <td>55</td>\n",
       "      <td>1962</td>\n",
       "      <td>130</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>1145</td>\n",
       "      <td>991</td>\n",
       "      <td>587</td>\n",
       "      <td>622</td>\n",
       "      <td>43</td>\n",
       "      <td>7</td>\n",
       "      <td>181</td>\n",
<<<<<<< HEAD
       "      <td>2140</td>\n",
=======
>>>>>>> 5be6589eb73edd4cf96d0baea41a7ddc63f0aa24
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             user_id  original_image  face_id  age  gender     x     y   dx  \\\n",
       "age                                                                           \n",
       "Abraham           78             787      228    1       2   680   582  321   \n",
       "Adolescent        13             222       25    1       2   224   201  169   \n",
       "Adult            114            2352      462    1       2  1333  1040  608   \n",
       "Child             66            1673      196    1       3  1167   998  506   \n",
       "Elderly           65             728      185    1       3   618   528  297   \n",
       "Teenager          62            1069      316    1       3  1023   794  485   \n",
       "Toddler           43            2499       55    1       3  1081   950  884   \n",
       "Young_Adult      123            3812      623    1       3  1681  1236  792   \n",
       "Young_Child       55            1962      130    1       3  1145   991  587   \n",
       "\n",
<<<<<<< HEAD
       "              dy  tilt_ang  fiducial_yaw_angle  fiducial_score\\n    ID  \n",
       "age                                                                     \n",
       "Abraham      342        31                   7               154   930  \n",
       "Adolescent   170        24                   7               117   245  \n",
       "Adult        646        38                   7               187  2889  \n",
       "Child        507        37                   7               178  2287  \n",
       "Elderly      312        36                   7               150   867  \n",
       "Teenager     480        30                   7               164  1642  \n",
       "Toddler      893        48                   7               167  2509  \n",
       "Young_Adult  876        38                   7               190  5041  \n",
       "Young_Child  622        43                   7               181  2140  "
      ]
     },
     "execution_count": 218,
=======
       "              dy  tilt_ang  fiducial_yaw_angle  fiducial_score\\n  \n",
       "age                                                               \n",
       "Abraham      342        31                   7               154  \n",
       "Adolescent   170        24                   7               117  \n",
       "Adult        646        38                   7               187  \n",
       "Child        507        37                   7               178  \n",
       "Elderly      312        36                   7               150  \n",
       "Teenager     480        30                   7               164  \n",
       "Toddler      893        48                   7               167  \n",
       "Young_Adult  876        38                   7               190  \n",
       "Young_Child  622        43                   7               181  "
      ]
     },
     "execution_count": 167,
>>>>>>> 5be6589eb73edd4cf96d0baea41a7ddc63f0aa24
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
<<<<<<< HEAD
    "# Check data diversity\n",
=======
    "# Check data\n",
>>>>>>> 5be6589eb73edd4cf96d0baea41a7ddc63f0aa24
    "count = df.groupby('age').nunique()\n",
    "count"
   ]
  },
  {
   "cell_type": "code",
<<<<<<< HEAD
   "execution_count": 219,
=======
   "execution_count": 168,
>>>>>>> 5be6589eb73edd4cf96d0baea41a7ddc63f0aa24
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYAAAAEwCAYAAAC+DabKAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nSQARER2VBBAR0VFJABERHfX/AexwY78RiH2BAAAAAElFTkSuQmCC\n",
      "text/plain": [
<<<<<<< HEAD
       "<matplotlib.figure.Figure at 0x196fe586a58>"
=======
       "<matplotlib.figure.Figure at 0x21308eee2b0>"
>>>>>>> 5be6589eb73edd4cf96d0baea41a7ddc63f0aa24
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Plot age distribution\n",
    "plt.hist(df['age'])\n",
    "plt.xticks(rotation=90)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
<<<<<<< HEAD
   "execution_count": 220,
=======
   "execution_count": 178,
>>>>>>> 5be6589eb73edd4cf96d0baea41a7ddc63f0aa24
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
<<<<<<< HEAD
    "'''\n",
    "This function looks throught the folder and finds all the files with .jpg extension\n",
    "'''\n",
    "def find_files(folder_path, extension):\n",
    "    directory = []\n",
    "    for file in os.listdir(folder_path):\n",
    "        if file.endswith(extension):\n",
=======
    "def find_files(folder_path):\n",
    "    directory = []\n",
    "    for file in os.listdir(folder_path):\n",
    "        if file.endswith(\".jpg\"):\n",
>>>>>>> 5be6589eb73edd4cf96d0baea41a7ddc63f0aa24
    "            directory.append(os.path.join(file))\n",
    "    return directory"
   ]
  },
  {
   "cell_type": "code",
<<<<<<< HEAD
   "execution_count": 221,
=======
   "execution_count": 185,
>>>>>>> 5be6589eb73edd4cf96d0baea41a7ddc63f0aa24
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
<<<<<<< HEAD
    "'''\n",
    "This function should be used together with the find_files function. It will combine the face_id and the photo_id together\n",
    "with the .jpg file extension to match the ID from the lookup dataframe.\n",
    "'''\n",
    "def get_ids(filename):\n",
    "    ids = []\n",
    "    for i in range(len(filename)):\n",
    "        splits = filename[i].split('.')\n",
    "        ids.append(splits[1]+'.'+splits[2]+'.jpg') # Face_id + original_image + .jpg\n",
    "    df_ids = pd.DataFrame(ids)\n",
    "    df_ids.rename(columns = {0: \"ID\"}, inplace=True)\n",
    "    return df_ids"
=======
    "def get_ids(directory):\n",
    "    ids = []\n",
    "    for i in range(len(directory)):\n",
    "        splits = directory[i].split('.')\n",
    "        ids.append(splits[2]+'.jpg')\n",
    "    return ids"
>>>>>>> 5be6589eb73edd4cf96d0baea41a7ddc63f0aa24
   ]
  },
  {
   "cell_type": "code",
<<<<<<< HEAD
   "execution_count": 222,
=======
   "execution_count": 258,
>>>>>>> 5be6589eb73edd4cf96d0baea41a7ddc63f0aa24
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
<<<<<<< HEAD
    "'''\n",
    "This function overlaps the IDs from all the training pictures to the total dataset of pictures and extracts the data\n",
    "from only the training data.\n",
    "'''\n",
    "def useful_df(look_up, subset):\n",
    "    useful = look_up[look_up.ID.isin(subset['ID'])]\n",
    "    useful.set_index('ID', inplace=True)\n",
    "    useful['facial_landmarks'] = 0\n",
=======
    "def useful_df(df, ids):\n",
    "    useful = np.zeros((len(ids),3), dtype = str)\n",
    "    for i in range(len(ids)):\n",
    "        change = df.loc[df['original_image'] == ids['original_image'][i]].as_matrix()\n",
    "        useful[i][0] = ids['original_image'][i]\n",
    "        useful[i][1] = change[3] #Age\n",
    "        useful[i][2] = change[4] #Gender\n",
    "        \n",
>>>>>>> 5be6589eb73edd4cf96d0baea41a7ddc63f0aa24
    "    return useful    "
   ]
  },
  {
   "cell_type": "code",
<<<<<<< HEAD
   "execution_count": 223,
=======
   "execution_count": 186,
>>>>>>> 5be6589eb73edd4cf96d0baea41a7ddc63f0aa24
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
<<<<<<< HEAD
    "def find_landmarks(image):\n",
    "    landmarks_array = 0\n",
    "    detector = dlib.get_frontal_face_detector()\n",
    "    # Loading in the pretrained predictor\n",
    "    predictor = dlib.shape_predictor('C:/Users/Arno/Desktop/Facial/shape_predictor_68_face_landmarks.dat')\n",
    "    rects = detector(image,0)\n",
    "    for (i, rect) in enumerate(rects):\n",
    "        '''\n",
    "        Determine the facial landmarks for the face region, then\n",
    "        convert the facial landmark (x, y)-coordinates to a NumPy array\n",
    "        '''\n",
    "        face = predictor(image, rect)\n",
    "        landmarks_array = face_utils.shape_to_np(face)\n",
    "    return landmarks_array "
=======
    "files = find_files('C:/Users/Arno/Desktop/Facial/DataBase')"
>>>>>>> 5be6589eb73edd4cf96d0baea41a7ddc63f0aa24
   ]
  },
  {
   "cell_type": "code",
<<<<<<< HEAD
   "execution_count": 224,
   "metadata": {},
   "outputs": [
    {
     "ename": "IndentationError",
     "evalue": "expected an indented block (<ipython-input-224-771a0ff46347>, line 5)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;36m  File \u001b[1;32m\"<ipython-input-224-771a0ff46347>\"\u001b[1;36m, line \u001b[1;32m5\u001b[0m\n\u001b[1;33m    ret, frame = cap.read()\u001b[0m\n\u001b[1;37m      ^\u001b[0m\n\u001b[1;31mIndentationError\u001b[0m\u001b[1;31m:\u001b[0m expected an indented block\n"
     ]
    }
   ],
   "source": [
    "def capture_video(frames, output):\n",
    "    cap = cv2.VideoCapture(0)\n",
    "    while(True):\n",
    "    # Capture frame-by-frame\n",
    "    ret, frame = cap.read()\n",
    "\n",
    "    # Our operations on the frame come here\n",
    "    gray = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY)\n",
    "    if cv2.waitKey(1) & 0xFF == ord('q'):\n",
    "        break\n",
    "\n",
    "# When everything done, release the capture\n",
    "cap.release()\n",
    "cv2.destroyAllWindows()"
=======
   "execution_count": 222,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "ids = get_ids(files)\n",
    "df_ids = pd.DataFrame(ids)\n",
    "df_ids.rename(columns = {0: \"original_image\"}, inplace=True)"
>>>>>>> 5be6589eb73edd4cf96d0baea41a7ddc63f0aa24
   ]
  },
  {
   "cell_type": "code",
<<<<<<< HEAD
   "execution_count": 225,
=======
   "execution_count": 224,
>>>>>>> 5be6589eb73edd4cf96d0baea41a7ddc63f0aa24
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
<<<<<<< HEAD
   "source": [
    "def landmark_printer(x): \n",
    "    for i in range(len(x)):\n",
    "        plt.scatter(x[i][:,0],x[i][:,1])\n",
    "        plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 226,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "files = find_files('C:/Users/Arno/Desktop/Facial/DataBase', '.jpg')"
=======
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 259,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "ename": "IndexError",
     "evalue": "index 3 is out of bounds for axis 0 with size 2",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-259-dec72a1dd108>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mdf_useful\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0museful_df\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdf\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mdf_ids\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m<ipython-input-258-ff6312882f0b>\u001b[0m in \u001b[0;36museful_df\u001b[1;34m(df, ids)\u001b[0m\n\u001b[0;32m      4\u001b[0m         \u001b[0mchange\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mdf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mloc\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mdf\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'original_image'\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m==\u001b[0m \u001b[0mids\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'original_image'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mas_matrix\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m         \u001b[0museful\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mids\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'original_image'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 6\u001b[1;33m         \u001b[0museful\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mchange\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m3\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;31m#Age\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      7\u001b[0m         \u001b[0museful\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m2\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mchange\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m4\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;31m#Gender\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      8\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mIndexError\u001b[0m: index 3 is out of bounds for axis 0 with size 2"
     ]
    }
   ],
   "source": [
    "df_useful = useful_df(df,df_ids)"
>>>>>>> 5be6589eb73edd4cf96d0baea41a7ddc63f0aa24
   ]
  },
  {
   "cell_type": "code",
<<<<<<< HEAD
   "execution_count": 227,
=======
   "execution_count": 253,
>>>>>>> 5be6589eb73edd4cf96d0baea41a7ddc63f0aa24
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
<<<<<<< HEAD
       "['coarse_tilt_aligned_face.1000.8194283079_fe7c8c9b2f_o.jpg',\n",
       " 'coarse_tilt_aligned_face.1000.8314899476_8c1ac2e4bb_o.jpg',\n",
       " 'coarse_tilt_aligned_face.1000.8884658111_c692813a62_o.jpg',\n",
       " 'coarse_tilt_aligned_face.1001.10009166853_a6b50b4117_o.jpg',\n",
       " 'coarse_tilt_aligned_face.1001.8195375498_06c6fc5627_o.jpg',\n",
       " 'coarse_tilt_aligned_face.1001.8215787552_3198c25285_o.jpg',\n",
       " 'coarse_tilt_aligned_face.1001.8586120507_6c519d5923_o.jpg',\n",
       " 'coarse_tilt_aligned_face.1002.8314893776_8ddb4d4549_o.jpg',\n",
       " 'coarse_tilt_aligned_face.1003.8194283079_fe7c8c9b2f_o.jpg',\n",
       " 'coarse_tilt_aligned_face.1004.8469357784_ac74572242_o.jpg',\n",
       " 'coarse_tilt_aligned_face.1005.8313851951_3a0bd24aeb_o.jpg',\n",
       " 'coarse_tilt_aligned_face.1005.8314901670_835a0aec49_o.jpg',\n",
       " 'coarse_tilt_aligned_face.1006.11533025853_f3eb6ae6c7_o.jpg',\n",
       " 'coarse_tilt_aligned_face.1050.11486219815_c7725c3300_o.jpg',\n",
       " 'coarse_tilt_aligned_face.1050.11486520496_955dea5c71_o.jpg',\n",
       " 'coarse_tilt_aligned_face.1050.11486644334_fcd534e0ec_o.jpg',\n",
       " 'coarse_tilt_aligned_face.1050.11486726716_e0dcf8f67a_o.jpg',\n",
       " 'coarse_tilt_aligned_face.1050.11486731586_0c25a7d057_o.jpg',\n",
       " 'coarse_tilt_aligned_face.1050.11486800265_fed6909ed6_o.jpg',\n",
       " 'coarse_tilt_aligned_face.1050.11486804315_38016fa7a3_o.jpg',\n",
       " 'coarse_tilt_aligned_face.1050.11486850554_e39f75fb7e_o.jpg',\n",
       " 'coarse_tilt_aligned_face.1050.11486871145_20f34d8610_o.jpg',\n",
       " 'coarse_tilt_aligned_face.1050.11486871494_8ded06f48c_o.jpg',\n",
       " 'coarse_tilt_aligned_face.1050.11486879925_4f1e6e9a8a_o.jpg',\n",
       " 'coarse_tilt_aligned_face.1050.11486887194_5efdb501fa_o.jpg',\n",
       " 'coarse_tilt_aligned_face.1050.11486889344_27967040ff_o.jpg',\n",
       " 'coarse_tilt_aligned_face.1050.11486899924_c3eb356839_o.jpg',\n",
       " 'coarse_tilt_aligned_face.1050.11486916314_778b823dc2_o.jpg',\n",
       " 'coarse_tilt_aligned_face.1050.11486924966_c3d8cdbcc8_o.jpg',\n",
       " 'coarse_tilt_aligned_face.1050.11486965696_f2d3b39d7a_o.jpg',\n",
       " 'coarse_tilt_aligned_face.1050.11486976856_f9917fec31_o.jpg',\n",
       " 'coarse_tilt_aligned_face.1050.11486998633_5b9c636d36_o.jpg',\n",
       " 'coarse_tilt_aligned_face.1050.11488884825_218518c94c_o.jpg',\n",
       " 'coarse_tilt_aligned_face.1050.11488940654_81e1a84bf0_o.jpg',\n",
       " 'coarse_tilt_aligned_face.1050.11489024833_e211de59c5_o.jpg',\n",
       " 'coarse_tilt_aligned_face.1050.11489543156_4284de3505_o.jpg',\n",
       " 'coarse_tilt_aligned_face.1051.11486181634_c4c2e6a140_o.jpg',\n",
       " 'coarse_tilt_aligned_face.1051.11486223085_37b94fd38a_o.jpg',\n",
       " 'coarse_tilt_aligned_face.1051.11486225125_86f865e7ba_o.jpg',\n",
       " 'coarse_tilt_aligned_face.1051.11486233954_cf9182cdcd_o.jpg',\n",
       " 'coarse_tilt_aligned_face.1051.11486320666_83e4e8ed27_o.jpg',\n",
       " 'coarse_tilt_aligned_face.1051.11486331973_d6868c2e31_o.jpg',\n",
       " 'coarse_tilt_aligned_face.1051.11486443503_6600ac2fe9_o.jpg',\n",
       " 'coarse_tilt_aligned_face.1051.11486520395_65cb63af61_o.jpg',\n",
       " 'coarse_tilt_aligned_face.1051.11486585196_f28ce5a70f_o.jpg',\n",
       " 'coarse_tilt_aligned_face.1051.11486586063_714453b44c_o.jpg',\n",
       " 'coarse_tilt_aligned_face.1051.11486618426_ee0a8cf6be_o.jpg',\n",
       " 'coarse_tilt_aligned_face.1051.11486630646_8acb9db15d_o.jpg',\n",
       " 'coarse_tilt_aligned_face.1051.11486638635_2c04a14d70_o.jpg',\n",
       " 'coarse_tilt_aligned_face.1051.11486641884_46ef3df822_o.jpg',\n",
       " 'coarse_tilt_aligned_face.1051.11486647863_d0ea91101b_o.jpg',\n",
       " 'coarse_tilt_aligned_face.1051.11486674315_a91463b838_o.jpg',\n",
       " 'coarse_tilt_aligned_face.1051.11486675854_ae9457aca5_o.jpg',\n",
       " 'coarse_tilt_aligned_face.1051.11486678664_775d2aeecd_o.jpg',\n",
       " 'coarse_tilt_aligned_face.1051.11486744514_f23fa54d61_o.jpg',\n",
       " 'coarse_tilt_aligned_face.1051.11486747746_b1cbeaa5c8_o.jpg',\n",
       " 'coarse_tilt_aligned_face.1051.11486751376_1b994f4569_o.jpg',\n",
       " 'coarse_tilt_aligned_face.1051.11486766743_71e3cc2266_o.jpg',\n",
       " 'coarse_tilt_aligned_face.1051.11486770363_f6a75be62a_o.jpg',\n",
       " 'coarse_tilt_aligned_face.1051.11486778763_4a73c8f860_o.jpg',\n",
       " 'coarse_tilt_aligned_face.1051.11486804315_38016fa7a3_o.jpg',\n",
       " 'coarse_tilt_aligned_face.1051.11486823313_65b3059109_o.jpg',\n",
       " 'coarse_tilt_aligned_face.1051.11486916314_778b823dc2_o.jpg',\n",
       " 'coarse_tilt_aligned_face.1051.11486972716_95ccb305d6_o.jpg',\n",
       " 'coarse_tilt_aligned_face.1051.11486973323_5eb9a33462_o.jpg',\n",
       " 'coarse_tilt_aligned_face.1051.11486991546_2d94c34574_o.jpg',\n",
       " 'coarse_tilt_aligned_face.1051.11487014573_35db14c793_o.jpg',\n",
       " 'coarse_tilt_aligned_face.1051.11488902375_9632606f65_o.jpg',\n",
       " 'coarse_tilt_aligned_face.1051.11488903565_c7181af3a0_o.jpg',\n",
       " 'coarse_tilt_aligned_face.1051.11488916775_b60a2e98b3_o.jpg',\n",
       " 'coarse_tilt_aligned_face.1051.11488919055_a36cb45880_o.jpg',\n",
       " 'coarse_tilt_aligned_face.1051.11488943975_f463d03732_o.jpg',\n",
       " 'coarse_tilt_aligned_face.1051.11488945265_a8c35a601e_o.jpg',\n",
       " 'coarse_tilt_aligned_face.1051.11488950085_737b57f784_o.jpg',\n",
       " 'coarse_tilt_aligned_face.1051.11488971874_d4d8916590_o.jpg',\n",
       " 'coarse_tilt_aligned_face.1051.11489012506_49c4dd57c1_o.jpg',\n",
       " 'coarse_tilt_aligned_face.1051.11489016923_f1631bf183_o.jpg',\n",
       " 'coarse_tilt_aligned_face.1051.11489054113_cd40072044_o.jpg',\n",
       " 'coarse_tilt_aligned_face.1051.11489055896_340ffb5909_o.jpg',\n",
       " 'coarse_tilt_aligned_face.1051.11489056043_b7655ccbb1_o.jpg',\n",
       " 'coarse_tilt_aligned_face.1051.11489058623_592f4f53aa_o.jpg',\n",
       " 'coarse_tilt_aligned_face.1051.11489058856_4011c3267e_o.jpg',\n",
       " 'coarse_tilt_aligned_face.1051.11489067866_d926f51fb2_o.jpg',\n",
       " 'coarse_tilt_aligned_face.1051.11489089323_b73633f5ff_o.jpg',\n",
       " 'coarse_tilt_aligned_face.1052.11486312464_8f09d0ba81_o.jpg',\n",
       " 'coarse_tilt_aligned_face.1052.11486427933_306e315f8a_o.jpg',\n",
       " 'coarse_tilt_aligned_face.1052.11486675854_ae9457aca5_o.jpg',\n",
       " 'coarse_tilt_aligned_face.1052.11486778763_4a73c8f860_o.jpg',\n",
       " 'coarse_tilt_aligned_face.1052.11486847254_eecd04f67a_o.jpg',\n",
       " 'coarse_tilt_aligned_face.1052.11486945373_14a6bbd86c_o.jpg',\n",
       " 'coarse_tilt_aligned_face.1052.11487017643_8640525028_o.jpg',\n",
       " 'coarse_tilt_aligned_face.1053.11486402433_879c872348_o.jpg',\n",
       " 'coarse_tilt_aligned_face.1054.11486567753_43840879a7_o.jpg',\n",
       " 'coarse_tilt_aligned_face.1154.8181847504_03421a876b_o.jpg',\n",
       " 'coarse_tilt_aligned_face.1154.8887436088_550fd2aa66_o.jpg',\n",
       " 'coarse_tilt_aligned_face.1154.9817776724_07065d5745_o.jpg',\n",
       " 'coarse_tilt_aligned_face.1154.9819364706_d0cb2dd24c_o.jpg',\n",
       " 'coarse_tilt_aligned_face.1154.9819393085_bc15d60f79_o.jpg',\n",
       " 'coarse_tilt_aligned_face.1154.9819415243_82607bcdc2_o.jpg',\n",
       " 'coarse_tilt_aligned_face.1154.9819480963_6d378646c9_o.jpg',\n",
       " 'coarse_tilt_aligned_face.1155.8048536239_eee970d7f0_o.jpg',\n",
       " 'coarse_tilt_aligned_face.1155.9480947939_5c1e20f7cf_o.jpg',\n",
       " 'coarse_tilt_aligned_face.1155.9818160664_57fb4c5433_o.jpg',\n",
       " 'coarse_tilt_aligned_face.1155.9818179176_58e3044f33_o.jpg',\n",
       " 'coarse_tilt_aligned_face.1155.9818527876_911cff7a12_o.jpg',\n",
       " 'coarse_tilt_aligned_face.1155.9818573796_23651f3e1b_o.jpg',\n",
       " 'coarse_tilt_aligned_face.1155.9818627343_bf3d480e36_o.jpg',\n",
       " 'coarse_tilt_aligned_face.1155.9818956436_7f65042ce3_o.jpg',\n",
       " 'coarse_tilt_aligned_face.1155.9819343596_257768f42d_o.jpg',\n",
       " 'coarse_tilt_aligned_face.1155.9819415243_82607bcdc2_o.jpg',\n",
       " 'coarse_tilt_aligned_face.1155.9819488355_05fe5cc722_o.jpg',\n",
       " 'coarse_tilt_aligned_face.1155.9819497635_bd4db92d61_o.jpg',\n",
       " 'coarse_tilt_aligned_face.1155.9819583274_61022958e8_o.jpg',\n",
       " 'coarse_tilt_aligned_face.1155.9819600456_00d3f6aea7_o.jpg',\n",
       " 'coarse_tilt_aligned_face.1155.9819655043_6bb8e4a1fa_o.jpg',\n",
       " 'coarse_tilt_aligned_face.1156.10507385625_bb4f7c957b_o.jpg',\n",
       " 'coarse_tilt_aligned_face.1156.10507411934_474e726ce3_o.jpg',\n",
       " 'coarse_tilt_aligned_face.1157.9817895353_68ef55dda8_o.jpg',\n",
       " 'coarse_tilt_aligned_face.1157.9818086864_05d72cd64c_o.jpg',\n",
       " 'coarse_tilt_aligned_face.1157.9818478894_a00af206db_o.jpg',\n",
       " 'coarse_tilt_aligned_face.1157.9818509376_e060e4eb3a_o.jpg',\n",
       " 'coarse_tilt_aligned_face.1157.9818537426_cf3c220ffc_o.jpg',\n",
       " 'coarse_tilt_aligned_face.1157.9818594043_3164696f93_o.jpg',\n",
       " 'coarse_tilt_aligned_face.1158.8888142544_0311ff6e60_o.jpg',\n",
       " 'coarse_tilt_aligned_face.1159.9480947939_5c1e20f7cf_o.jpg',\n",
       " 'coarse_tilt_aligned_face.1159.9817813695_ed834e77fa_o.jpg',\n",
       " 'coarse_tilt_aligned_face.1159.9817827684_bf57f6529c_o.jpg',\n",
       " 'coarse_tilt_aligned_face.1159.9817834615_cd4ecbf736_o.jpg',\n",
       " 'coarse_tilt_aligned_face.1159.9817842825_1491eda00a_o.jpg',\n",
       " 'coarse_tilt_aligned_face.1159.9818083855_b651f26a3b_o.jpg',\n",
       " 'coarse_tilt_aligned_face.1159.9818260503_b263c7ecd4_o.jpg',\n",
       " 'coarse_tilt_aligned_face.1159.9818615903_f3ee213fa1_o.jpg',\n",
       " 'coarse_tilt_aligned_face.1159.9818956436_7f65042ce3_o.jpg',\n",
       " 'coarse_tilt_aligned_face.1159.9819389686_273551eec5_o.jpg',\n",
       " 'coarse_tilt_aligned_face.1159.9819573733_9a8d2019d0_o.jpg',\n",
       " 'coarse_tilt_aligned_face.1159.9819653765_a3f9d62b8b_o.jpg',\n",
       " 'coarse_tilt_aligned_face.1159.9819658524_8744c512c4_o.jpg',\n",
       " 'coarse_tilt_aligned_face.1159.9819666094_8565273a64_o.jpg',\n",
       " 'coarse_tilt_aligned_face.1159.9819758983_049beff7d2_o.jpg',\n",
       " 'coarse_tilt_aligned_face.1159.9819932974_4357771405_o.jpg',\n",
       " 'coarse_tilt_aligned_face.1160.8474690925_b83a73e563_o.jpg',\n",
       " 'coarse_tilt_aligned_face.1160.9818872304_d28110ba52_o.jpg',\n",
       " 'coarse_tilt_aligned_face.1160.9818899635_ae0f7f3183_o.jpg',\n",
       " 'coarse_tilt_aligned_face.1161.8474690925_b83a73e563_o.jpg',\n",
       " 'coarse_tilt_aligned_face.1161.8474692523_38f468299c_o.jpg',\n",
       " 'coarse_tilt_aligned_face.1161.9817732295_954e26a1f7_o.jpg',\n",
       " 'coarse_tilt_aligned_face.1161.9817737215_59254bb0b1_o.jpg',\n",
       " 'coarse_tilt_aligned_face.1162.9817764484_fa125d448e_o.jpg',\n",
       " 'coarse_tilt_aligned_face.1163.9817764484_fa125d448e_o.jpg',\n",
       " 'coarse_tilt_aligned_face.1163.9817818093_9301bd2b43_o.jpg',\n",
       " 'coarse_tilt_aligned_face.1164.8887426536_6914838e02_o.jpg',\n",
       " 'coarse_tilt_aligned_face.1164.8887436088_550fd2aa66_o.jpg',\n",
       " 'coarse_tilt_aligned_face.1164.9817878973_7ce8174e0b_o.jpg',\n",
       " 'coarse_tilt_aligned_face.1164.9817901083_63067f0a77_o.jpg',\n",
       " 'coarse_tilt_aligned_face.1164.9819520015_fa8d2c3373_o.jpg',\n",
       " 'coarse_tilt_aligned_face.1164.9819527085_8f8f0b41f8_o.jpg',\n",
       " 'coarse_tilt_aligned_face.1165.9817866804_2112de1591_o.jpg',\n",
       " 'coarse_tilt_aligned_face.1166.9819488355_05fe5cc722_o.jpg',\n",
       " 'coarse_tilt_aligned_face.1166.9819497635_bd4db92d61_o.jpg',\n",
       " 'coarse_tilt_aligned_face.1167.9819488355_05fe5cc722_o.jpg',\n",
       " 'coarse_tilt_aligned_face.1168.8886806101_1118f3d6e1_o.jpg',\n",
       " 'coarse_tilt_aligned_face.1168.8887426536_6914838e02_o.jpg',\n",
       " 'coarse_tilt_aligned_face.1168.8887436088_550fd2aa66_o.jpg',\n",
       " 'coarse_tilt_aligned_face.1169.10507373426_df0b807f0c_o.jpg',\n",
       " 'coarse_tilt_aligned_face.1169.10507401784_e1242336a5_o.jpg',\n",
       " 'coarse_tilt_aligned_face.1169.10640698496_ae87a7d24f_o.jpg',\n",
       " 'coarse_tilt_aligned_face.1169.10775942136_5733b47b67_o.jpg',\n",
       " 'coarse_tilt_aligned_face.1169.10776171033_7e7a75f112_o.jpg',\n",
       " 'coarse_tilt_aligned_face.1169.8065421616_842f1aa4de_o.jpg',\n",
       " 'coarse_tilt_aligned_face.1169.9818180355_6c9c922d3e_o.jpg',\n",
       " 'coarse_tilt_aligned_face.1170.9819512885_edde480d43_o.jpg',\n",
       " 'coarse_tilt_aligned_face.1170.9819573733_9a8d2019d0_o.jpg',\n",
       " 'coarse_tilt_aligned_face.1171.8065415677_d69359133f_o.jpg',\n",
       " 'coarse_tilt_aligned_face.1172.10744072323_a465c7618e_o.jpg',\n",
       " 'coarse_tilt_aligned_face.1173.10743841116_f90d329820_o.jpg',\n",
       " 'coarse_tilt_aligned_face.1173.10744072323_a465c7618e_o.jpg',\n",
       " 'coarse_tilt_aligned_face.1174.10743841116_f90d329820_o.jpg',\n",
       " 'coarse_tilt_aligned_face.1174.10744072323_a465c7618e_o.jpg',\n",
       " 'coarse_tilt_aligned_face.1175.10743841116_f90d329820_o.jpg',\n",
       " 'coarse_tilt_aligned_face.1175.10744072323_a465c7618e_o.jpg',\n",
       " 'coarse_tilt_aligned_face.1176.9817740584_818e9f6a8d_o.jpg',\n",
       " 'coarse_tilt_aligned_face.1177.9817740584_818e9f6a8d_o.jpg',\n",
       " 'coarse_tilt_aligned_face.1178.10470557845_33a1d0249b_o.jpg',\n",
       " 'coarse_tilt_aligned_face.1178.10507385625_bb4f7c957b_o.jpg',\n",
       " 'coarse_tilt_aligned_face.1179.10397763914_ed922c5da1_o.jpg',\n",
       " 'coarse_tilt_aligned_face.1180.9819497635_bd4db92d61_o.jpg',\n",
       " 'coarse_tilt_aligned_face.1180.9819573733_9a8d2019d0_o.jpg',\n",
       " 'coarse_tilt_aligned_face.1181.9819573733_9a8d2019d0_o.jpg',\n",
       " 'coarse_tilt_aligned_face.1182.9819497635_bd4db92d61_o.jpg',\n",
       " 'coarse_tilt_aligned_face.1182.9819573733_9a8d2019d0_o.jpg',\n",
       " 'coarse_tilt_aligned_face.1183.9818949806_99ae454386_o.jpg',\n",
       " 'coarse_tilt_aligned_face.1184.8181849986_2996a44253_o.jpg',\n",
       " 'coarse_tilt_aligned_face.1185.8228059421_e3a4cbafcd_o.jpg',\n",
       " 'coarse_tilt_aligned_face.1186.10426500625_7cda471401_o.jpg',\n",
       " 'coarse_tilt_aligned_face.1187.10397783766_d2a0350cb5_o.jpg',\n",
       " 'coarse_tilt_aligned_face.1188.10470557845_33a1d0249b_o.jpg',\n",
       " 'coarse_tilt_aligned_face.1189.10743841116_f90d329820_o.jpg',\n",
       " 'coarse_tilt_aligned_face.1190.11674850055_0107e2c11e_o.jpg',\n",
       " 'coarse_tilt_aligned_face.1190.11675144444_1e7e8b4e00_o.jpg',\n",
       " 'coarse_tilt_aligned_face.1190.11675351554_bfce40ae2c_o.jpg',\n",
       " 'coarse_tilt_aligned_face.1190.11675736376_35b4b2397d_o.jpg',\n",
       " 'coarse_tilt_aligned_face.1190.11695386025_f817925f61_o.jpg',\n",
       " 'coarse_tilt_aligned_face.1190.11715771373_ff5b0fec19_o.jpg',\n",
       " 'coarse_tilt_aligned_face.1190.11718222785_0e542f4798_o.jpg',\n",
       " 'coarse_tilt_aligned_face.1190.11718607835_5aaf4b333b_o.jpg',\n",
       " 'coarse_tilt_aligned_face.1190.11718865536_230f2b0c1d_o.jpg',\n",
       " 'coarse_tilt_aligned_face.1190.11718882903_b7599bb352_o.jpg',\n",
       " 'coarse_tilt_aligned_face.1190.11718982194_2d5ae88732_o.jpg',\n",
       " 'coarse_tilt_aligned_face.1190.11719324384_8b56e795f3_o.jpg',\n",
       " 'coarse_tilt_aligned_face.1190.11736573925_b74a66d130_o.jpg',\n",
       " 'coarse_tilt_aligned_face.1190.11739951455_daaa2fb3d8_o.jpg',\n",
       " 'coarse_tilt_aligned_face.1190.11740146116_14825d3b71_o.jpg',\n",
       " 'coarse_tilt_aligned_face.1190.11740279055_c0059b5de8_o.jpg',\n",
       " 'coarse_tilt_aligned_face.1190.11740345784_0ecc45a8bd_o.jpg',\n",
       " 'coarse_tilt_aligned_face.1190.11740888306_1d194a8bfd_o.jpg',\n",
       " 'coarse_tilt_aligned_face.1190.11761689265_7b984cb061_o.jpg',\n",
       " 'coarse_tilt_aligned_face.1190.11762786095_3658b69c0b_o.jpg',\n",
       " 'coarse_tilt_aligned_face.1190.11762814664_7c365b5e8e_o.jpg',\n",
       " 'coarse_tilt_aligned_face.1190.11763164396_affcb7f1bc_o.jpg',\n",
       " 'coarse_tilt_aligned_face.1190.11764097016_f644c28870_o.jpg',\n",
       " 'coarse_tilt_aligned_face.1190.11782512684_53de3f98c4_o.jpg',\n",
       " 'coarse_tilt_aligned_face.1190.11782588895_2672ee5409_o.jpg',\n",
       " 'coarse_tilt_aligned_face.1190.11783710056_e2a9a43e88_o.jpg',\n",
       " 'coarse_tilt_aligned_face.1191.11674846505_3278a48cd5_o.jpg',\n",
       " 'coarse_tilt_aligned_face.1191.11674850055_0107e2c11e_o.jpg',\n",
       " 'coarse_tilt_aligned_face.1191.11675144444_1e7e8b4e00_o.jpg',\n",
       " 'coarse_tilt_aligned_face.1191.11675206034_26f81b852a_o.jpg',\n",
       " 'coarse_tilt_aligned_face.1191.11675218213_044e88b6fc_o.jpg',\n",
       " 'coarse_tilt_aligned_face.1191.11675354834_1d18d1fbd7_o.jpg',\n",
       " 'coarse_tilt_aligned_face.1191.11675636406_56c90b9955_o.jpg',\n",
       " 'coarse_tilt_aligned_face.1191.11675736376_35b4b2397d_o.jpg',\n",
       " 'coarse_tilt_aligned_face.1191.11693252063_66a26c1093_o.jpg',\n",
       " 'coarse_tilt_aligned_face.1191.11696372825_b8fccff283_o.jpg',\n",
       " 'coarse_tilt_aligned_face.1191.11696719825_5ffecae552_o.jpg',\n",
       " 'coarse_tilt_aligned_face.1191.11715959185_702525c26b_o.jpg',\n",
       " 'coarse_tilt_aligned_face.1191.11716626444_bf4e4cc93e_o.jpg',\n",
       " 'coarse_tilt_aligned_face.1191.11716891996_33318c1e3c_o.jpg',\n",
       " 'coarse_tilt_aligned_face.1191.11718882903_b7599bb352_o.jpg',\n",
       " 'coarse_tilt_aligned_face.1191.11719324384_8b56e795f3_o.jpg',\n",
       " 'coarse_tilt_aligned_face.1191.11736573925_b74a66d130_o.jpg',\n",
       " 'coarse_tilt_aligned_face.1191.11741543515_93c4ebccd4_o.jpg',\n",
       " 'coarse_tilt_aligned_face.1191.11741745995_0c3b564c3b_o.jpg',\n",
       " 'coarse_tilt_aligned_face.1191.11758419285_fd3be7f13d_o.jpg',\n",
       " 'coarse_tilt_aligned_face.1191.11758969484_e3a36eae20_o.jpg',\n",
       " 'coarse_tilt_aligned_face.1191.11759177256_7742e58aaf_o.jpg',\n",
       " 'coarse_tilt_aligned_face.1191.11759400705_4b40f521d8_o.jpg',\n",
       " 'coarse_tilt_aligned_face.1191.11761689265_7b984cb061_o.jpg',\n",
       " 'coarse_tilt_aligned_face.1191.11762786095_3658b69c0b_o.jpg',\n",
       " 'coarse_tilt_aligned_face.1191.11762814664_7c365b5e8e_o.jpg',\n",
       " 'coarse_tilt_aligned_face.1191.11763164396_affcb7f1bc_o.jpg',\n",
       " 'coarse_tilt_aligned_face.1191.11764097016_f644c28870_o.jpg',\n",
       " 'coarse_tilt_aligned_face.1192.11718222785_0e542f4798_o.jpg',\n",
       " 'coarse_tilt_aligned_face.1192.11718607835_5aaf4b333b_o.jpg',\n",
       " 'coarse_tilt_aligned_face.1192.11718865536_230f2b0c1d_o.jpg',\n",
       " 'coarse_tilt_aligned_face.1192.11718882903_b7599bb352_o.jpg',\n",
       " 'coarse_tilt_aligned_face.1192.11719324384_8b56e795f3_o.jpg',\n",
       " 'coarse_tilt_aligned_face.1192.11736573925_b74a66d130_o.jpg',\n",
       " 'coarse_tilt_aligned_face.1192.11741543515_93c4ebccd4_o.jpg',\n",
       " 'coarse_tilt_aligned_face.1192.11741745995_0c3b564c3b_o.jpg',\n",
       " 'coarse_tilt_aligned_face.1192.11758419285_fd3be7f13d_o.jpg',\n",
       " 'coarse_tilt_aligned_face.1192.11758969484_e3a36eae20_o.jpg',\n",
       " 'coarse_tilt_aligned_face.1192.11759177256_7742e58aaf_o.jpg',\n",
       " 'coarse_tilt_aligned_face.1192.11759400705_4b40f521d8_o.jpg',\n",
       " 'coarse_tilt_aligned_face.1193.11674837945_e780087338_o.jpg',\n",
       " 'coarse_tilt_aligned_face.1193.11675206034_26f81b852a_o.jpg',\n",
       " 'coarse_tilt_aligned_face.1193.11675622866_18704bf16a_o.jpg',\n",
       " 'coarse_tilt_aligned_face.1193.11741543515_93c4ebccd4_o.jpg',\n",
       " 'coarse_tilt_aligned_face.1193.11741745995_0c3b564c3b_o.jpg',\n",
       " 'coarse_tilt_aligned_face.1193.11758419285_fd3be7f13d_o.jpg',\n",
       " 'coarse_tilt_aligned_face.1193.11758969484_e3a36eae20_o.jpg',\n",
       " 'coarse_tilt_aligned_face.1193.11759177256_7742e58aaf_o.jpg',\n",
       " 'coarse_tilt_aligned_face.1193.11759400705_4b40f521d8_o.jpg',\n",
       " 'coarse_tilt_aligned_face.1193.11761689265_7b984cb061_o.jpg',\n",
       " 'coarse_tilt_aligned_face.1193.11762786095_3658b69c0b_o.jpg',\n",
       " 'coarse_tilt_aligned_face.1193.11762814664_7c365b5e8e_o.jpg',\n",
       " 'coarse_tilt_aligned_face.1193.11763164396_affcb7f1bc_o.jpg',\n",
       " 'coarse_tilt_aligned_face.1193.11764097016_f644c28870_o.jpg',\n",
       " 'coarse_tilt_aligned_face.1194.11716788983_1bf44f294b_o.jpg',\n",
       " 'coarse_tilt_aligned_face.1194.11717036266_c455097f76_o.jpg',\n",
       " 'coarse_tilt_aligned_face.1194.11717201613_fdb9a9828c_o.jpg',\n",
       " 'coarse_tilt_aligned_face.1195.11675766126_47529719f5_o.jpg',\n",
       " 'coarse_tilt_aligned_face.1206.11392426065_a7e278dedc_o.jpg',\n",
       " 'coarse_tilt_aligned_face.1206.11392429795_c174aecb8e_o.jpg',\n",
       " 'coarse_tilt_aligned_face.1206.11392438975_4bb2f9930e_o.jpg',\n",
       " 'coarse_tilt_aligned_face.1206.11392441406_04588640be_o.jpg',\n",
       " 'coarse_tilt_aligned_face.1206.11392442686_e1f7e34853_o.jpg',\n",
       " 'coarse_tilt_aligned_face.1206.11392445125_8072258b0c_o.jpg',\n",
       " 'coarse_tilt_aligned_face.1206.11392452765_fc1d7ccb2d_o.jpg',\n",
       " 'coarse_tilt_aligned_face.1206.11392456366_13ec8353c0_o.jpg',\n",
       " 'coarse_tilt_aligned_face.1206.11392463954_570f4f7bca_o.jpg',\n",
       " 'coarse_tilt_aligned_face.1206.11392474704_ae749021bd_o.jpg',\n",
       " 'coarse_tilt_aligned_face.1206.11392475666_e558834772_o.jpg',\n",
       " 'coarse_tilt_aligned_face.1206.11392476424_e5f8d65c89_o.jpg',\n",
       " 'coarse_tilt_aligned_face.1206.11392479345_5dca6c70cb_o.jpg',\n",
       " 'coarse_tilt_aligned_face.1206.11392480636_6b48151863_o.jpg',\n",
       " 'coarse_tilt_aligned_face.1206.11392487275_78ddfd60b4_o.jpg',\n",
       " 'coarse_tilt_aligned_face.1206.11392487754_e6b6df071b_o.jpg',\n",
       " 'coarse_tilt_aligned_face.1206.11392493486_9f6eeebf88_o.jpg',\n",
       " 'coarse_tilt_aligned_face.1206.11392494386_bb893a12c9_o.jpg',\n",
       " 'coarse_tilt_aligned_face.1206.11392498464_c8c5c8807f_o.jpg',\n",
       " 'coarse_tilt_aligned_face.1206.11392501054_65fd495a8a_o.jpg',\n",
       " 'coarse_tilt_aligned_face.1206.11392502106_73a107a4b7_o.jpg',\n",
       " 'coarse_tilt_aligned_face.1206.11392504144_7b8c1bb734_o.jpg',\n",
       " 'coarse_tilt_aligned_face.1206.11392510674_93f0ce923d_o.jpg',\n",
       " 'coarse_tilt_aligned_face.1206.11392573954_2d0c3a9e12_o.jpg',\n",
       " 'coarse_tilt_aligned_face.1206.11392585353_a89b3f5dcf_o.jpg',\n",
       " 'coarse_tilt_aligned_face.1206.11392595283_a79417f74c_o.jpg',\n",
       " 'coarse_tilt_aligned_face.1206.11392598293_d20e590a81_o.jpg',\n",
       " 'coarse_tilt_aligned_face.1207.11392424735_ec9651311e_o.jpg',\n",
       " 'coarse_tilt_aligned_face.1207.11392429795_c174aecb8e_o.jpg',\n",
       " 'coarse_tilt_aligned_face.1207.11392438975_4bb2f9930e_o.jpg',\n",
       " 'coarse_tilt_aligned_face.1207.11392441406_04588640be_o.jpg',\n",
       " 'coarse_tilt_aligned_face.1207.11392445125_8072258b0c_o.jpg',\n",
       " 'coarse_tilt_aligned_face.1207.11392456366_13ec8353c0_o.jpg',\n",
       " 'coarse_tilt_aligned_face.1207.11392464445_96a446057d_o.jpg',\n",
       " 'coarse_tilt_aligned_face.1207.11392465676_7ae08167f2_o.jpg',\n",
       " 'coarse_tilt_aligned_face.1207.11392474704_ae749021bd_o.jpg',\n",
       " 'coarse_tilt_aligned_face.1207.11392476424_e5f8d65c89_o.jpg',\n",
       " 'coarse_tilt_aligned_face.1207.11392487275_78ddfd60b4_o.jpg',\n",
       " 'coarse_tilt_aligned_face.1207.11392487754_e6b6df071b_o.jpg',\n",
       " 'coarse_tilt_aligned_face.1207.11392493486_9f6eeebf88_o.jpg',\n",
       " 'coarse_tilt_aligned_face.1207.11392494386_bb893a12c9_o.jpg',\n",
       " 'coarse_tilt_aligned_face.1207.11392570133_e0584c1d10_o.jpg',\n",
       " 'coarse_tilt_aligned_face.1207.11392571094_6163db0882_o.jpg',\n",
       " 'coarse_tilt_aligned_face.1207.11392585353_a89b3f5dcf_o.jpg',\n",
       " 'coarse_tilt_aligned_face.1207.11392672263_89f8accd35_o.jpg',\n",
       " 'coarse_tilt_aligned_face.1208.11392465676_7ae08167f2_o.jpg',\n",
       " 'coarse_tilt_aligned_face.1209.11392566354_31ea04551a_o.jpg',\n",
       " 'coarse_tilt_aligned_face.1210.11392464445_96a446057d_o.jpg',\n",
       " 'coarse_tilt_aligned_face.1210.11392598293_d20e590a81_o.jpg',\n",
       " 'coarse_tilt_aligned_face.1211.11392573954_2d0c3a9e12_o.jpg',\n",
       " 'coarse_tilt_aligned_face.1212.11392573954_2d0c3a9e12_o.jpg',\n",
       " 'coarse_tilt_aligned_face.1213.11392501054_65fd495a8a_o.jpg',\n",
       " 'coarse_tilt_aligned_face.1214.11392501054_65fd495a8a_o.jpg',\n",
       " 'coarse_tilt_aligned_face.1215.11392493486_9f6eeebf88_o.jpg',\n",
       " 'coarse_tilt_aligned_face.1215.11392498464_c8c5c8807f_o.jpg',\n",
       " 'coarse_tilt_aligned_face.1216.11392498464_c8c5c8807f_o.jpg',\n",
       " 'coarse_tilt_aligned_face.1217.11392498464_c8c5c8807f_o.jpg',\n",
       " 'coarse_tilt_aligned_face.1218.11392569414_6c7494ff30_o.jpg',\n",
       " 'coarse_tilt_aligned_face.1219.11392475666_e558834772_o.jpg',\n",
       " 'coarse_tilt_aligned_face.1275.9073726088_8eca6712a6_o.jpg',\n",
       " 'coarse_tilt_aligned_face.1275.9073726988_ce29f43ae8_o.jpg',\n",
       " 'coarse_tilt_aligned_face.1276.9073726088_8eca6712a6_o.jpg',\n",
       " 'coarse_tilt_aligned_face.1276.9073726988_ce29f43ae8_o.jpg',\n",
       " 'coarse_tilt_aligned_face.1277.9073712582_6ca7b2c0af_o.jpg',\n",
       " 'coarse_tilt_aligned_face.1278.11641470503_4ccce9bce2_o.jpg',\n",
       " 'coarse_tilt_aligned_face.1278.11642179146_3f238d008a_o.jpg',\n",
       " 'coarse_tilt_aligned_face.1279.11641301605_421e3e1747_o.jpg',\n",
       " 'coarse_tilt_aligned_face.1280.11642186846_f5ef51287b_o.jpg',\n",
       " 'coarse_tilt_aligned_face.1281.11642186846_f5ef51287b_o.jpg',\n",
       " 'coarse_tilt_aligned_face.1282.11642179146_3f238d008a_o.jpg',\n",
       " 'coarse_tilt_aligned_face.1283.11599787095_3c316a250e_o.jpg',\n",
       " 'coarse_tilt_aligned_face.1284.11599787095_3c316a250e_o.jpg',\n",
       " 'coarse_tilt_aligned_face.1285.9073711768_3fe0f466fe_o.jpg',\n",
       " 'coarse_tilt_aligned_face.1286.11641281175_eb3229b4f3_o.jpg',\n",
       " 'coarse_tilt_aligned_face.1287.11603109103_fe5738fa86_o.jpg',\n",
       " 'coarse_tilt_aligned_face.1287.11641545144_1114a2dee3_o.jpg',\n",
       " 'coarse_tilt_aligned_face.1288.11603109103_fe5738fa86_o.jpg',\n",
       " 'coarse_tilt_aligned_face.1288.11641545144_1114a2dee3_o.jpg',\n",
       " 'coarse_tilt_aligned_face.1289.11642182316_9a09f944a3_o.jpg',\n",
       " 'coarse_tilt_aligned_face.1290.11641418305_f95f430cb7_o.jpg',\n",
       " 'coarse_tilt_aligned_face.1290.11642182316_9a09f944a3_o.jpg',\n",
       " 'coarse_tilt_aligned_face.1291.11600044173_f4097d5e10_o.jpg',\n",
       " 'coarse_tilt_aligned_face.1298.10716195165_73d4903180_o.jpg',\n",
       " 'coarse_tilt_aligned_face.1298.10716274184_7de972914e_o.jpg',\n",
       " 'coarse_tilt_aligned_face.1298.10716274534_d60d20a7ac_o.jpg',\n",
       " 'coarse_tilt_aligned_face.1298.10716288186_542c54faba_o.jpg',\n",
       " 'coarse_tilt_aligned_face.1298.10716473433_1b724d622c_o.jpg',\n",
       " 'coarse_tilt_aligned_face.1299.10716275954_2ee9de231f_o.jpg',\n",
       " 'coarse_tilt_aligned_face.1300.10716276474_d9ac2c8cd9_o.jpg',\n",
       " 'coarse_tilt_aligned_face.1301.10716276474_d9ac2c8cd9_o.jpg',\n",
       " 'coarse_tilt_aligned_face.1302.10716288026_60a33b2360_o.jpg',\n",
       " 'coarse_tilt_aligned_face.1302.10716288046_4b3d764606_o.jpg',\n",
       " 'coarse_tilt_aligned_face.1302.10716288136_d09246d94d_o.jpg',\n",
       " 'coarse_tilt_aligned_face.1302.10716288456_3fb1c66b83_o.jpg',\n",
       " 'coarse_tilt_aligned_face.1302.10716288576_a8cf119366_o.jpg',\n",
       " 'coarse_tilt_aligned_face.1302.10716288956_0bba11c0df_o.jpg',\n",
       " 'coarse_tilt_aligned_face.1302.10716289386_e0b4e255b0_o.jpg',\n",
       " 'coarse_tilt_aligned_face.1302.10716289736_3446e2122b_o.jpg',\n",
       " 'coarse_tilt_aligned_face.1302.10716474073_8c4aa7de02_o.jpg',\n",
       " 'coarse_tilt_aligned_face.1302.10716474633_bd07921efb_o.jpg',\n",
       " 'coarse_tilt_aligned_face.1309.11313777254_1ffd6fc1ae_o.jpg',\n",
       " 'coarse_tilt_aligned_face.1309.11313857873_03445cd7d1_o.jpg',\n",
       " 'coarse_tilt_aligned_face.1309.11313989556_54a05ba7c9_o.jpg',\n",
       " 'coarse_tilt_aligned_face.1309.11313997624_c423107888_o.jpg',\n",
       " 'coarse_tilt_aligned_face.1309.11314102376_4e42dd0c49_o.jpg',\n",
       " 'coarse_tilt_aligned_face.1309.11314305135_97b178a2ba_o.jpg',\n",
       " 'coarse_tilt_aligned_face.1309.11314668074_cd11c65e44_o.jpg',\n",
       " 'coarse_tilt_aligned_face.1310.11278760266_7698d5e952_o.jpg',\n",
       " 'coarse_tilt_aligned_face.1310.11278800334_04ca2fa619_o.jpg',\n",
       " 'coarse_tilt_aligned_face.1310.11278827484_7efb25e649_o.jpg',\n",
       " 'coarse_tilt_aligned_face.1311.11278385353_aa3286b998_o.jpg',\n",
       " 'coarse_tilt_aligned_face.1312.11278795125_191781f4fd_o.jpg',\n",
       " 'coarse_tilt_aligned_face.1312.11278903633_6cae5694bb_o.jpg',\n",
       " 'coarse_tilt_aligned_face.1312.11278912453_3d93248d05_o.jpg',\n",
       " 'coarse_tilt_aligned_face.1313.9922938755_50dfa22d0b_o.jpg',\n",
       " 'coarse_tilt_aligned_face.1313.9922995754_0bf72c599d_o.jpg',\n",
       " 'coarse_tilt_aligned_face.1313.9923006816_fe7bf3fbda_o.jpg',\n",
       " 'coarse_tilt_aligned_face.1317.10015661874_a5aa37e8e6_o.jpg',\n",
       " 'coarse_tilt_aligned_face.1317.10015670524_d20f65c86c_o.jpg',\n",
       " 'coarse_tilt_aligned_face.1317.10015676034_6a1f64c00a_o.jpg',\n",
       " 'coarse_tilt_aligned_face.1317.10015709095_9d994f87c0_o.jpg',\n",
       " 'coarse_tilt_aligned_face.1317.10015710295_81eb61f216_o.jpg',\n",
       " 'coarse_tilt_aligned_face.1317.10015724796_e877772d00_o.jpg',\n",
       " 'coarse_tilt_aligned_face.1317.10015728995_1fb87478ff_o.jpg',\n",
       " 'coarse_tilt_aligned_face.1317.10015731215_96942bf02b_o.jpg',\n",
       " 'coarse_tilt_aligned_face.1317.10015738326_b37eeb7108_o.jpg',\n",
       " 'coarse_tilt_aligned_face.1317.10015742546_dc0334b225_o.jpg',\n",
       " 'coarse_tilt_aligned_face.1317.10015748766_b9ea37f9ae_o.jpg',\n",
       " 'coarse_tilt_aligned_face.1317.10015797643_15d19acabb_o.jpg',\n",
       " 'coarse_tilt_aligned_face.1317.10283962954_367e6253f8_o.jpg',\n",
       " 'coarse_tilt_aligned_face.1317.10284077925_4aafbd8e08_o.jpg',\n",
       " 'coarse_tilt_aligned_face.1317.10284162384_8ae1139e3f_o.jpg',\n",
       " 'coarse_tilt_aligned_face.1317.10284187033_1734404158_o.jpg',\n",
       " 'coarse_tilt_aligned_face.1317.10284234964_77bfe3d631_o.jpg',\n",
       " 'coarse_tilt_aligned_face.1317.10284238426_ce339933f6_o.jpg',\n",
       " 'coarse_tilt_aligned_face.1317.10284241316_1507bbb5ee_o.jpg',\n",
       " 'coarse_tilt_aligned_face.1317.10284257956_a1cd702ae6_o.jpg',\n",
       " 'coarse_tilt_aligned_face.1317.10284274745_74652ec836_o.jpg',\n",
       " 'coarse_tilt_aligned_face.1317.10284275425_e1bd6ce984_o.jpg',\n",
       " 'coarse_tilt_aligned_face.1317.10284281586_1dfbca5b68_o.jpg',\n",
       " 'coarse_tilt_aligned_face.1317.10284295845_ac7ac26e4c_o.jpg',\n",
       " 'coarse_tilt_aligned_face.1317.10284309246_38b3b08312_o.jpg',\n",
       " 'coarse_tilt_aligned_face.1317.10284339366_20fd83ecd2_o.jpg',\n",
       " 'coarse_tilt_aligned_face.1317.10284379826_f7f70c9c22_o.jpg',\n",
       " 'coarse_tilt_aligned_face.1317.10284404833_0237c70957_o.jpg',\n",
       " 'coarse_tilt_aligned_face.1317.10286491024_ac53c8e080_o.jpg',\n",
       " 'coarse_tilt_aligned_face.1317.10286497874_9953289f03_o.jpg',\n",
       " 'coarse_tilt_aligned_face.1317.10286569876_5ae02449b7_o.jpg',\n",
       " 'coarse_tilt_aligned_face.1317.10286599596_47c69c032a_o.jpg',\n",
       " 'coarse_tilt_aligned_face.1317.10286610436_f8d822cd39_o.jpg',\n",
       " 'coarse_tilt_aligned_face.1317.10286611395_696b4cc377_o.jpg',\n",
       " 'coarse_tilt_aligned_face.1317.10286612955_748a43f97b_o.jpg',\n",
       " 'coarse_tilt_aligned_face.1317.10286700833_564a7ef475_o.jpg',\n",
       " 'coarse_tilt_aligned_face.1317.10286701583_7ed180fefe_o.jpg',\n",
       " 'coarse_tilt_aligned_face.1317.10286708733_7d5283f233_o.jpg',\n",
       " 'coarse_tilt_aligned_face.1317.10286716723_c599871fa3_o.jpg',\n",
       " 'coarse_tilt_aligned_face.1317.10398446334_f63b8124bc_o.jpg',\n",
       " 'coarse_tilt_aligned_face.1317.10398468876_5030735798_o.jpg',\n",
       " 'coarse_tilt_aligned_face.1317.10398473904_7f09975864_o.jpg',\n",
       " 'coarse_tilt_aligned_face.1317.10398475186_e19a0fed69_o.jpg',\n",
       " 'coarse_tilt_aligned_face.1317.10398481076_6e5f2c1981_o.jpg',\n",
       " 'coarse_tilt_aligned_face.1317.10398492586_8441d50d5d_o.jpg',\n",
       " 'coarse_tilt_aligned_face.1317.10398496754_b9847bef50_o.jpg',\n",
       " 'coarse_tilt_aligned_face.1317.10398502456_54ea784990_o.jpg',\n",
       " 'coarse_tilt_aligned_face.1317.10398505474_a242b02288_o.jpg',\n",
       " 'coarse_tilt_aligned_face.1317.10398517345_4fe0c316ac_o.jpg',\n",
       " 'coarse_tilt_aligned_face.1317.10398518155_3ba540b6e0_o.jpg',\n",
       " 'coarse_tilt_aligned_face.1317.10398519065_1b7a5a7eb2_o.jpg',\n",
       " 'coarse_tilt_aligned_face.1317.10398521715_cf4c0d4733_o.jpg',\n",
       " 'coarse_tilt_aligned_face.1317.10398533906_25bd5a06ba_o.jpg',\n",
       " 'coarse_tilt_aligned_face.1317.10398535036_7df4902c5e_o.jpg',\n",
       " 'coarse_tilt_aligned_face.1317.10398631953_7a2b51bc53_o.jpg',\n",
       " 'coarse_tilt_aligned_face.1317.10398634693_795db9cc87_o.jpg',\n",
       " 'coarse_tilt_aligned_face.1317.10398666273_9048f05ab0_o.jpg',\n",
       " 'coarse_tilt_aligned_face.1317.10398673163_ac93734617_o.jpg',\n",
       " 'coarse_tilt_aligned_face.1317.10398676643_4a8f322773_o.jpg',\n",
       " 'coarse_tilt_aligned_face.1317.10398677913_353ea34a06_o.jpg',\n",
       " 'coarse_tilt_aligned_face.1317.10531817455_5cb6a63805_o.jpg',\n",
       " 'coarse_tilt_aligned_face.1317.10531837125_933493fb5b_o.jpg',\n",
       " 'coarse_tilt_aligned_face.1317.10531838966_e5a9d7cf26_o.jpg',\n",
       " 'coarse_tilt_aligned_face.1317.10531839835_125564092b_o.jpg',\n",
       " 'coarse_tilt_aligned_face.1317.10531840735_255355fd59_o.jpg',\n",
       " 'coarse_tilt_aligned_face.1317.10531842435_70e627462c_o.jpg',\n",
       " 'coarse_tilt_aligned_face.1317.10531853576_5e07824a46_o.jpg',\n",
       " 'coarse_tilt_aligned_face.1317.10531863066_08cd0e1b0b_o.jpg',\n",
       " 'coarse_tilt_aligned_face.1317.10531866215_29aa9d0a14_o.jpg',\n",
       " 'coarse_tilt_aligned_face.1317.10531869244_d310ed9d64_o.jpg',\n",
       " 'coarse_tilt_aligned_face.1317.10531874794_6a7daf8a9b_o.jpg',\n",
       " 'coarse_tilt_aligned_face.1317.10531877164_4ebb7dd720_o.jpg',\n",
       " 'coarse_tilt_aligned_face.1317.10531883036_e2fabb419f_o.jpg',\n",
       " 'coarse_tilt_aligned_face.1317.10531884394_a1441a1f43_o.jpg',\n",
       " 'coarse_tilt_aligned_face.1317.10531886774_872f50d7da_o.jpg',\n",
       " 'coarse_tilt_aligned_face.1317.10531888526_153b4c00dc_o.jpg',\n",
       " 'coarse_tilt_aligned_face.1317.10531888534_696b8930e0_o.jpg',\n",
       " 'coarse_tilt_aligned_face.1317.10531889305_7683c1acc9_o.jpg',\n",
       " 'coarse_tilt_aligned_face.1317.10531892144_46c88b98a6_o.jpg',\n",
       " 'coarse_tilt_aligned_face.1317.10531907156_552dd19d39_o.jpg',\n",
       " 'coarse_tilt_aligned_face.1317.10531925444_9863f33ae6_o.jpg',\n",
       " 'coarse_tilt_aligned_face.1317.10531928864_1c4d5b138b_o.jpg',\n",
       " 'coarse_tilt_aligned_face.1317.10531929804_653d93ae39_o.jpg',\n",
       " 'coarse_tilt_aligned_face.1317.10531935014_a38200826b_o.jpg',\n",
       " 'coarse_tilt_aligned_face.1317.10531943604_74402a9bc9_o.jpg',\n",
       " 'coarse_tilt_aligned_face.1317.10532060963_f079c62a68_o.jpg',\n",
       " 'coarse_tilt_aligned_face.1317.10532061823_ac18b0fbb6_o.jpg',\n",
       " 'coarse_tilt_aligned_face.1317.10532072683_a89c383a56_o.jpg',\n",
       " 'coarse_tilt_aligned_face.1317.10532078443_fc29d88e27_o.jpg',\n",
       " 'coarse_tilt_aligned_face.1317.10532085263_0b1e3548e2_o.jpg',\n",
       " 'coarse_tilt_aligned_face.1317.10532086003_e5eeb02f55_o.jpg',\n",
       " 'coarse_tilt_aligned_face.1317.10532086843_c4aefdd9b4_o.jpg',\n",
       " 'coarse_tilt_aligned_face.1317.10532108503_ff84ac2650_o.jpg',\n",
       " 'coarse_tilt_aligned_face.1317.10532110203_b761bf34f5_o.jpg',\n",
       " 'coarse_tilt_aligned_face.1317.10532131063_8635d3067c_o.jpg',\n",
       " 'coarse_tilt_aligned_face.1317.10701444755_01b7e039ed_o.jpg',\n",
       " 'coarse_tilt_aligned_face.1317.10701473935_5bc9845efd_o.jpg',\n",
       " 'coarse_tilt_aligned_face.1317.10701483725_aa020ca920_o.jpg',\n",
       " 'coarse_tilt_aligned_face.1317.10701493415_da2f095f92_o.jpg',\n",
       " 'coarse_tilt_aligned_face.1317.10701494345_31499b7896_o.jpg',\n",
       " 'coarse_tilt_aligned_face.1317.10701495215_3f3db2ae92_o.jpg',\n",
       " 'coarse_tilt_aligned_face.1317.10701497834_25d60885ef_o.jpg',\n",
       " 'coarse_tilt_aligned_face.1317.10701499904_0358871301_o.jpg',\n",
       " 'coarse_tilt_aligned_face.1317.10701506254_cce3e11c00_o.jpg',\n",
       " 'coarse_tilt_aligned_face.1317.10701522035_8070814859_o.jpg',\n",
       " 'coarse_tilt_aligned_face.1317.10701524705_a6d3f7e3a2_o.jpg',\n",
       " 'coarse_tilt_aligned_face.1317.10701527295_7bc9b70db4_o.jpg',\n",
       " 'coarse_tilt_aligned_face.1317.10701531425_c44ba24d8f_o.jpg',\n",
       " 'coarse_tilt_aligned_face.1317.10701539154_58b197151f_o.jpg',\n",
       " 'coarse_tilt_aligned_face.1317.10701540054_3e5f57c6da_o.jpg',\n",
       " 'coarse_tilt_aligned_face.1317.10701547754_978035d85d_o.jpg',\n",
       " 'coarse_tilt_aligned_face.1317.10701554024_bf7c838a00_o.jpg',\n",
       " 'coarse_tilt_aligned_face.1317.10701554794_936029778c_o.jpg',\n",
       " 'coarse_tilt_aligned_face.1317.10701557936_d07bde171d_o.jpg',\n",
       " 'coarse_tilt_aligned_face.1317.10701560636_4753cf0d03_o.jpg',\n",
       " 'coarse_tilt_aligned_face.1317.10701570594_a52ee737cf_o.jpg',\n",
       " 'coarse_tilt_aligned_face.1317.10701572224_4692cd8f50_o.jpg',\n",
       " 'coarse_tilt_aligned_face.1317.10701576356_92233b7c75_o.jpg',\n",
       " 'coarse_tilt_aligned_face.1317.10701577034_ff6858d7fd_o.jpg',\n",
       " 'coarse_tilt_aligned_face.1317.10701582664_6924b69662_o.jpg',\n",
       " 'coarse_tilt_aligned_face.1317.10701602966_3c766bb592_o.jpg',\n",
       " 'coarse_tilt_aligned_face.1317.10701689813_6b330bb302_o.jpg',\n",
       " 'coarse_tilt_aligned_face.1317.10701690813_50236f3a65_o.jpg',\n",
       " 'coarse_tilt_aligned_face.1317.10701697023_75bd09de58_o.jpg',\n",
       " 'coarse_tilt_aligned_face.1317.10701706393_3031e35a42_o.jpg',\n",
       " 'coarse_tilt_aligned_face.1317.10701707173_857bc768d1_o.jpg',\n",
       " 'coarse_tilt_aligned_face.1317.10701722243_2ce70a7c79_o.jpg',\n",
       " 'coarse_tilt_aligned_face.1317.10701729133_9b74be645f_o.jpg',\n",
       " 'coarse_tilt_aligned_face.1317.10701732643_39bc0a4bdf_o.jpg',\n",
       " 'coarse_tilt_aligned_face.1317.10701736543_778440fc83_o.jpg',\n",
       " 'coarse_tilt_aligned_face.1317.10701747263_4a4cbfa022_o.jpg',\n",
       " 'coarse_tilt_aligned_face.1317.10701757903_5530092cf2_o.jpg',\n",
       " 'coarse_tilt_aligned_face.1317.10734287045_5f45894b6a_o.jpg',\n",
       " 'coarse_tilt_aligned_face.1317.10734296105_c3d9b7d32d_o.jpg',\n",
       " 'coarse_tilt_aligned_face.1317.10734299635_cb2e331799_o.jpg',\n",
       " 'coarse_tilt_aligned_face.1317.10734386474_c632ec7cc0_o.jpg',\n",
       " 'coarse_tilt_aligned_face.1317.10734387726_2c868de5d5_o.jpg',\n",
       " 'coarse_tilt_aligned_face.1317.10734389554_41b0aab031_o.jpg',\n",
       " 'coarse_tilt_aligned_face.1317.10734390864_910049bac7_o.jpg',\n",
       " 'coarse_tilt_aligned_face.1317.10734392296_ec86668c48_o.jpg',\n",
       " 'coarse_tilt_aligned_face.1317.10734394004_cf12c43e4b_o.jpg',\n",
       " 'coarse_tilt_aligned_face.1317.10734399574_8eaaf3058b_o.jpg',\n",
       " 'coarse_tilt_aligned_face.1317.10734592183_e24213cd7e_o.jpg',\n",
       " 'coarse_tilt_aligned_face.1317.10734594303_7a88591235_o.jpg',\n",
       " 'coarse_tilt_aligned_face.1317.10734600543_3d99eeda7c_o.jpg',\n",
       " 'coarse_tilt_aligned_face.1317.10734601463_bb310e619f_o.jpg',\n",
       " 'coarse_tilt_aligned_face.1317.10834891545_a806c275bf_o.jpg',\n",
       " 'coarse_tilt_aligned_face.1317.10834903665_c83e19d4da_o.jpg',\n",
       " 'coarse_tilt_aligned_face.1317.10834940765_2fce3d1943_o.jpg',\n",
       " 'coarse_tilt_aligned_face.1317.10834944065_75d5bc020b_o.jpg',\n",
       " 'coarse_tilt_aligned_face.1317.10834950105_5f6ede6707_o.jpg',\n",
       " 'coarse_tilt_aligned_face.1317.10834958976_25a55ab1bc_o.jpg',\n",
       " 'coarse_tilt_aligned_face.1317.10834961296_0db8d24df6_o.jpg',\n",
       " 'coarse_tilt_aligned_face.1317.10834963746_cd5e519b08_o.jpg',\n",
       " 'coarse_tilt_aligned_face.1317.10834999616_572a4bbd3a_o.jpg',\n",
       " 'coarse_tilt_aligned_face.1317.10835009096_0ca7901717_o.jpg',\n",
       " 'coarse_tilt_aligned_face.1317.10835071824_ab9fd19b13_o.jpg',\n",
       " 'coarse_tilt_aligned_face.1317.10835078734_5a7137b509_o.jpg',\n",
       " 'coarse_tilt_aligned_face.1317.10835225033_f55963f25f_o.jpg',\n",
       " 'coarse_tilt_aligned_face.1317.10835225673_d83891423c_o.jpg',\n",
       " 'coarse_tilt_aligned_face.1317.10835231033_46bb057c90_o.jpg',\n",
       " 'coarse_tilt_aligned_face.1317.10835273883_ff7042e1dd_o.jpg',\n",
       " 'coarse_tilt_aligned_face.1317.10835274603_7d947bd7df_o.jpg',\n",
       " 'coarse_tilt_aligned_face.1317.10935898815_fa09b26127_o.jpg',\n",
       " 'coarse_tilt_aligned_face.1317.10935903185_10fd8ec4ac_o.jpg',\n",
       " 'coarse_tilt_aligned_face.1317.10935917525_b5d193b4ec_o.jpg',\n",
       " 'coarse_tilt_aligned_face.1317.10935969566_9e66b9d6f9_o.jpg',\n",
       " 'coarse_tilt_aligned_face.1317.10935974845_edc8f1ccf5_o.jpg',\n",
       " 'coarse_tilt_aligned_face.1317.10935975665_bec90e09c7_o.jpg',\n",
       " 'coarse_tilt_aligned_face.1317.10935976856_22a8ca19b6_o.jpg',\n",
       " 'coarse_tilt_aligned_face.1317.10935981166_dabaa7b0a5_o.jpg',\n",
       " 'coarse_tilt_aligned_face.1317.10935983456_7357000416_o.jpg',\n",
       " 'coarse_tilt_aligned_face.1317.10935984206_7cfda30a05_o.jpg',\n",
       " 'coarse_tilt_aligned_face.1317.10935986826_f05c3721bc_o.jpg',\n",
       " 'coarse_tilt_aligned_face.1317.10936002915_c4d7b5da65_o.jpg',\n",
       " 'coarse_tilt_aligned_face.1317.10936047054_c728c3fed9_o.jpg',\n",
       " 'coarse_tilt_aligned_face.1317.10936050806_f87b1bdb8e_o.jpg',\n",
       " 'coarse_tilt_aligned_face.1317.10936062824_e27a2751d4_o.jpg',\n",
       " 'coarse_tilt_aligned_face.1317.10936075114_4a66e4f21d_o.jpg',\n",
       " 'coarse_tilt_aligned_face.1317.10936116894_afa59d6647_o.jpg',\n",
       " 'coarse_tilt_aligned_face.1317.10936121005_e969a0c7ea_o.jpg',\n",
       " 'coarse_tilt_aligned_face.1317.10936121725_b91db17b00_o.jpg',\n",
       " 'coarse_tilt_aligned_face.1317.10936129415_756f33b1c2_o.jpg',\n",
       " 'coarse_tilt_aligned_face.1317.10936137155_7a06bcd771_o.jpg',\n",
       " 'coarse_tilt_aligned_face.1317.10936137674_63b9a8bb40_o.jpg',\n",
       " 'coarse_tilt_aligned_face.1317.10936166556_e306dd3c13_o.jpg',\n",
       " 'coarse_tilt_aligned_face.1317.10936171336_ce29b1d0a6_o.jpg',\n",
       " 'coarse_tilt_aligned_face.1317.10936214296_719bab4d07_o.jpg',\n",
       " 'coarse_tilt_aligned_face.1317.10936257383_1d9e547278_o.jpg',\n",
       " 'coarse_tilt_aligned_face.1317.10936262743_ccecf16c39_o.jpg',\n",
       " 'coarse_tilt_aligned_face.1317.10936264993_37f9937577_o.jpg',\n",
       " 'coarse_tilt_aligned_face.1317.10936270174_d31369a995_o.jpg',\n",
       " 'coarse_tilt_aligned_face.1317.10936272654_256f869069_o.jpg',\n",
       " 'coarse_tilt_aligned_face.1317.10936280404_18c73f3af9_o.jpg',\n",
       " 'coarse_tilt_aligned_face.1317.10936281164_977397548b_o.jpg',\n",
       " 'coarse_tilt_aligned_face.1317.10936282904_2be32cfa79_o.jpg',\n",
       " 'coarse_tilt_aligned_face.1317.10936380563_f1b91e226d_o.jpg',\n",
       " 'coarse_tilt_aligned_face.1317.10936404173_f5a05fa7a2_o.jpg',\n",
       " 'coarse_tilt_aligned_face.1317.10936441523_6eac2e5457_o.jpg',\n",
       " 'coarse_tilt_aligned_face.1317.10936442373_695d56d608_o.jpg',\n",
       " 'coarse_tilt_aligned_face.1317.11041869415_463fa04643_o.jpg',\n",
       " 'coarse_tilt_aligned_face.1317.11041870595_dc8d7b613e_o.jpg',\n",
       " 'coarse_tilt_aligned_face.1317.11041882645_6e310118a9_o.jpg',\n",
       " 'coarse_tilt_aligned_face.1317.11041887455_16084e9946_o.jpg',\n",
       " 'coarse_tilt_aligned_face.1317.11041890805_8dfc0c5f55_o.jpg',\n",
       " 'coarse_tilt_aligned_face.1317.11041891765_1d9aed7540_o.jpg',\n",
       " 'coarse_tilt_aligned_face.1317.11041895735_50c547da68_o.jpg',\n",
       " 'coarse_tilt_aligned_face.1317.11041902176_c56ee436d2_o.jpg',\n",
       " 'coarse_tilt_aligned_face.1317.11041904215_aa9fe0357c_o.jpg',\n",
       " 'coarse_tilt_aligned_face.1317.11041915015_bc59ebdf6b_o.jpg',\n",
       " 'coarse_tilt_aligned_face.1317.11041921766_c5da0db4a9_o.jpg',\n",
       " 'coarse_tilt_aligned_face.1317.11041944684_75b5d9ae07_o.jpg',\n",
       " 'coarse_tilt_aligned_face.1317.11041961394_7335859c5e_o.jpg',\n",
       " 'coarse_tilt_aligned_face.1317.11041977466_ea6d58c972_o.jpg',\n",
       " 'coarse_tilt_aligned_face.1317.11041982336_e8abdc1194_o.jpg',\n",
       " 'coarse_tilt_aligned_face.1317.11041996106_39ae97a0e7_o.jpg',\n",
       " 'coarse_tilt_aligned_face.1317.11041999733_1a2bc1504d_o.jpg',\n",
       " 'coarse_tilt_aligned_face.1317.11042013294_5d193bf80b_o.jpg',\n",
       " 'coarse_tilt_aligned_face.1317.11042025164_2be9731231_o.jpg',\n",
       " 'coarse_tilt_aligned_face.1317.11042027034_118fabfa6a_o.jpg',\n",
       " 'coarse_tilt_aligned_face.1317.11042033334_450b6656fc_o.jpg',\n",
       " 'coarse_tilt_aligned_face.1317.11042059953_c2f311994a_o.jpg',\n",
       " 'coarse_tilt_aligned_face.1317.11042063563_45f62e6174_o.jpg',\n",
       " 'coarse_tilt_aligned_face.1317.11042084723_c5c5bf83de_o.jpg',\n",
       " 'coarse_tilt_aligned_face.1317.11042088473_5b8d28283f_o.jpg',\n",
       " 'coarse_tilt_aligned_face.1317.11042105023_4c540919dc_o.jpg',\n",
       " 'coarse_tilt_aligned_face.1317.11164183725_47d266b838_o.jpg',\n",
       " 'coarse_tilt_aligned_face.1317.11164184645_b979bffe05_o.jpg',\n",
       " 'coarse_tilt_aligned_face.1317.11164188765_ee78c717e7_o.jpg',\n",
       " 'coarse_tilt_aligned_face.1317.11164239544_a721373a83_o.jpg',\n",
       " 'coarse_tilt_aligned_face.1317.11164242014_01ee6f69f4_o.jpg',\n",
       " 'coarse_tilt_aligned_face.1317.11164282035_c9d3aa1ec3_o.jpg',\n",
       " 'coarse_tilt_aligned_face.1317.11164296665_2d6a7d43ec_o.jpg',\n",
       " 'coarse_tilt_aligned_face.1317.11164297495_12ebdb8f50_o.jpg',\n",
       " 'coarse_tilt_aligned_face.1317.11164324506_a8408a75e5_o.jpg',\n",
       " 'coarse_tilt_aligned_face.1317.11164337234_6429b61967_o.jpg',\n",
       " 'coarse_tilt_aligned_face.1317.11164354023_d09c3522f6_o.jpg',\n",
       " 'coarse_tilt_aligned_face.1317.11164355043_65d3cb3a01_o.jpg',\n",
       " 'coarse_tilt_aligned_face.1317.11164366573_a4dfc32f23_o.jpg',\n",
       " 'coarse_tilt_aligned_face.1317.11164475013_f9e0b297a2_o.jpg',\n",
       " 'coarse_tilt_aligned_face.1317.11164477153_cbfcfeb21c_o.jpg',\n",
       " 'coarse_tilt_aligned_face.1317.11285937695_3f9b3b22e6_o.jpg',\n",
       " 'coarse_tilt_aligned_face.1317.11285939345_5bdbdcc400_o.jpg',\n",
       " 'coarse_tilt_aligned_face.1317.11285961326_93a95353a2_o.jpg',\n",
       " 'coarse_tilt_aligned_face.1317.11285961986_082cfb5265_o.jpg',\n",
       " 'coarse_tilt_aligned_face.1317.11285963606_8ef8eaeaf0_o.jpg',\n",
       " 'coarse_tilt_aligned_face.1317.11286012516_f7c398b3f9_o.jpg',\n",
       " 'coarse_tilt_aligned_face.1317.11286022574_651625f0c8_o.jpg',\n",
       " 'coarse_tilt_aligned_face.1317.11286024254_fa2dfe6dee_o.jpg',\n",
       " 'coarse_tilt_aligned_face.1317.11286031763_ff08a7a748_o.jpg',\n",
       " 'coarse_tilt_aligned_face.1317.11286032334_9b6b389f83_o.jpg',\n",
       " 'coarse_tilt_aligned_face.1317.11286033846_74092954af_o.jpg',\n",
       " 'coarse_tilt_aligned_face.1317.11286045674_d2cd456f35_o.jpg',\n",
       " 'coarse_tilt_aligned_face.1317.11286069233_9b622eecbf_o.jpg',\n",
       " 'coarse_tilt_aligned_face.1317.11286099623_7c52bb7f06_o.jpg',\n",
       " 'coarse_tilt_aligned_face.1317.11286100393_cace4a6d31_o.jpg',\n",
       " 'coarse_tilt_aligned_face.1317.11399596665_c0cbd011e0_o.jpg',\n",
       " 'coarse_tilt_aligned_face.1317.11399605055_2b5f23544c_o.jpg',\n",
       " 'coarse_tilt_aligned_face.1317.11399607805_c754bb2a10_o.jpg',\n",
       " 'coarse_tilt_aligned_face.1317.11399609125_3b9d780c49_o.jpg',\n",
       " 'coarse_tilt_aligned_face.1317.11399612706_7083606421_o.jpg',\n",
       " 'coarse_tilt_aligned_face.1317.11399613304_79691a1594_o.jpg',\n",
       " 'coarse_tilt_aligned_face.1317.11399615064_521a8088c8_o.jpg',\n",
       " 'coarse_tilt_aligned_face.1317.11399615556_c2c549d855_o.jpg',\n",
       " 'coarse_tilt_aligned_face.1317.11399626684_2ffe2b4077_o.jpg',\n",
       " 'coarse_tilt_aligned_face.1317.11399628114_1e0c7e7e81_o.jpg',\n",
       " 'coarse_tilt_aligned_face.1317.11399710843_d963ca5aed_o.jpg',\n",
       " 'coarse_tilt_aligned_face.1317.11399729263_6a985b9e44_o.jpg',\n",
       " 'coarse_tilt_aligned_face.1317.11510329225_2eabcfce98_o.jpg',\n",
       " 'coarse_tilt_aligned_face.1317.11510340555_97b6803199_o.jpg',\n",
       " 'coarse_tilt_aligned_face.1317.11510344155_ec2d7aee60_o.jpg',\n",
       " 'coarse_tilt_aligned_face.1317.11510345795_9cae76ba05_o.jpg',\n",
       " 'coarse_tilt_aligned_face.1317.11510346545_931d909b0e_o.jpg',\n",
       " 'coarse_tilt_aligned_face.1317.11510350605_ef68d863fa_o.jpg',\n",
       " 'coarse_tilt_aligned_face.1317.11510356525_5a6ea5e918_o.jpg',\n",
       " 'coarse_tilt_aligned_face.1317.11510360515_b0d3238aaa_o.jpg',\n",
       " 'coarse_tilt_aligned_face.1317.11510363835_814fdbffbd_o.jpg',\n",
       " 'coarse_tilt_aligned_face.1317.11510364205_958d800f18_o.jpg',\n",
       " 'coarse_tilt_aligned_face.1317.11510365645_7ee410f66f_o.jpg',\n",
       " 'coarse_tilt_aligned_face.1317.11510366964_3fd17b2cda_o.jpg',\n",
       " 'coarse_tilt_aligned_face.1317.11510368785_054e230a3b_o.jpg',\n",
       " 'coarse_tilt_aligned_face.1317.11510369785_ab889420fe_o.jpg',\n",
       " 'coarse_tilt_aligned_face.1317.11510374515_3339c68ae9_o.jpg',\n",
       " 'coarse_tilt_aligned_face.1317.11510377814_f78753ecdf_o.jpg',\n",
       " 'coarse_tilt_aligned_face.1317.11510380844_3496d412a7_o.jpg',\n",
       " 'coarse_tilt_aligned_face.1317.11510384035_e269b5e3fb_o.jpg',\n",
       " 'coarse_tilt_aligned_face.1317.11510385484_a2d3f419af_o.jpg',\n",
       " 'coarse_tilt_aligned_face.1317.11510402414_b7dc5bb87e_o.jpg',\n",
       " 'coarse_tilt_aligned_face.1317.11510409254_d29a3c047b_o.jpg',\n",
       " 'coarse_tilt_aligned_face.1317.11510410144_e6829e864a_o.jpg',\n",
       " 'coarse_tilt_aligned_face.1317.11510411463_d850128996_o.jpg',\n",
       " 'coarse_tilt_aligned_face.1317.11510414903_99fcd120c8_o.jpg',\n",
       " 'coarse_tilt_aligned_face.1317.11510415576_4d5d536bb4_o.jpg',\n",
       " 'coarse_tilt_aligned_face.1317.11510422234_fef5205eaf_o.jpg',\n",
       " 'coarse_tilt_aligned_face.1317.11510438296_b80be6142d_o.jpg',\n",
       " 'coarse_tilt_aligned_face.1317.11510446916_4dfdd73f67_o.jpg',\n",
       " 'coarse_tilt_aligned_face.1317.11510455856_c19168bdb9_o.jpg',\n",
       " 'coarse_tilt_aligned_face.1317.11510457503_aea48983d1_o.jpg',\n",
       " 'coarse_tilt_aligned_face.1317.11510459083_82efeb5e91_o.jpg',\n",
       " 'coarse_tilt_aligned_face.1317.11510462346_01124fa29c_o.jpg',\n",
       " 'coarse_tilt_aligned_face.1317.11510464576_7644001cf3_o.jpg',\n",
       " 'coarse_tilt_aligned_face.1317.11510468773_eb79b4ee98_o.jpg',\n",
       " 'coarse_tilt_aligned_face.1317.11510468973_21411007be_o.jpg',\n",
       " 'coarse_tilt_aligned_face.1317.11581359525_4586bc2a5a_o.jpg',\n",
       " 'coarse_tilt_aligned_face.1317.11705058725_bf0a4deab6_o.jpg',\n",
       " 'coarse_tilt_aligned_face.1317.11705060715_1b3050c97f_o.jpg',\n",
       " 'coarse_tilt_aligned_face.1317.11705187845_71bb2e2b9f_o.jpg',\n",
       " 'coarse_tilt_aligned_face.1317.11705285583_b4e1e63765_o.jpg',\n",
       " 'coarse_tilt_aligned_face.1317.11705291573_025ca31bab_o.jpg',\n",
       " 'coarse_tilt_aligned_face.1317.11705337634_31d55de8cd_o.jpg',\n",
       " 'coarse_tilt_aligned_face.1317.11705422524_635f9cc4bf_o.jpg',\n",
       " 'coarse_tilt_aligned_face.1317.11705557124_f308b4b605_o.jpg',\n",
       " 'coarse_tilt_aligned_face.1317.11705559224_da393c2879_o.jpg',\n",
       " 'coarse_tilt_aligned_face.1317.11705818846_78a4608d29_o.jpg',\n",
       " 'coarse_tilt_aligned_face.1317.11705938206_80c350f2fb_o.jpg',\n",
       " 'coarse_tilt_aligned_face.1317.11811841733_7736934b09_o.jpg',\n",
       " 'coarse_tilt_aligned_face.1317.11811843353_2beec9f476_o.jpg',\n",
       " 'coarse_tilt_aligned_face.1317.11812334546_c77f94a534_o.jpg',\n",
       " 'coarse_tilt_aligned_face.1317.11812335826_771e6fec9c_o.jpg',\n",
       " 'coarse_tilt_aligned_face.1317.11923348495_8282bba292_o.jpg',\n",
       " 'coarse_tilt_aligned_face.1317.11923354235_68c39fbc1d_o.jpg',\n",
       " 'coarse_tilt_aligned_face.1317.11923388535_048b2ed202_o.jpg',\n",
       " 'coarse_tilt_aligned_face.1317.11923660733_d30ec29df9_o.jpg',\n",
       " 'coarse_tilt_aligned_face.1317.11923800814_aab593b411_o.jpg',\n",
       " 'coarse_tilt_aligned_face.1317.11923850094_c030945209_o.jpg',\n",
       " 'coarse_tilt_aligned_face.1317.11924256816_18930c7fd4_o.jpg',\n",
       " 'coarse_tilt_aligned_face.1317.9660114691_930b277e3e_o.jpg',\n",
       " 'coarse_tilt_aligned_face.1317.9709052574_f51a7ce775_o.jpg',\n",
       " 'coarse_tilt_aligned_face.1317.9709070222_0d180eb3c7_o.jpg',\n",
       " 'coarse_tilt_aligned_face.1317.9709082628_9f1075d8ae_o.jpg',\n",
       " 'coarse_tilt_aligned_face.1317.9709082848_719bfd6fee_o.jpg',\n",
       " 'coarse_tilt_aligned_face.1317.9709083230_b074e459b1_o.jpg',\n",
       " 'coarse_tilt_aligned_face.1317.9767518631_71261193e8_o.jpg',\n",
       " 'coarse_tilt_aligned_face.1317.9767521622_2740ba9306_o.jpg',\n",
       " 'coarse_tilt_aligned_face.1317.9767523662_981ca7d501_o.jpg',\n",
       " 'coarse_tilt_aligned_face.1317.9767553951_82c00ccfa5_o.jpg',\n",
       " 'coarse_tilt_aligned_face.1317.9767560531_70325c1da6_o.jpg',\n",
       " 'coarse_tilt_aligned_face.1317.9767564331_27e66b858e_o.jpg',\n",
       " 'coarse_tilt_aligned_face.1317.9767729905_9d20c241d5_o.jpg',\n",
       " 'coarse_tilt_aligned_face.1317.9767738694_e35f264e24_o.jpg',\n",
       " 'coarse_tilt_aligned_face.1317.9767762355_a78d86aae7_o.jpg',\n",
       " 'coarse_tilt_aligned_face.1317.9767775186_327f3bde32_o.jpg',\n",
       " 'coarse_tilt_aligned_face.1317.9767775744_f8cb77a796_o.jpg',\n",
       " 'coarse_tilt_aligned_face.1317.9767776324_02cfb5c28f_o.jpg',\n",
       " 'coarse_tilt_aligned_face.1317.9767778096_b9ff679fb8_o.jpg',\n",
       " 'coarse_tilt_aligned_face.1317.9767782125_a8c95d607e_o.jpg',\n",
       " 'coarse_tilt_aligned_face.1317.9767816454_05dd4688f8_o.jpg',\n",
       " 'coarse_tilt_aligned_face.1317.9767823486_28c2161802_o.jpg',\n",
       " 'coarse_tilt_aligned_face.1317.9767850613_0a46f1e406_o.jpg',\n",
       " 'coarse_tilt_aligned_face.1317.9892086174_c71d8855b2_o.jpg',\n",
       " 'coarse_tilt_aligned_face.1317.9892091925_ae1ae346a9_o.jpg',\n",
       " 'coarse_tilt_aligned_face.1317.9892098925_a1160bbf78_o.jpg',\n",
       " 'coarse_tilt_aligned_face.1317.9892106726_3c77c63e40_o.jpg',\n",
       " 'coarse_tilt_aligned_face.1317.9892108546_1325075c37_o.jpg',\n",
       " 'coarse_tilt_aligned_face.1317.9892110695_e0b0784df4_o.jpg',\n",
       " 'coarse_tilt_aligned_face.1317.9892113435_ffa5223db7_o.jpg',\n",
       " 'coarse_tilt_aligned_face.1317.9892114434_f2acbf753e_o.jpg',\n",
       " 'coarse_tilt_aligned_face.1317.9892118394_00489beec9_o.jpg',\n",
       " 'coarse_tilt_aligned_face.1317.9892118586_cd59d4016e_o.jpg',\n",
       " 'coarse_tilt_aligned_face.1317.9892119835_ebc6fb5471_o.jpg',\n",
       " 'coarse_tilt_aligned_face.1317.9892123364_d31690baa2_o.jpg',\n",
       " 'coarse_tilt_aligned_face.1317.9892127456_a7216c7698_o.jpg',\n",
       " 'coarse_tilt_aligned_face.1317.9892140614_25e4596ccb_o.jpg',\n",
       " 'coarse_tilt_aligned_face.1317.9892141195_74c8a6281a_o.jpg',\n",
       " 'coarse_tilt_aligned_face.1317.9892143014_66902c67d8_o.jpg',\n",
       " 'coarse_tilt_aligned_face.1317.9892145526_e431b75baa_o.jpg',\n",
       " 'coarse_tilt_aligned_face.1317.9892148434_611007e07b_o.jpg',\n",
       " 'coarse_tilt_aligned_face.1317.9892150264_4025b3fe5d_o.jpg',\n",
       " 'coarse_tilt_aligned_face.1317.9892150425_43012056ac_o.jpg',\n",
       " 'coarse_tilt_aligned_face.1317.9892155894_f1c1867b97_o.jpg',\n",
       " 'coarse_tilt_aligned_face.1317.9892167684_b48718dda1_o.jpg',\n",
       " 'coarse_tilt_aligned_face.1317.9892171576_3298bc719c_o.jpg',\n",
       " 'coarse_tilt_aligned_face.1317.9892177674_0fb4f59c7a_o.jpg',\n",
       " 'coarse_tilt_aligned_face.1317.9892187754_df039f6e25_o.jpg',\n",
       " 'coarse_tilt_aligned_face.1317.9892189155_7c07c1fa16_o.jpg',\n",
       " 'coarse_tilt_aligned_face.1317.9892192755_7cc8da63ef_o.jpg',\n",
       " 'coarse_tilt_aligned_face.1317.9892194425_26470db33a_o.jpg',\n",
       " 'coarse_tilt_aligned_face.1317.9892216934_5f54e7aac5_o.jpg',\n",
       " 'coarse_tilt_aligned_face.1317.9892222994_3af06c74ee_o.jpg',\n",
       " 'coarse_tilt_aligned_face.1317.9892225543_43823d6bfe_o.jpg',\n",
       " 'coarse_tilt_aligned_face.1317.9892238283_fa482195c3_o.jpg',\n",
       " 'coarse_tilt_aligned_face.1317.9892258983_4e871c7134_o.jpg',\n",
       " 'coarse_tilt_aligned_face.1317.9892275063_8c5c893e89_o.jpg',\n",
       " 'coarse_tilt_aligned_face.1317.9892277043_03404b11b5_o.jpg',\n",
       " 'coarse_tilt_aligned_face.1317.9892320683_b3966062fc_o.jpg',\n",
       " 'coarse_tilt_aligned_face.1317.9962664795_f557394c59_o.jpg',\n",
       " 'coarse_tilt_aligned_face.1317.9962678185_f2c48fec86_o.jpg',\n",
       " 'coarse_tilt_aligned_face.1317.9962681035_79c1e003ed_o.jpg',\n",
       " 'coarse_tilt_aligned_face.1317.9962681985_c8256244dc_o.jpg',\n",
       " 'coarse_tilt_aligned_face.1317.9962692174_6b60308074_o.jpg',\n",
       " 'coarse_tilt_aligned_face.1317.9962706694_c76a059c2b_o.jpg',\n",
       " 'coarse_tilt_aligned_face.1317.9962736556_1b408b8fe2_o.jpg',\n",
       " 'coarse_tilt_aligned_face.1317.9962740176_72155b4c20_o.jpg',\n",
       " 'coarse_tilt_aligned_face.1317.9962745116_1c3bd50824_o.jpg',\n",
       " 'coarse_tilt_aligned_face.1317.9962796373_1ed1878ccc_o.jpg',\n",
       " 'coarse_tilt_aligned_face.1317.9962799673_210025fd96_o.jpg',\n",
       " 'coarse_tilt_aligned_face.1317.9962804693_a0264e34c9_o.jpg',\n",
       " 'coarse_tilt_aligned_face.1317.9962806923_00603b0891_o.jpg',\n",
       " 'coarse_tilt_aligned_face.1317.9962807593_b701a9631c_o.jpg',\n",
       " 'coarse_tilt_aligned_face.1318.10015661874_a5aa37e8e6_o.jpg',\n",
       " 'coarse_tilt_aligned_face.1318.10015723825_994158f693_o.jpg',\n",
       " 'coarse_tilt_aligned_face.1318.10286497874_9953289f03_o.jpg',\n",
       " 'coarse_tilt_aligned_face.1318.10286569876_5ae02449b7_o.jpg',\n",
       " 'coarse_tilt_aligned_face.1318.10286700833_564a7ef475_o.jpg',\n",
       " 'coarse_tilt_aligned_face.1318.10286701583_7ed180fefe_o.jpg',\n",
       " 'coarse_tilt_aligned_face.1318.10286708733_7d5283f233_o.jpg',\n",
       " 'coarse_tilt_aligned_face.1318.10286738103_e86fc108a3_o.jpg',\n",
       " 'coarse_tilt_aligned_face.1318.10286739513_9d1a0dcdfa_o.jpg',\n",
       " 'coarse_tilt_aligned_face.1318.10935917525_b5d193b4ec_o.jpg',\n",
       " 'coarse_tilt_aligned_face.1318.10935930185_4f2a102d8d_o.jpg',\n",
       " 'coarse_tilt_aligned_face.1318.10935935185_1732b7256f_o.jpg',\n",
       " 'coarse_tilt_aligned_face.1318.10935976856_22a8ca19b6_o.jpg',\n",
       " 'coarse_tilt_aligned_face.1318.10935978815_04396a796a_o.jpg',\n",
       " 'coarse_tilt_aligned_face.1318.10935981166_dabaa7b0a5_o.jpg',\n",
       " 'coarse_tilt_aligned_face.1318.10935983456_7357000416_o.jpg',\n",
       " 'coarse_tilt_aligned_face.1318.10935984206_7cfda30a05_o.jpg',\n",
       " 'coarse_tilt_aligned_face.1318.10935986056_0309e1b2cf_o.jpg',\n",
       " 'coarse_tilt_aligned_face.1318.10935986826_f05c3721bc_o.jpg',\n",
       " 'coarse_tilt_aligned_face.1318.10935990786_f7264cdaaf_o.jpg',\n",
       " 'coarse_tilt_aligned_face.1318.10935994746_82187055bc_o.jpg',\n",
       " 'coarse_tilt_aligned_face.1318.10936002915_c4d7b5da65_o.jpg',\n",
       " 'coarse_tilt_aligned_face.1318.10936018445_f843314fc6_o.jpg',\n",
       " 'coarse_tilt_aligned_face.1318.10936050806_f87b1bdb8e_o.jpg',\n",
       " 'coarse_tilt_aligned_face.1318.10936058176_c79a74dbcd_o.jpg',\n",
       " 'coarse_tilt_aligned_face.1318.10936061834_8ceea6b3bb_o.jpg',\n",
       " 'coarse_tilt_aligned_face.1318.10936062824_e27a2751d4_o.jpg',\n",
       " 'coarse_tilt_aligned_face.1318.10936075114_4a66e4f21d_o.jpg',\n",
       " 'coarse_tilt_aligned_face.1318.10936123024_6b5152b705_o.jpg',\n",
       " 'coarse_tilt_aligned_face.1318.10936124144_9100321ef2_o.jpg',\n",
       " 'coarse_tilt_aligned_face.1318.10936137674_63b9a8bb40_o.jpg',\n",
       " 'coarse_tilt_aligned_face.1318.10936188403_091dd60345_o.jpg',\n",
       " 'coarse_tilt_aligned_face.1318.10936197013_94ea99f174_o.jpg',\n",
       " 'coarse_tilt_aligned_face.1318.10936197763_ca89071058_o.jpg',\n",
       " 'coarse_tilt_aligned_face.1318.10936261593_af8c422d82_o.jpg',\n",
       " 'coarse_tilt_aligned_face.1318.10936266213_cba830b57b_o.jpg',\n",
       " 'coarse_tilt_aligned_face.1318.11164183725_47d266b838_o.jpg',\n",
       " 'coarse_tilt_aligned_face.1318.11164184645_b979bffe05_o.jpg',\n",
       " 'coarse_tilt_aligned_face.1318.11164224714_60c0a34898_o.jpg',\n",
       " 'coarse_tilt_aligned_face.1318.11164227734_6ae6aea28d_o.jpg',\n",
       " 'coarse_tilt_aligned_face.1318.11164239544_a721373a83_o.jpg',\n",
       " 'coarse_tilt_aligned_face.1318.11164365163_51e44860f3_o.jpg',\n",
       " 'coarse_tilt_aligned_face.1318.11164366573_a4dfc32f23_o.jpg',\n",
       " 'coarse_tilt_aligned_face.1318.11164374843_8e13e7a48b_o.jpg',\n",
       " 'coarse_tilt_aligned_face.1318.11285937695_3f9b3b22e6_o.jpg',\n",
       " 'coarse_tilt_aligned_face.1318.11285938655_5b266a4a62_o.jpg',\n",
       " 'coarse_tilt_aligned_face.1318.11285939345_5bdbdcc400_o.jpg',\n",
       " 'coarse_tilt_aligned_face.1318.11285941635_d7267aeb57_o.jpg',\n",
       " 'coarse_tilt_aligned_face.1318.11285984264_a47429d054_o.jpg',\n",
       " 'coarse_tilt_aligned_face.1318.11286001116_34dee3d480_o.jpg',\n",
       " 'coarse_tilt_aligned_face.1318.11286031763_ff08a7a748_o.jpg',\n",
       " 'coarse_tilt_aligned_face.1318.11286032493_7361fef28a_o.jpg',\n",
       " 'coarse_tilt_aligned_face.1318.11286069233_9b622eecbf_o.jpg',\n",
       " 'coarse_tilt_aligned_face.1318.11399712393_b3fdae9178_o.jpg',\n",
       " 'coarse_tilt_aligned_face.1318.11399717633_528aa960f4_o.jpg',\n",
       " 'coarse_tilt_aligned_face.1318.11510364205_958d800f18_o.jpg',\n",
       " 'coarse_tilt_aligned_face.1318.11510365645_7ee410f66f_o.jpg',\n",
       " 'coarse_tilt_aligned_face.1318.11510368785_054e230a3b_o.jpg',\n",
       " 'coarse_tilt_aligned_face.1318.11510369785_ab889420fe_o.jpg',\n",
       " 'coarse_tilt_aligned_face.1318.11510370245_f02fe97ff6_o.jpg',\n",
       " 'coarse_tilt_aligned_face.1318.11510400324_15185bf283_o.jpg',\n",
       " 'coarse_tilt_aligned_face.1318.11510438296_b80be6142d_o.jpg',\n",
       " 'coarse_tilt_aligned_face.1318.11510468253_f08f4fecdc_o.jpg',\n",
       " 'coarse_tilt_aligned_face.1318.11510468773_eb79b4ee98_o.jpg',\n",
       " 'coarse_tilt_aligned_face.1318.11705009795_82acf0348f_o.jpg',\n",
       " 'coarse_tilt_aligned_face.1318.11705220473_3c2f643590_o.jpg',\n",
       " 'coarse_tilt_aligned_face.1318.11705298653_2539bbafc1_o.jpg',\n",
       " 'coarse_tilt_aligned_face.1318.11705413173_8b5e274d6d_o.jpg',\n",
       " 'coarse_tilt_aligned_face.1318.11705548314_ba05490501_o.jpg',\n",
       " 'coarse_tilt_aligned_face.1318.11923356515_cf6e7cee05_o.jpg',\n",
       " 'coarse_tilt_aligned_face.1318.9892163775_d8454ef1e6_o.jpg',\n",
       " 'coarse_tilt_aligned_face.1319.10015709095_9d994f87c0_o.jpg',\n",
       " 'coarse_tilt_aligned_face.1319.10015728215_2732f4d950_o.jpg',\n",
       " 'coarse_tilt_aligned_face.1319.10015743856_cfeccae814_o.jpg',\n",
       " 'coarse_tilt_aligned_face.1319.10015795763_530459dfac_o.jpg',\n",
       " 'coarse_tilt_aligned_face.1319.10015795873_da1e68ccd4_o.jpg',\n",
       " 'coarse_tilt_aligned_face.1319.10015797643_15d19acabb_o.jpg',\n",
       " 'coarse_tilt_aligned_face.1319.10078834104_483b1093c5_o.jpg',\n",
       " 'coarse_tilt_aligned_face.1319.10078875785_c8f8562fb2_o.jpg',\n",
       " 'coarse_tilt_aligned_face.1319.10078971943_f884ce5a0a_o.jpg',\n",
       " 'coarse_tilt_aligned_face.1319.10286613466_2613057e55_o.jpg',\n",
       " 'coarse_tilt_aligned_face.1319.10286616186_84bd4f6f70_o.jpg',\n",
       " 'coarse_tilt_aligned_face.1319.10286632375_b2332bafd9_o.jpg',\n",
       " 'coarse_tilt_aligned_face.1319.10286708733_7d5283f233_o.jpg',\n",
       " 'coarse_tilt_aligned_face.1319.10286744873_3cebcefa9a_o.jpg',\n",
       " 'coarse_tilt_aligned_face.1319.10398666273_9048f05ab0_o.jpg',\n",
       " 'coarse_tilt_aligned_face.1319.10531817455_5cb6a63805_o.jpg',\n",
       " 'coarse_tilt_aligned_face.1319.10531827896_763329fa0e_o.jpg',\n",
       " 'coarse_tilt_aligned_face.1319.10531844536_11ef2a9831_o.jpg',\n",
       " 'coarse_tilt_aligned_face.1319.10935903185_10fd8ec4ac_o.jpg',\n",
       " 'coarse_tilt_aligned_face.1319.10936175513_cccf6cf1db_o.jpg',\n",
       " 'coarse_tilt_aligned_face.1319.10936262743_ccecf16c39_o.jpg',\n",
       " 'coarse_tilt_aligned_face.1319.10936263733_75a247d486_o.jpg',\n",
       " 'coarse_tilt_aligned_face.1319.10936264993_37f9937577_o.jpg',\n",
       " 'coarse_tilt_aligned_face.1319.11164285406_9635b5fa10_o.jpg',\n",
       " 'coarse_tilt_aligned_face.1319.11399608036_9c53b675b3_o.jpg',\n",
       " 'coarse_tilt_aligned_face.1319.11399622704_528a7b719e_o.jpg',\n",
       " 'coarse_tilt_aligned_face.1319.11399625074_50542bef46_o.jpg',\n",
       " 'coarse_tilt_aligned_face.1319.11399720503_ca98cee05c_o.jpg',\n",
       " 'coarse_tilt_aligned_face.1319.11510340555_97b6803199_o.jpg',\n",
       " 'coarse_tilt_aligned_face.1319.11510342154_dc91ff8a32_o.jpg',\n",
       " 'coarse_tilt_aligned_face.1319.11510342654_f0ae16d6e0_o.jpg',\n",
       " 'coarse_tilt_aligned_face.1319.11510344155_ec2d7aee60_o.jpg',\n",
       " 'coarse_tilt_aligned_face.1319.11510345795_9cae76ba05_o.jpg',\n",
       " 'coarse_tilt_aligned_face.1319.11510346545_931d909b0e_o.jpg',\n",
       " 'coarse_tilt_aligned_face.1319.11510360515_b0d3238aaa_o.jpg',\n",
       " 'coarse_tilt_aligned_face.1319.11510366964_3fd17b2cda_o.jpg',\n",
       " 'coarse_tilt_aligned_face.1319.11510369026_cd87fbe5b2_o.jpg',\n",
       " 'coarse_tilt_aligned_face.1319.11510372824_fa3c9fdf50_o.jpg',\n",
       " 'coarse_tilt_aligned_face.1319.11510373264_fc3f9bb0ec_o.jpg',\n",
       " 'coarse_tilt_aligned_face.1319.11510377814_f78753ecdf_o.jpg',\n",
       " 'coarse_tilt_aligned_face.1319.11510384406_53d31240d9_o.jpg',\n",
       " 'coarse_tilt_aligned_face.1319.11510384966_f2c6498ab3_o.jpg',\n",
       " 'coarse_tilt_aligned_face.1319.11510389954_0680e1de54_o.jpg',\n",
       " 'coarse_tilt_aligned_face.1319.11510411463_d850128996_o.jpg',\n",
       " 'coarse_tilt_aligned_face.1319.11510415576_4d5d536bb4_o.jpg',\n",
       " 'coarse_tilt_aligned_face.1319.11510446013_48df8e8cb3_o.jpg',\n",
       " 'coarse_tilt_aligned_face.1319.11510457503_aea48983d1_o.jpg',\n",
       " 'coarse_tilt_aligned_face.1319.11510459083_82efeb5e91_o.jpg',\n",
       " 'coarse_tilt_aligned_face.1319.11581679634_0708fb6f87_o.jpg',\n",
       " 'coarse_tilt_aligned_face.1319.11705470833_a757d9c577_o.jpg',\n",
       " 'coarse_tilt_aligned_face.1319.11705543834_4814bbd736_o.jpg',\n",
       " 'coarse_tilt_aligned_face.1319.11705578644_1f523e74c6_o.jpg',\n",
       " 'coarse_tilt_aligned_face.1319.11705605294_3a962a0d95_o.jpg',\n",
       " 'coarse_tilt_aligned_face.1319.11705769926_96be630a5a_o.jpg',\n",
       " 'coarse_tilt_aligned_face.1319.11924231706_a2f7db970f_o.jpg',\n",
       " 'coarse_tilt_aligned_face.1319.9709082924_628f433a51_o.jpg',\n",
       " 'coarse_tilt_aligned_face.1319.9709083126_845e10d33b_o.jpg',\n",
       " 'coarse_tilt_aligned_face.1319.9892171576_3298bc719c_o.jpg',\n",
       " 'coarse_tilt_aligned_face.1319.9892177674_0fb4f59c7a_o.jpg',\n",
       " 'coarse_tilt_aligned_face.132.11343779175_d8e550d32e_o.jpg',\n",
       " 'coarse_tilt_aligned_face.132.11343848026_7f024ce9a7_o.jpg',\n",
       " 'coarse_tilt_aligned_face.132.11343871024_db071b2f98_o.jpg',\n",
       " 'coarse_tilt_aligned_face.132.11343883554_f289ffed45_o.jpg',\n",
       " 'coarse_tilt_aligned_face.132.11343916003_83b2d8d3e1_o.jpg',\n",
       " 'coarse_tilt_aligned_face.132.11343924233_0f17bf1461_o.jpg',\n",
       " 'coarse_tilt_aligned_face.132.11343929825_e91310d8bb_o.jpg',\n",
       " 'coarse_tilt_aligned_face.132.11344036584_5ba4b6d6a0_o.jpg',\n",
       " 'coarse_tilt_aligned_face.132.11345629955_c05a411ca8_o.jpg',\n",
       " 'coarse_tilt_aligned_face.132.11345711336_7a70c81d07_o.jpg',\n",
       " 'coarse_tilt_aligned_face.132.11345714956_886896e6c1_o.jpg',\n",
       " 'coarse_tilt_aligned_face.132.11345729574_42cd79dc37_o.jpg',\n",
       " 'coarse_tilt_aligned_face.132.11345738184_71774bb21a_o.jpg',\n",
       " 'coarse_tilt_aligned_face.132.11345741476_a767abaf34_o.jpg',\n",
       " 'coarse_tilt_aligned_face.132.11345777233_3a8585ffc6_o.jpg',\n",
       " 'coarse_tilt_aligned_face.132.11345780073_f1f561ce66_o.jpg',\n",
       " 'coarse_tilt_aligned_face.132.11345786763_b3c1c8b41a_o.jpg',\n",
       " 'coarse_tilt_aligned_face.1320.10936163875_e1a6b7a64a_o.jpg',\n",
       " 'coarse_tilt_aligned_face.1320.10936223276_d35ca077fa_o.jpg',\n",
       " 'coarse_tilt_aligned_face.1321.11041891765_1d9aed7540_o.jpg',\n",
       " 'coarse_tilt_aligned_face.1321.11041895735_50c547da68_o.jpg',\n",
       " 'coarse_tilt_aligned_face.1321.11042033334_450b6656fc_o.jpg',\n",
       " 'coarse_tilt_aligned_face.1321.11042038564_c0c0878c29_o.jpg',\n",
       " 'coarse_tilt_aligned_face.1321.11042084723_c5c5bf83de_o.jpg',\n",
       " 'coarse_tilt_aligned_face.1321.11042088473_5b8d28283f_o.jpg',\n",
       " 'coarse_tilt_aligned_face.1321.11042098083_c545ac11f9_o.jpg',\n",
       " 'coarse_tilt_aligned_face.133.11331226025_e649b1c7cb_o.jpg',\n",
       " 'coarse_tilt_aligned_face.133.11331297256_0dd6face23_o.jpg',\n",
       " 'coarse_tilt_aligned_face.133.11331331594_cf75db3a12_o.jpg',\n",
       " 'coarse_tilt_aligned_face.133.11331339346_04d596b4bf_o.jpg',\n",
       " 'coarse_tilt_aligned_face.133.11331364744_bf16856562_o.jpg',\n",
       " 'coarse_tilt_aligned_face.133.11343740245_85135406a6_o.jpg',\n",
       " 'coarse_tilt_aligned_face.133.11343758975_04c1067ca8_o.jpg',\n",
       " 'coarse_tilt_aligned_face.133.11343865944_ea294ffe50_o.jpg',\n",
       " 'coarse_tilt_aligned_face.133.11343902554_43e0b5f4c2_o.jpg',\n",
       " 'coarse_tilt_aligned_face.133.11343929825_e91310d8bb_o.jpg',\n",
       " 'coarse_tilt_aligned_face.133.11343942943_a3763042ce_o.jpg',\n",
       " 'coarse_tilt_aligned_face.133.11344033223_dc97ea2a53_o.jpg',\n",
       " 'coarse_tilt_aligned_face.133.11344035543_1598217bf9_o.jpg',\n",
       " 'coarse_tilt_aligned_face.133.11344036584_5ba4b6d6a0_o.jpg',\n",
       " 'coarse_tilt_aligned_face.133.11345596463_f1b436705f_o.jpg',\n",
       " 'coarse_tilt_aligned_face.133.9345544977_d24ed0e29f_o.jpg',\n",
       " 'coarse_tilt_aligned_face.133.9348335200_3b1bc97c47_o.jpg',\n",
       " 'coarse_tilt_aligned_face.134.11331226025_e649b1c7cb_o.jpg',\n",
       " 'coarse_tilt_aligned_face.134.11331297256_0dd6face23_o.jpg',\n",
       " 'coarse_tilt_aligned_face.134.11331320526_f8635e254e_o.jpg',\n",
       " 'coarse_tilt_aligned_face.134.11331383403_780c5e16b5_o.jpg',\n",
       " 'coarse_tilt_aligned_face.134.11331401403_bb5944aa2d_o.jpg',\n",
       " 'coarse_tilt_aligned_face.134.11343759245_695b4d73ff_o.jpg',\n",
       " 'coarse_tilt_aligned_face.134.11343967453_c80078b6bb_o.jpg',\n",
       " 'coarse_tilt_aligned_face.134.11343991073_81a6175e9b_o.jpg',\n",
       " 'coarse_tilt_aligned_face.134.11345440565_249feec5c3_o.jpg',\n",
       " 'coarse_tilt_aligned_face.134.11345515785_ef6eeefd51_o.jpg',\n",
       " 'coarse_tilt_aligned_face.134.11345559683_64f628a9ef_o.jpg',\n",
       " 'coarse_tilt_aligned_face.134.11345608563_4950c8b64c_o.jpg',\n",
       " 'coarse_tilt_aligned_face.135.11331443003_96947bfb3f_o.jpg',\n",
       " 'coarse_tilt_aligned_face.135.11345491524_801281ac3d_o.jpg',\n",
       " 'coarse_tilt_aligned_face.135.11345509685_6e2b1dfac7_o.jpg',\n",
       " 'coarse_tilt_aligned_face.135.11345515785_ef6eeefd51_o.jpg',\n",
       " 'coarse_tilt_aligned_face.135.11345586926_27c45583a9_o.jpg',\n",
       " 'coarse_tilt_aligned_face.136.11345509685_6e2b1dfac7_o.jpg',\n",
       " 'coarse_tilt_aligned_face.136.11345586926_27c45583a9_o.jpg',\n",
       " 'coarse_tilt_aligned_face.136.11345661333_52d0ac2914_o.jpg',\n",
       " 'coarse_tilt_aligned_face.137.11331226025_e649b1c7cb_o.jpg',\n",
       " 'coarse_tilt_aligned_face.137.11331297256_0dd6face23_o.jpg',\n",
       " 'coarse_tilt_aligned_face.137.11345509685_6e2b1dfac7_o.jpg',\n",
       " 'coarse_tilt_aligned_face.137.11345586926_27c45583a9_o.jpg',\n",
       " 'coarse_tilt_aligned_face.137.11345830753_1574997964_o.jpg',\n",
       " 'coarse_tilt_aligned_face.137.11345832453_a6f691f233_o.jpg',\n",
       " 'coarse_tilt_aligned_face.138.9345522341_a6fa2675a6_o.jpg',\n",
       " 'coarse_tilt_aligned_face.1388.10195441525_109279b5aa_o.jpg',\n",
       " 'coarse_tilt_aligned_face.1388.10195443005_5e565e5b33_o.jpg',\n",
       " 'coarse_tilt_aligned_face.1388.10195451775_1f7021cda7_o.jpg',\n",
       " ...]"
      ]
     },
     "execution_count": 227,
=======
       "6714"
      ]
     },
     "execution_count": 253,
>>>>>>> 5be6589eb73edd4cf96d0baea41a7ddc63f0aa24
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
<<<<<<< HEAD
    "files"
=======
    "len(df_ids)"
>>>>>>> 5be6589eb73edd4cf96d0baea41a7ddc63f0aa24
   ]
  },
  {
   "cell_type": "code",
<<<<<<< HEAD
   "execution_count": 228,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df_ids = get_ids(files)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 229,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# ID, Gender, Age of whole dataframe\n",
    "df_IGA_only = df[['ID', 'gender', 'age']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 230,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Arno\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:8: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  \n"
     ]
    }
   ],
   "source": [
    "df_useful = useful_df(df_IGA_only,df_ids)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 231,
=======
   "execution_count": 246,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "merge() got an unexpected keyword argument 'validation'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-246-7042f1dc5235>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mi_df\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmerge\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdf\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdf_ids\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mon\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'original_image'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mhow\u001b[0m \u001b[1;33m=\u001b[0m\u001b[1;34m'inner'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mvalidation\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'one_to_one'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m: merge() got an unexpected keyword argument 'validation'"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 244,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'DataFrame' object has no attribute 'validate'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-244-2adfc6f9a07d>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mi_df\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mvalidate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'one_to_one'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\pandas\\core\\generic.py\u001b[0m in \u001b[0;36m__getattr__\u001b[1;34m(self, name)\u001b[0m\n\u001b[0;32m   3079\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mname\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_info_axis\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   3080\u001b[0m                 \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mname\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 3081\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0mobject\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__getattribute__\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mname\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   3082\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   3083\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m__setattr__\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mname\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mAttributeError\u001b[0m: 'DataFrame' object has no attribute 'validate'"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 250,
>>>>>>> 5be6589eb73edd4cf96d0baea41a7ddc63f0aa24
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
<<<<<<< HEAD
       "      <th>ID</th>\n",
       "      <th>gender</th>\n",
       "      <th>age</th>\n",
=======
       "      <th>original_image</th>\n",
>>>>>>> 5be6589eb73edd4cf96d0baea41a7ddc63f0aa24
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
<<<<<<< HEAD
       "      <th>1912</th>\n",
       "      <td>132.11343916003_83b2d8d3e1_o.jpg</td>\n",
       "      <td>f</td>\n",
       "      <td>Young_Adult</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1913</th>\n",
       "      <td>133.9345544977_d24ed0e29f_o.jpg</td>\n",
       "      <td>f</td>\n",
       "      <td>Adult</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1914</th>\n",
       "      <td>132.11343848026_7f024ce9a7_o.jpg</td>\n",
       "      <td>f</td>\n",
       "      <td>Young_Adult</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1915</th>\n",
       "      <td>134.11331383403_780c5e16b5_o.jpg</td>\n",
       "      <td>m</td>\n",
       "      <td>Abraham</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1916</th>\n",
       "      <td>135.11345586926_27c45583a9_o.jpg</td>\n",
       "      <td>m</td>\n",
       "      <td>Abraham</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1917</th>\n",
       "      <td>136.11345586926_27c45583a9_o.jpg</td>\n",
       "      <td>m</td>\n",
       "      <td>Abraham</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1918</th>\n",
       "      <td>137.11345586926_27c45583a9_o.jpg</td>\n",
       "      <td>m</td>\n",
       "      <td>Abraham</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1919</th>\n",
       "      <td>132.11343924233_0f17bf1461_o.jpg</td>\n",
       "      <td>f</td>\n",
       "      <td>Young_Adult</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1920</th>\n",
       "      <td>138.9345522341_a6fa2675a6_o.jpg</td>\n",
       "      <td>f</td>\n",
       "      <td>Child</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1921</th>\n",
       "      <td>139.11331412223_63218e1bc6_o.jpg</td>\n",
       "      <td>m</td>\n",
       "      <td>Adult</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1922</th>\n",
       "      <td>139.11331362774_740f99d50e_o.jpg</td>\n",
       "      <td>m</td>\n",
       "      <td>Adult</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1923</th>\n",
       "      <td>140.11331364744_bf16856562_o.jpg</td>\n",
       "      <td>m</td>\n",
       "      <td>Adult</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1924</th>\n",
       "      <td>133.11331364744_bf16856562_o.jpg</td>\n",
       "      <td>f</td>\n",
       "      <td>Adult</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1925</th>\n",
       "      <td>139.11331364744_bf16856562_o.jpg</td>\n",
       "      <td>m</td>\n",
       "      <td>Adult</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1926</th>\n",
       "      <td>141.11345608563_4950c8b64c_o.jpg</td>\n",
       "      <td>m</td>\n",
       "      <td>Adult</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1927</th>\n",
       "      <td>134.11345608563_4950c8b64c_o.jpg</td>\n",
       "      <td>m</td>\n",
       "      <td>Abraham</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1928</th>\n",
       "      <td>142.11345653275_45382c435c_o.jpg</td>\n",
       "      <td>m</td>\n",
       "      <td>Adult</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1929</th>\n",
       "      <td>140.11345507154_6a5c22030b_o.jpg</td>\n",
       "      <td>m</td>\n",
       "      <td>Adult</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1930</th>\n",
       "      <td>132.11345629955_c05a411ca8_o.jpg</td>\n",
       "      <td>f</td>\n",
       "      <td>Young_Adult</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1931</th>\n",
       "      <td>143.10155685563_eb6c07b357_o.jpg</td>\n",
       "      <td>m</td>\n",
       "      <td>Young_Adult</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1932</th>\n",
       "      <td>140.11345588846_65a35ed630_o.jpg</td>\n",
       "      <td>m</td>\n",
       "      <td>Adult</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1933</th>\n",
       "      <td>140.11345506124_c397d8c402_o.jpg</td>\n",
       "      <td>m</td>\n",
       "      <td>Adult</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1934</th>\n",
       "      <td>140.11345487344_e716a9aef8_o.jpg</td>\n",
       "      <td>m</td>\n",
       "      <td>Adult</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1935</th>\n",
       "      <td>144.11345487344_e716a9aef8_o.jpg</td>\n",
       "      <td>f</td>\n",
       "      <td>Elderly</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1936</th>\n",
       "      <td>137.11331226025_e649b1c7cb_o.jpg</td>\n",
       "      <td>m</td>\n",
       "      <td>Abraham</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1937</th>\n",
       "      <td>145.11331226025_e649b1c7cb_o.jpg</td>\n",
       "      <td>m</td>\n",
       "      <td>Adult</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1938</th>\n",
       "      <td>146.11331226025_e649b1c7cb_o.jpg</td>\n",
       "      <td>m</td>\n",
       "      <td>Abraham</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1939</th>\n",
       "      <td>147.11331226025_e649b1c7cb_o.jpg</td>\n",
       "      <td>m</td>\n",
       "      <td>Abraham</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1940</th>\n",
       "      <td>140.11331226025_e649b1c7cb_o.jpg</td>\n",
       "      <td>m</td>\n",
       "      <td>Adult</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1941</th>\n",
       "      <td>134.11331226025_e649b1c7cb_o.jpg</td>\n",
       "      <td>m</td>\n",
       "      <td>Abraham</td>\n",
=======
       "      <th>0</th>\n",
       "      <td>8194283079_fe7c8c9b2f_o.jpg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>8314899476_8c1ac2e4bb_o.jpg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>8884658111_c692813a62_o.jpg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>10009166853_a6b50b4117_o.jpg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>8195375498_06c6fc5627_o.jpg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>8215787552_3198c25285_o.jpg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>8586120507_6c519d5923_o.jpg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>8314893776_8ddb4d4549_o.jpg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>8194283079_fe7c8c9b2f_o.jpg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>8469357784_ac74572242_o.jpg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>8313851951_3a0bd24aeb_o.jpg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>8314901670_835a0aec49_o.jpg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>11533025853_f3eb6ae6c7_o.jpg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>11486219815_c7725c3300_o.jpg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>11486520496_955dea5c71_o.jpg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>11486644334_fcd534e0ec_o.jpg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>11486726716_e0dcf8f67a_o.jpg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>11486731586_0c25a7d057_o.jpg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>11486800265_fed6909ed6_o.jpg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>11486804315_38016fa7a3_o.jpg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>11486850554_e39f75fb7e_o.jpg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>11486871145_20f34d8610_o.jpg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>11486871494_8ded06f48c_o.jpg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>11486879925_4f1e6e9a8a_o.jpg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>11486887194_5efdb501fa_o.jpg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>11486889344_27967040ff_o.jpg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>11486899924_c3eb356839_o.jpg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>11486916314_778b823dc2_o.jpg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>11486924966_c3d8cdbcc8_o.jpg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>11486965696_f2d3b39d7a_o.jpg</td>\n",
>>>>>>> 5be6589eb73edd4cf96d0baea41a7ddc63f0aa24
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
<<<<<<< HEAD
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19255</th>\n",
       "      <td>2252.11842009335_2bfa8c57ba_o.jpg</td>\n",
       "      <td>m</td>\n",
       "      <td>Adult</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19256</th>\n",
       "      <td>2254.11842709396_db383df3c3_o.jpg</td>\n",
       "      <td>f</td>\n",
       "      <td>Elderly</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19257</th>\n",
       "      <td>2253.11836911476_f977d4b1ea_o.jpg</td>\n",
       "      <td>f</td>\n",
       "      <td>Young_Adult</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19258</th>\n",
       "      <td>2255.11836914936_8a115cf2f8_o.jpg</td>\n",
       "      <td>f</td>\n",
       "      <td>Young_Adult</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19259</th>\n",
       "      <td>2250.11842945736_544f02301d_o.jpg</td>\n",
       "      <td>m</td>\n",
       "      <td>Young_Adult</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19260</th>\n",
       "      <td>2253.11836131615_5ac81d4a25_o.jpg</td>\n",
       "      <td>f</td>\n",
       "      <td>Young_Adult</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19308</th>\n",
       "      <td>2260.10128398023_c5def6551c_o.jpg</td>\n",
       "      <td>f</td>\n",
       "      <td>Adult</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19309</th>\n",
       "      <td>2261.9237738346_5a05379225_o.jpg</td>\n",
       "      <td>f</td>\n",
       "      <td>Teenager</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19310</th>\n",
       "      <td>2262.9237738346_5a05379225_o.jpg</td>\n",
       "      <td>f</td>\n",
       "      <td>Teenager</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19311</th>\n",
       "      <td>2263.9237738346_5a05379225_o.jpg</td>\n",
       "      <td>f</td>\n",
       "      <td>Teenager</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19312</th>\n",
       "      <td>2264.9237738346_5a05379225_o.jpg</td>\n",
       "      <td>f</td>\n",
       "      <td>Child</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19313</th>\n",
       "      <td>2265.9237738346_5a05379225_o.jpg</td>\n",
       "      <td>m</td>\n",
       "      <td>Child</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19314</th>\n",
       "      <td>2261.9237730868_93f71f021b_o.jpg</td>\n",
       "      <td>f</td>\n",
       "      <td>Teenager</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19315</th>\n",
       "      <td>2265.9237730868_93f71f021b_o.jpg</td>\n",
       "      <td>m</td>\n",
       "      <td>Child</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19316</th>\n",
       "      <td>2263.9237730868_93f71f021b_o.jpg</td>\n",
       "      <td>f</td>\n",
       "      <td>Teenager</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19317</th>\n",
       "      <td>2262.9237730868_93f71f021b_o.jpg</td>\n",
       "      <td>f</td>\n",
       "      <td>Teenager</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19318</th>\n",
       "      <td>2264.9237730868_93f71f021b_o.jpg</td>\n",
       "      <td>f</td>\n",
       "      <td>Child</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19319</th>\n",
       "      <td>2260.10128401573_37b1b29f58_o.jpg</td>\n",
       "      <td>f</td>\n",
       "      <td>Adult</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19320</th>\n",
       "      <td>2260.10128422953_fd6ddec73f_o.jpg</td>\n",
       "      <td>f</td>\n",
       "      <td>Adult</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19321</th>\n",
       "      <td>2260.10128267395_2ce79b7e8b_o.jpg</td>\n",
       "      <td>f</td>\n",
       "      <td>Adult</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19322</th>\n",
       "      <td>2266.9237725932_2cf8561707_o.jpg</td>\n",
       "      <td>m</td>\n",
       "      <td>Young_Adult</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19323</th>\n",
       "      <td>2266.9237724854_a38271b17f_o.jpg</td>\n",
       "      <td>m</td>\n",
       "      <td>Young_Adult</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19331</th>\n",
       "      <td>2270.11523339855_06aeaa34c5_o.jpg</td>\n",
       "      <td>m</td>\n",
       "      <td>Adult</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19332</th>\n",
       "      <td>2271.11523339855_06aeaa34c5_o.jpg</td>\n",
       "      <td>m</td>\n",
       "      <td>Adult</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19333</th>\n",
       "      <td>2272.11167919424_a403c326c9_o.jpg</td>\n",
       "      <td>f</td>\n",
       "      <td>Young_Adult</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19334</th>\n",
       "      <td>2273.11167919424_a403c326c9_o.jpg</td>\n",
       "      <td>f</td>\n",
       "      <td>Young_Adult</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19335</th>\n",
       "      <td>2274.11167919424_a403c326c9_o.jpg</td>\n",
       "      <td>f</td>\n",
       "      <td>Young_Adult</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19336</th>\n",
       "      <td>2275.11484200864_460219a65c_o.jpg</td>\n",
       "      <td>f</td>\n",
       "      <td>Teenager</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19337</th>\n",
       "      <td>2275.11484683456_78a81016ae_o.jpg</td>\n",
       "      <td>f</td>\n",
       "      <td>Teenager</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19338</th>\n",
       "      <td>2276.11523414516_2bee128e37_o.jpg</td>\n",
       "      <td>f</td>\n",
       "      <td>Young_Adult</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>6079 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "0                                     ID gender          age\n",
       "1912    132.11343916003_83b2d8d3e1_o.jpg      f  Young_Adult\n",
       "1913     133.9345544977_d24ed0e29f_o.jpg      f        Adult\n",
       "1914    132.11343848026_7f024ce9a7_o.jpg      f  Young_Adult\n",
       "1915    134.11331383403_780c5e16b5_o.jpg      m      Abraham\n",
       "1916    135.11345586926_27c45583a9_o.jpg      m      Abraham\n",
       "1917    136.11345586926_27c45583a9_o.jpg      m      Abraham\n",
       "1918    137.11345586926_27c45583a9_o.jpg      m      Abraham\n",
       "1919    132.11343924233_0f17bf1461_o.jpg      f  Young_Adult\n",
       "1920     138.9345522341_a6fa2675a6_o.jpg      f        Child\n",
       "1921    139.11331412223_63218e1bc6_o.jpg      m        Adult\n",
       "1922    139.11331362774_740f99d50e_o.jpg      m        Adult\n",
       "1923    140.11331364744_bf16856562_o.jpg      m        Adult\n",
       "1924    133.11331364744_bf16856562_o.jpg      f        Adult\n",
       "1925    139.11331364744_bf16856562_o.jpg      m        Adult\n",
       "1926    141.11345608563_4950c8b64c_o.jpg      m        Adult\n",
       "1927    134.11345608563_4950c8b64c_o.jpg      m      Abraham\n",
       "1928    142.11345653275_45382c435c_o.jpg      m        Adult\n",
       "1929    140.11345507154_6a5c22030b_o.jpg      m        Adult\n",
       "1930    132.11345629955_c05a411ca8_o.jpg      f  Young_Adult\n",
       "1931    143.10155685563_eb6c07b357_o.jpg      m  Young_Adult\n",
       "1932    140.11345588846_65a35ed630_o.jpg      m        Adult\n",
       "1933    140.11345506124_c397d8c402_o.jpg      m        Adult\n",
       "1934    140.11345487344_e716a9aef8_o.jpg      m        Adult\n",
       "1935    144.11345487344_e716a9aef8_o.jpg      f      Elderly\n",
       "1936    137.11331226025_e649b1c7cb_o.jpg      m      Abraham\n",
       "1937    145.11331226025_e649b1c7cb_o.jpg      m        Adult\n",
       "1938    146.11331226025_e649b1c7cb_o.jpg      m      Abraham\n",
       "1939    147.11331226025_e649b1c7cb_o.jpg      m      Abraham\n",
       "1940    140.11331226025_e649b1c7cb_o.jpg      m        Adult\n",
       "1941    134.11331226025_e649b1c7cb_o.jpg      m      Abraham\n",
       "...                                  ...    ...          ...\n",
       "19255  2252.11842009335_2bfa8c57ba_o.jpg      m        Adult\n",
       "19256  2254.11842709396_db383df3c3_o.jpg      f      Elderly\n",
       "19257  2253.11836911476_f977d4b1ea_o.jpg      f  Young_Adult\n",
       "19258  2255.11836914936_8a115cf2f8_o.jpg      f  Young_Adult\n",
       "19259  2250.11842945736_544f02301d_o.jpg      m  Young_Adult\n",
       "19260  2253.11836131615_5ac81d4a25_o.jpg      f  Young_Adult\n",
       "19308  2260.10128398023_c5def6551c_o.jpg      f        Adult\n",
       "19309   2261.9237738346_5a05379225_o.jpg      f     Teenager\n",
       "19310   2262.9237738346_5a05379225_o.jpg      f     Teenager\n",
       "19311   2263.9237738346_5a05379225_o.jpg      f     Teenager\n",
       "19312   2264.9237738346_5a05379225_o.jpg      f        Child\n",
       "19313   2265.9237738346_5a05379225_o.jpg      m        Child\n",
       "19314   2261.9237730868_93f71f021b_o.jpg      f     Teenager\n",
       "19315   2265.9237730868_93f71f021b_o.jpg      m        Child\n",
       "19316   2263.9237730868_93f71f021b_o.jpg      f     Teenager\n",
       "19317   2262.9237730868_93f71f021b_o.jpg      f     Teenager\n",
       "19318   2264.9237730868_93f71f021b_o.jpg      f        Child\n",
       "19319  2260.10128401573_37b1b29f58_o.jpg      f        Adult\n",
       "19320  2260.10128422953_fd6ddec73f_o.jpg      f        Adult\n",
       "19321  2260.10128267395_2ce79b7e8b_o.jpg      f        Adult\n",
       "19322   2266.9237725932_2cf8561707_o.jpg      m  Young_Adult\n",
       "19323   2266.9237724854_a38271b17f_o.jpg      m  Young_Adult\n",
       "19331  2270.11523339855_06aeaa34c5_o.jpg      m        Adult\n",
       "19332  2271.11523339855_06aeaa34c5_o.jpg      m        Adult\n",
       "19333  2272.11167919424_a403c326c9_o.jpg      f  Young_Adult\n",
       "19334  2273.11167919424_a403c326c9_o.jpg      f  Young_Adult\n",
       "19335  2274.11167919424_a403c326c9_o.jpg      f  Young_Adult\n",
       "19336  2275.11484200864_460219a65c_o.jpg      f     Teenager\n",
       "19337  2275.11484683456_78a81016ae_o.jpg      f     Teenager\n",
       "19338  2276.11523414516_2bee128e37_o.jpg      f  Young_Adult\n",
       "\n",
       "[6079 rows x 3 columns]"
      ]
     },
     "execution_count": 231,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_IGA_only[df_IGA_only.ID.isin(df_ids['ID'])]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "  0%|                                                                                         | 0/6714 [00:00<?, ?it/s]\n",
      "  0%|                                                                               | 1/6714 [00:03<7:14:59,  3.89s/it]\n",
      "  0%|                                                                               | 2/6714 [00:07<7:21:11,  3.94s/it]\n",
      "Exception in thread Thread-11:\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\Arno\\Anaconda3\\lib\\threading.py\", line 916, in _bootstrap_inner\n",
      "    self.run()\n",
      "  File \"C:\\Users\\Arno\\Anaconda3\\lib\\site-packages\\tqdm\\_monitor.py\", line 62, in run\n",
      "    for instance in self.tqdm_cls._instances:\n",
      "  File \"C:\\Users\\Arno\\Anaconda3\\lib\\_weakrefset.py\", line 60, in __iter__\n",
      "    for itemref in self.data:\n",
      "RuntimeError: Set changed size during iteration\n",
      "\n",
      "100%|████████████████████████████████████████████████████████████████████████████| 6714/6714 [6:01:43<00:00,  3.23s/it]\n"
     ]
    }
   ],
   "source": [
    "# Make array with every row: gender, age, facial landmarks\n",
    "# This takes a long time! (+10min)\n",
    "# tqdm makes progress bar\n",
    "counter = 1 # Batch-counter starts at 1\n",
    "for i in tqdm(range(len(files))):\n",
    "    if i%100 == 0 and i!=0:  \n",
    "        output_name = \"training_set_%s.mat\" %counter\n",
    "        scipy.io.savemat(output_name, mdict={'out': test_data}, oned_as='row')\n",
    "        counter +=1\n",
    "        test_data = []\n",
    "        \n",
    "    # Last batch\n",
    "    if i == len(files):\n",
    "        output_name = \"training_set_%s.mat\" %counter\n",
    "        scipy.io.savemat(output_name, mdict={'out': test_data}, oned_as='row')\n",
    "        \n",
    "        \n",
    "    file = files[i]\n",
    "    ID = get_ids([file]) # Get id from picture to match with dataframe, extra [] because input if def is a directory\n",
    "    if ID['ID'][0] in df_useful.index:  # Check whether the ID is actually in the list\n",
    "        image = cv2.imread(os.path.join('C:/Users/Arno/Desktop/Facial/DataBase',file),0) # 0 grayscales the image\n",
    "        image = imutils.resize(image, width = 500) # Resize to 500 pixels        \n",
    "        landmarks = find_landmarks(image)  # Get matrix of x,y coordinates of facial landmarks  \n",
    "        information = df_useful.loc[ID['ID']].as_matrix()\n",
    "        information = information[0] # Remove extra brackets imported when making directory\n",
    "        information[2] = landmarks\n",
    "        test_data.append(information)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 464,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "training_set_1.mat\n",
      "training_set_10.mat\n",
      "training_set_11.mat\n",
      "training_set_12.mat\n",
      "training_set_13.mat\n",
      "training_set_14.mat\n",
      "training_set_15.mat\n",
      "training_set_16.mat\n",
      "training_set_17.mat\n",
      "training_set_18.mat\n",
      "training_set_19.mat\n",
      "training_set_2.mat\n",
      "training_set_20.mat\n",
      "training_set_21.mat\n",
      "training_set_22.mat\n",
      "training_set_23.mat\n",
      "training_set_24.mat\n",
      "training_set_25.mat\n",
      "training_set_26.mat\n",
      "training_set_27.mat\n",
      "training_set_28.mat\n",
      "training_set_29.mat\n",
      "training_set_3.mat\n",
      "training_set_30.mat\n",
      "training_set_31.mat\n",
      "training_set_32.mat\n",
      "training_set_33.mat\n",
      "training_set_34.mat\n",
      "training_set_35.mat\n",
      "training_set_36.mat\n",
      "training_set_37.mat\n",
      "training_set_38.mat\n",
      "training_set_39.mat\n",
      "training_set_4.mat\n",
      "training_set_40.mat\n",
      "training_set_41.mat\n",
      "training_set_42.mat\n",
      "training_set_43.mat\n",
      "training_set_44.mat\n",
      "training_set_45.mat\n",
      "training_set_46.mat\n",
      "training_set_47.mat\n",
      "training_set_48.mat\n",
      "training_set_49.mat\n",
      "training_set_50.mat\n",
      "training_set_51.mat\n",
      "training_set_52.mat\n",
      "training_set_53.mat\n",
      "training_set_54.mat\n",
      "training_set_55.mat\n",
      "training_set_56.mat\n",
      "training_set_57.mat\n",
      "training_set_58.mat\n",
      "training_set_59.mat\n",
      "training_set_60.mat\n",
      "training_set_61.mat\n",
      "training_set_62.mat\n",
      "training_set_63.mat\n",
      "training_set_64.mat\n",
      "training_set_65.mat\n",
      "training_set_66.mat\n",
      "training_set_67.mat\n",
      "training_set_68.mat\n"
     ]
    }
   ],
   "source": [
    "# Merge all the batches to one workable matrix\n",
    "# Some batches were removed because they were empty\n",
    "\n",
    "training_files = find_files('C:/Users/Arno/Desktop/Facial/Final-Project-Bletchley-02/Training', '.mat')\n",
    "training_data = np.zeros(3) # Initiate\n",
    "for file in training_files:\n",
    "    print(file) # Check\n",
    "    file_dir = 'C:/Users/Arno/Desktop/Facial/Final-Project-Bletchley-02/Training/'+file\n",
    "    loading = scipy.io.loadmat(file_dir) # Put it in a variable, so it overwrites every iteration\n",
    "    loading = loading['out']\n",
    "    training_data = np.vstack((training_data, loading))\n",
    "\n",
    "# Remove initial zero row\n",
    "training_data = training_data[1:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 465,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Arno\\Anaconda3\\lib\\site-packages\\pandas\\core\\internals.py:1153: FutureWarning: elementwise comparison failed; returning scalar instead, but in the future will perform elementwise comparison\n",
      "  result = func(values, other)\n"
     ]
    }
   ],
   "source": [
    "# Clean the matrix of unidentified genders\n",
    "df_clean = pd.DataFrame(training_data)\n",
    "df_clean = df_clean[df_clean !=['u']]\n",
    "\n",
    "# Clean the matrix of no facial landmarks (if no landmarks are found the program outputs [[0]], which has a length of 1)\n",
    "df_clean = df_clean[df_clean[2].map(len) != 1]\n",
    "\n",
    "df_clean.dropna(inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 466,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# To numpy array again\n",
    "training_data = df_clean.as_matrix()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 467,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Splitting up the X_train and Y_train\n",
    "Y_train = np.column_stack((training_data[:,0], training_data[:,1]))\n",
    "X_train = training_data[:,2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 468,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "Cleaning up the data. Scipy.io.loadmat puts every entry in its own formatted array. This loop removes all the entries and\n",
    "puts it in one single array.\n",
    "'''\n",
    "for i in range(len(Y_train)):\n",
    "    Y_train[i][0] = Y_train[i][0][0]\n",
    "    Y_train[i][1] = Y_train[i][1][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 473,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "'''Y_train still needs to be one hot encoded'''\n",
    "df_Y_train = pd.DataFrame(Y_train)\n",
    "Y_train_dummies = pd.get_dummies(df_Y_train).as_matrix()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 474,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "Splitting up into training and validation data\n",
    "'''\n",
    "# Validation size = 20% , rs=2 is seed\n",
    "X_train, X_val, Y_train, Y_val = train_test_split(X_train, Y_train_dummies, test_size = 0.2, random_state = 4) \n",
    "\n",
    "# Split up the training outcome data into age and gender => Two different models\n",
    "Y_train_gender = Y_train[:,0:2]\n",
    "Y_train_age = Y_train[:,2:Y_train.shape[1]+1]\n",
    "Y_val_gender = Y_val[:,0:2]\n",
    "Y_val_age = Y_val[:,2:Y_train.shape[1]+1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 476,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0, 1],\n",
       "       [1, 0],\n",
       "       [0, 1],\n",
       "       ..., \n",
       "       [1, 0],\n",
       "       [1, 0],\n",
       "       [0, 1]], dtype=uint8)"
      ]
     },
     "execution_count": 476,
=======
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6684</th>\n",
       "      <td>9998955365_eff114f58a_o.jpg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6685</th>\n",
       "      <td>9999002276_615e2e74f5_o.jpg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6686</th>\n",
       "      <td>9999017466_ab44275470_o.jpg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6687</th>\n",
       "      <td>9999085413_662fb85eb9_o.jpg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6688</th>\n",
       "      <td>10009166853_a6b50b4117_o.jpg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6689</th>\n",
       "      <td>8195382282_52f726fcca_o.jpg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6690</th>\n",
       "      <td>8313838943_01bb882c5b_o.jpg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6691</th>\n",
       "      <td>8510748864_9ba44c5846_o.jpg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6692</th>\n",
       "      <td>8606243325_885ca2aed2_o.jpg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6693</th>\n",
       "      <td>8606245097_8aaa593d53_o.jpg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6694</th>\n",
       "      <td>8621547297_706919c027_o.jpg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6695</th>\n",
       "      <td>9000573343_ebd6946789_o.jpg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6696</th>\n",
       "      <td>9001757858_e00ae02e60_o.jpg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6697</th>\n",
       "      <td>9001759406_00d2dff905_o.jpg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6698</th>\n",
       "      <td>10009166853_a6b50b4117_o.jpg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6699</th>\n",
       "      <td>8194286207_1694e0a1fb_o.jpg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6700</th>\n",
       "      <td>8194289701_5a4d78126c_o.jpg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6701</th>\n",
       "      <td>8278120309_c60a8416f9_o.jpg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6702</th>\n",
       "      <td>8313838943_01bb882c5b_o.jpg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6703</th>\n",
       "      <td>8425634914_822664724a_o.jpg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6704</th>\n",
       "      <td>8510749730_7d107b6a6c_o.jpg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6705</th>\n",
       "      <td>8542958105_2672707f86_o.jpg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6706</th>\n",
       "      <td>8606243325_885ca2aed2_o.jpg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6707</th>\n",
       "      <td>8606245097_8aaa593d53_o.jpg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6708</th>\n",
       "      <td>8689479013_d5ddc429cc_o.jpg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6709</th>\n",
       "      <td>8690601272_7c2982b52f_o.jpg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6710</th>\n",
       "      <td>9000573343_ebd6946789_o.jpg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6711</th>\n",
       "      <td>9998952655_545d377dd2_o.jpg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6712</th>\n",
       "      <td>8299095416_67ff4ac0e9_o.jpg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6713</th>\n",
       "      <td>8885291628_84c931df3e_o.jpg</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>6714 rows × 1 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                    original_image\n",
       "0      8194283079_fe7c8c9b2f_o.jpg\n",
       "1      8314899476_8c1ac2e4bb_o.jpg\n",
       "2      8884658111_c692813a62_o.jpg\n",
       "3     10009166853_a6b50b4117_o.jpg\n",
       "4      8195375498_06c6fc5627_o.jpg\n",
       "5      8215787552_3198c25285_o.jpg\n",
       "6      8586120507_6c519d5923_o.jpg\n",
       "7      8314893776_8ddb4d4549_o.jpg\n",
       "8      8194283079_fe7c8c9b2f_o.jpg\n",
       "9      8469357784_ac74572242_o.jpg\n",
       "10     8313851951_3a0bd24aeb_o.jpg\n",
       "11     8314901670_835a0aec49_o.jpg\n",
       "12    11533025853_f3eb6ae6c7_o.jpg\n",
       "13    11486219815_c7725c3300_o.jpg\n",
       "14    11486520496_955dea5c71_o.jpg\n",
       "15    11486644334_fcd534e0ec_o.jpg\n",
       "16    11486726716_e0dcf8f67a_o.jpg\n",
       "17    11486731586_0c25a7d057_o.jpg\n",
       "18    11486800265_fed6909ed6_o.jpg\n",
       "19    11486804315_38016fa7a3_o.jpg\n",
       "20    11486850554_e39f75fb7e_o.jpg\n",
       "21    11486871145_20f34d8610_o.jpg\n",
       "22    11486871494_8ded06f48c_o.jpg\n",
       "23    11486879925_4f1e6e9a8a_o.jpg\n",
       "24    11486887194_5efdb501fa_o.jpg\n",
       "25    11486889344_27967040ff_o.jpg\n",
       "26    11486899924_c3eb356839_o.jpg\n",
       "27    11486916314_778b823dc2_o.jpg\n",
       "28    11486924966_c3d8cdbcc8_o.jpg\n",
       "29    11486965696_f2d3b39d7a_o.jpg\n",
       "...                            ...\n",
       "6684   9998955365_eff114f58a_o.jpg\n",
       "6685   9999002276_615e2e74f5_o.jpg\n",
       "6686   9999017466_ab44275470_o.jpg\n",
       "6687   9999085413_662fb85eb9_o.jpg\n",
       "6688  10009166853_a6b50b4117_o.jpg\n",
       "6689   8195382282_52f726fcca_o.jpg\n",
       "6690   8313838943_01bb882c5b_o.jpg\n",
       "6691   8510748864_9ba44c5846_o.jpg\n",
       "6692   8606243325_885ca2aed2_o.jpg\n",
       "6693   8606245097_8aaa593d53_o.jpg\n",
       "6694   8621547297_706919c027_o.jpg\n",
       "6695   9000573343_ebd6946789_o.jpg\n",
       "6696   9001757858_e00ae02e60_o.jpg\n",
       "6697   9001759406_00d2dff905_o.jpg\n",
       "6698  10009166853_a6b50b4117_o.jpg\n",
       "6699   8194286207_1694e0a1fb_o.jpg\n",
       "6700   8194289701_5a4d78126c_o.jpg\n",
       "6701   8278120309_c60a8416f9_o.jpg\n",
       "6702   8313838943_01bb882c5b_o.jpg\n",
       "6703   8425634914_822664724a_o.jpg\n",
       "6704   8510749730_7d107b6a6c_o.jpg\n",
       "6705   8542958105_2672707f86_o.jpg\n",
       "6706   8606243325_885ca2aed2_o.jpg\n",
       "6707   8606245097_8aaa593d53_o.jpg\n",
       "6708   8689479013_d5ddc429cc_o.jpg\n",
       "6709   8690601272_7c2982b52f_o.jpg\n",
       "6710   9000573343_ebd6946789_o.jpg\n",
       "6711   9998952655_545d377dd2_o.jpg\n",
       "6712   8299095416_67ff4ac0e9_o.jpg\n",
       "6713   8885291628_84c931df3e_o.jpg\n",
       "\n",
       "[6714 rows x 1 columns]"
      ]
     },
     "execution_count": 250,
>>>>>>> 5be6589eb73edd4cf96d0baea41a7ddc63f0aa24
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
<<<<<<< HEAD
    "Y_train_gender"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 477,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check if all have the same landmark length\n",
    "def check_len(X_train):\n",
    "    maxi = 0\n",
    "    mini = 100\n",
    "    for i in range(len(X_train)):\n",
    "        if len(X_train[i]) > maxi:\n",
    "            maxi = len(X_train[i])\n",
    "        if len(X_train[i]) < mini:\n",
    "            mini = len(X_train[i])\n",
    "    print(mini, maxi)"
=======
    "df_ids"
>>>>>>> 5be6589eb73edd4cf96d0baea41a7ddc63f0aa24
   ]
  },
  {
   "cell_type": "code",
<<<<<<< HEAD
   "execution_count": 480,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "68 68\n"
     ]
    }
   ],
   "source": [
    "check_len(X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 481,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Rework the shape of the numpy array\n",
    "def reshape(X_train):\n",
    "    for i in range(1, len(X_train)):\n",
    "        if i ==1:\n",
    "            inter = np.concatenate((X_train[0], X_train[1]), axis=0)\n",
    "        else:\n",
    "            inter = np.concatenate((inter, X_train[i]), axis=0)\n",
    "    inter = inter.reshape(len(X_train),68,2)\n",
    "    return inter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 482,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = reshape(X_train)\n",
    "X_val = reshape(X_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 483,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_input = X_train.reshape(len(X_train), 68*2)\n",
    "X_val_input = X_val.reshape(len(X_val), 68*2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 484,
=======
   "execution_count": 249,
>>>>>>> 5be6589eb73edd4cf96d0baea41a7ddc63f0aa24
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
<<<<<<< HEAD
       "(136,)"
      ]
     },
     "execution_count": 484,
=======
       "0"
      ]
     },
     "execution_count": 249,
>>>>>>> 5be6589eb73edd4cf96d0baea41a7ddc63f0aa24
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
<<<<<<< HEAD
   "source": [
    "X_train_input.shape[1:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 489,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "Building twe models: one for gender and one for age. Input is array with two columns, normal dense would suffice.\n",
    "We also use dropout for robustness\n",
    "'''\n",
    "model_gender = Sequential()\n",
    "model_gender.add(Dense(68, input_shape=(X_train_input.shape[1:])))  # Amount of landmarks is 68\n",
    "model_gender.add(Activation('relu'))\n",
    "model_gender.add(Dropout(0.2))\n",
    "model_gender.add(Dense(140))  \n",
    "model_gender.add(Activation('relu'))\n",
    "model_gender.add(Dense(100))  \n",
    "model_gender.add(Activation('relu'))\n",
    "model_gender.add(Dense(50))  \n",
    "model_gender.add(Activation('relu'))\n",
    "model_gender.add(Dense(10))  \n",
    "model_gender.add(Activation('relu'))\n",
    "model_gender.add(Dense(2))\n",
    "model_gender.add(Activation('sigmoid'))\n",
    "model_gender.compile(loss='binary_crossentropy',\n",
    "              optimizer='adam',\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "model_age = Sequential()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 490,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_125 (Dense)            (None, 68)                9316      \n",
      "_________________________________________________________________\n",
      "activation_117 (Activation)  (None, 68)                0         \n",
      "_________________________________________________________________\n",
      "dropout_40 (Dropout)         (None, 68)                0         \n",
      "_________________________________________________________________\n",
      "dense_126 (Dense)            (None, 140)               9660      \n",
      "_________________________________________________________________\n",
      "activation_118 (Activation)  (None, 140)               0         \n",
      "_________________________________________________________________\n",
      "dense_127 (Dense)            (None, 100)               14100     \n",
      "_________________________________________________________________\n",
      "activation_119 (Activation)  (None, 100)               0         \n",
      "_________________________________________________________________\n",
      "dense_128 (Dense)            (None, 50)                5050      \n",
      "_________________________________________________________________\n",
      "activation_120 (Activation)  (None, 50)                0         \n",
      "_________________________________________________________________\n",
      "dense_129 (Dense)            (None, 10)                510       \n",
      "_________________________________________________________________\n",
      "activation_121 (Activation)  (None, 10)                0         \n",
      "_________________________________________________________________\n",
      "dense_130 (Dense)            (None, 2)                 22        \n",
      "_________________________________________________________________\n",
      "activation_122 (Activation)  (None, 2)                 0         \n",
      "=================================================================\n",
      "Total params: 38,658\n",
      "Trainable params: 38,658\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model_gender.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 496,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 3424 samples, validate on 856 samples\n",
      "Epoch 1/500\n",
      "3424/3424 [==============================] - ETA: 0s - loss: 0.6932 - acc: 0.510 - ETA: 0s - loss: 0.6927 - acc: 0.516 - ETA: 0s - loss: 0.6925 - acc: 0.520 - 0s 41us/step - loss: 0.6926 - acc: 0.5194 - val_loss: 0.6917 - val_acc: 0.5339\n",
      "Epoch 2/500\n",
      "3424/3424 [==============================] - ETA: 0s - loss: 0.6912 - acc: 0.540 - ETA: 0s - loss: 0.6921 - acc: 0.528 - ETA: 0s - loss: 0.6929 - acc: 0.515 - 0s 46us/step - loss: 0.6925 - acc: 0.5216 - val_loss: 0.6912 - val_acc: 0.5386\n",
      "Epoch 3/500\n",
      "3424/3424 [==============================] - ETA: 0s - loss: 0.6866 - acc: 0.580 - ETA: 0s - loss: 0.6917 - acc: 0.525 - ETA: 0s - loss: 0.6923 - acc: 0.519 - 0s 49us/step - loss: 0.6925 - acc: 0.5174 - val_loss: 0.6914 - val_acc: 0.5339\n",
      "Epoch 4/500\n",
      "3424/3424 [==============================] - ETA: 0s - loss: 0.6888 - acc: 0.600 - ETA: 0s - loss: 0.6918 - acc: 0.532 - ETA: 0s - loss: 0.6924 - acc: 0.517 - 0s 49us/step - loss: 0.6925 - acc: 0.5177 - val_loss: 0.6916 - val_acc: 0.5339\n",
      "Epoch 5/500\n",
      "3424/3424 [==============================] - ETA: 0s - loss: 0.6937 - acc: 0.480 - ETA: 0s - loss: 0.6927 - acc: 0.512 - ETA: 0s - loss: 0.6919 - acc: 0.524 - ETA: 0s - loss: 0.6922 - acc: 0.519 - 0s 56us/step - loss: 0.6923 - acc: 0.5183 - val_loss: 0.6916 - val_acc: 0.5327\n",
      "Epoch 6/500\n",
      "3424/3424 [==============================] - ETA: 0s - loss: 0.6889 - acc: 0.565 - ETA: 0s - loss: 0.6922 - acc: 0.540 - ETA: 0s - loss: 0.6926 - acc: 0.526 - 0s 49us/step - loss: 0.6931 - acc: 0.5168 - val_loss: 0.6916 - val_acc: 0.5374\n",
      "Epoch 7/500\n",
      "3424/3424 [==============================] - ETA: 0s - loss: 0.6961 - acc: 0.455 - ETA: 0s - loss: 0.6928 - acc: 0.508 - ETA: 0s - loss: 0.6933 - acc: 0.509 - 0s 49us/step - loss: 0.6927 - acc: 0.5177 - val_loss: 0.6915 - val_acc: 0.5333\n",
      "Epoch 8/500\n",
      "3424/3424 [==============================] - ETA: 0s - loss: 0.6990 - acc: 0.465 - ETA: 0s - loss: 0.6925 - acc: 0.522 - ETA: 0s - loss: 0.6934 - acc: 0.508 - ETA: 0s - loss: 0.6931 - acc: 0.513 - 0s 53us/step - loss: 0.6931 - acc: 0.5145 - val_loss: 0.6916 - val_acc: 0.5345\n",
      "Epoch 9/500\n",
      "3424/3424 [==============================] - ETA: 0s - loss: 0.6985 - acc: 0.430 - ETA: 0s - loss: 0.6930 - acc: 0.510 - ETA: 0s - loss: 0.6928 - acc: 0.513 - ETA: 0s - loss: 0.6924 - acc: 0.519 - ETA: 0s - loss: 0.6924 - acc: 0.519 - 0s 69us/step - loss: 0.6926 - acc: 0.5178 - val_loss: 0.6912 - val_acc: 0.5350\n",
      "Epoch 10/500\n",
      "3424/3424 [==============================] - ETA: 0s - loss: 0.6908 - acc: 0.520 - ETA: 0s - loss: 0.6940 - acc: 0.512 - ETA: 0s - loss: 0.6928 - acc: 0.519 - ETA: 0s - loss: 0.6924 - acc: 0.522 - 0s 55us/step - loss: 0.6923 - acc: 0.5232 - val_loss: 0.6905 - val_acc: 0.5356\n",
      "Epoch 11/500\n",
      "3424/3424 [==============================] - ETA: 0s - loss: 0.6929 - acc: 0.510 - ETA: 0s - loss: 0.6911 - acc: 0.531 - ETA: 0s - loss: 0.6912 - acc: 0.531 - 0s 50us/step - loss: 0.6929 - acc: 0.5193 - val_loss: 0.6907 - val_acc: 0.5350\n",
      "Epoch 12/500\n",
      "3424/3424 [==============================] - ETA: 0s - loss: 0.6933 - acc: 0.500 - ETA: 0s - loss: 0.6909 - acc: 0.531 - ETA: 0s - loss: 0.6917 - acc: 0.519 - ETA: 0s - loss: 0.6925 - acc: 0.512 - 0s 59us/step - loss: 0.6935 - acc: 0.5118 - val_loss: 0.6947 - val_acc: 0.4988\n",
      "Epoch 13/500\n",
      "3424/3424 [==============================] - ETA: 0s - loss: 0.6993 - acc: 0.505 - ETA: 0s - loss: 0.6927 - acc: 0.517 - ETA: 0s - loss: 0.6932 - acc: 0.509 - ETA: 0s - loss: 0.6929 - acc: 0.516 - 0s 54us/step - loss: 0.6929 - acc: 0.5164 - val_loss: 0.6910 - val_acc: 0.5362\n",
      "Epoch 14/500\n",
      "3424/3424 [==============================] - ETA: 0s - loss: 0.6973 - acc: 0.465 - ETA: 0s - loss: 0.6926 - acc: 0.518 - ETA: 0s - loss: 0.6922 - acc: 0.523 - 0s 49us/step - loss: 0.6925 - acc: 0.5180 - val_loss: 0.6909 - val_acc: 0.5350\n",
      "Epoch 15/500\n",
      "3424/3424 [==============================] - ETA: 0s - loss: 0.6936 - acc: 0.515 - ETA: 0s - loss: 0.6907 - acc: 0.538 - ETA: 0s - loss: 0.6922 - acc: 0.519 - 0s 51us/step - loss: 0.6923 - acc: 0.5185 - val_loss: 0.6913 - val_acc: 0.5350\n",
      "Epoch 16/500\n",
      "3424/3424 [==============================] - ETA: 0s - loss: 0.6846 - acc: 0.630 - ETA: 0s - loss: 0.6916 - acc: 0.530 - ETA: 0s - loss: 0.6928 - acc: 0.513 - ETA: 0s - loss: 0.6926 - acc: 0.517 - 0s 53us/step - loss: 0.6925 - acc: 0.5184 - val_loss: 0.6915 - val_acc: 0.5350\n",
      "Epoch 17/500\n",
      "3424/3424 [==============================] - ETA: 0s - loss: 0.6945 - acc: 0.490 - ETA: 0s - loss: 0.6925 - acc: 0.517 - ETA: 0s - loss: 0.6932 - acc: 0.514 - 0s 52us/step - loss: 0.6927 - acc: 0.5185 - val_loss: 0.6914 - val_acc: 0.5350\n",
      "Epoch 18/500\n",
      "3424/3424 [==============================] - ETA: 0s - loss: 0.6930 - acc: 0.495 - ETA: 0s - loss: 0.6903 - acc: 0.545 - ETA: 0s - loss: 0.6918 - acc: 0.524 - ETA: 0s - loss: 0.6922 - acc: 0.520 - 0s 60us/step - loss: 0.6923 - acc: 0.5187 - val_loss: 0.6909 - val_acc: 0.5350\n",
      "Epoch 19/500\n",
      "3424/3424 [==============================] - ETA: 0s - loss: 0.6938 - acc: 0.500 - ETA: 0s - loss: 0.6927 - acc: 0.512 - ETA: 0s - loss: 0.6929 - acc: 0.512 - ETA: 0s - loss: 0.6925 - acc: 0.519 - 0s 54us/step - loss: 0.6926 - acc: 0.5183 - val_loss: 0.6912 - val_acc: 0.5345\n",
      "Epoch 20/500\n",
      "3424/3424 [==============================] - ETA: 0s - loss: 0.6910 - acc: 0.520 - ETA: 0s - loss: 0.6907 - acc: 0.536 - ETA: 0s - loss: 0.6917 - acc: 0.524 - 0s 49us/step - loss: 0.6922 - acc: 0.5168 - val_loss: 0.6911 - val_acc: 0.5350\n",
      "Epoch 21/500\n",
      "3424/3424 [==============================] - ETA: 0s - loss: 0.6921 - acc: 0.520 - ETA: 0s - loss: 0.6917 - acc: 0.523 - ETA: 0s - loss: 0.6915 - acc: 0.525 - 0s 50us/step - loss: 0.6925 - acc: 0.5175 - val_loss: 0.6909 - val_acc: 0.5356\n",
      "Epoch 22/500\n",
      "3424/3424 [==============================] - ETA: 0s - loss: 0.6936 - acc: 0.510 - ETA: 0s - loss: 0.6933 - acc: 0.498 - ETA: 0s - loss: 0.6929 - acc: 0.505 - ETA: 0s - loss: 0.6924 - acc: 0.513 - 0s 61us/step - loss: 0.6922 - acc: 0.5175 - val_loss: 0.6915 - val_acc: 0.5374\n",
      "Epoch 23/500\n",
      "3424/3424 [==============================] - ETA: 0s - loss: 0.6917 - acc: 0.520 - ETA: 0s - loss: 0.6927 - acc: 0.512 - ETA: 0s - loss: 0.6924 - acc: 0.519 - 0s 50us/step - loss: 0.6924 - acc: 0.5181 - val_loss: 0.6909 - val_acc: 0.5362\n",
      "Epoch 24/500\n",
      "3424/3424 [==============================] - ETA: 0s - loss: 0.6961 - acc: 0.460 - ETA: 0s - loss: 0.6933 - acc: 0.502 - ETA: 0s - loss: 0.6927 - acc: 0.504 - 0s 50us/step - loss: 0.6924 - acc: 0.5134 - val_loss: 0.6915 - val_acc: 0.5362\n",
      "Epoch 25/500\n",
      "3424/3424 [==============================] - ETA: 0s - loss: 0.6943 - acc: 0.545 - ETA: 0s - loss: 0.6930 - acc: 0.517 - ETA: 0s - loss: 0.6920 - acc: 0.524 - ETA: 0s - loss: 0.6924 - acc: 0.517 - 0s 53us/step - loss: 0.6923 - acc: 0.5183 - val_loss: 0.6914 - val_acc: 0.5350\n",
      "Epoch 26/500\n",
      "3424/3424 [==============================] - ETA: 0s - loss: 0.6945 - acc: 0.485 - ETA: 0s - loss: 0.6915 - acc: 0.525 - ETA: 0s - loss: 0.6918 - acc: 0.521 - 0s 49us/step - loss: 0.6921 - acc: 0.5177 - val_loss: 0.6909 - val_acc: 0.5350\n",
      "Epoch 27/500\n",
      "3424/3424 [==============================] - ETA: 0s - loss: 0.6891 - acc: 0.560 - ETA: 0s - loss: 0.6922 - acc: 0.511 - ETA: 0s - loss: 0.6920 - acc: 0.516 - 0s 49us/step - loss: 0.6921 - acc: 0.5185 - val_loss: 0.6908 - val_acc: 0.5356\n",
      "Epoch 28/500\n",
      "3424/3424 [==============================] - ETA: 0s - loss: 0.6928 - acc: 0.505 - ETA: 0s - loss: 0.6938 - acc: 0.498 - ETA: 0s - loss: 0.6928 - acc: 0.512 - ETA: 0s - loss: 0.6923 - acc: 0.518 - 0s 53us/step - loss: 0.6923 - acc: 0.5184 - val_loss: 0.6911 - val_acc: 0.5356\n",
      "Epoch 29/500\n",
      "3424/3424 [==============================] - ETA: 0s - loss: 0.6899 - acc: 0.550 - ETA: 0s - loss: 0.6921 - acc: 0.519 - ETA: 0s - loss: 0.6925 - acc: 0.511 - 0s 49us/step - loss: 0.6920 - acc: 0.5185 - val_loss: 0.6915 - val_acc: 0.5350\n",
      "Epoch 30/500\n",
      "3424/3424 [==============================] - ETA: 0s - loss: 0.6919 - acc: 0.525 - ETA: 0s - loss: 0.6915 - acc: 0.531 - ETA: 0s - loss: 0.6928 - acc: 0.517 - 0s 51us/step - loss: 0.6926 - acc: 0.5181 - val_loss: 0.6909 - val_acc: 0.5362\n",
      "Epoch 31/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3424/3424 [==============================] - ETA: 0s - loss: 0.6960 - acc: 0.530 - ETA: 0s - loss: 0.6938 - acc: 0.501 - ETA: 0s - loss: 0.6931 - acc: 0.510 - 0s 49us/step - loss: 0.6922 - acc: 0.5194 - val_loss: 0.6910 - val_acc: 0.5356\n",
      "Epoch 32/500\n",
      "3424/3424 [==============================] - ETA: 0s - loss: 0.6954 - acc: 0.505 - ETA: 0s - loss: 0.6927 - acc: 0.510 - ETA: 0s - loss: 0.6910 - acc: 0.529 - ETA: 0s - loss: 0.6916 - acc: 0.522 - 0s 64us/step - loss: 0.6918 - acc: 0.5200 - val_loss: 0.6909 - val_acc: 0.5345\n",
      "Epoch 33/500\n",
      "3424/3424 [==============================] - ETA: 0s - loss: 0.6951 - acc: 0.475 - ETA: 0s - loss: 0.6920 - acc: 0.511 - ETA: 0s - loss: 0.6927 - acc: 0.507 - ETA: 0s - loss: 0.6919 - acc: 0.516 - 0s 58us/step - loss: 0.6917 - acc: 0.5199 - val_loss: 0.6916 - val_acc: 0.5350\n",
      "Epoch 34/500\n",
      "3424/3424 [==============================] - ETA: 0s - loss: 0.6954 - acc: 0.490 - ETA: 0s - loss: 0.6917 - acc: 0.528 - ETA: 0s - loss: 0.6927 - acc: 0.515 - 0s 49us/step - loss: 0.6922 - acc: 0.5187 - val_loss: 0.6908 - val_acc: 0.5356\n",
      "Epoch 35/500\n",
      "3424/3424 [==============================] - ETA: 0s - loss: 0.6996 - acc: 0.425 - ETA: 0s - loss: 0.6926 - acc: 0.509 - ETA: 0s - loss: 0.6927 - acc: 0.508 - ETA: 0s - loss: 0.6921 - acc: 0.518 - 0s 53us/step - loss: 0.6920 - acc: 0.5187 - val_loss: 0.6913 - val_acc: 0.5362\n",
      "Epoch 36/500\n",
      "3424/3424 [==============================] - ETA: 0s - loss: 0.6984 - acc: 0.440 - ETA: 0s - loss: 0.6937 - acc: 0.496 - ETA: 0s - loss: 0.6914 - acc: 0.525 - 0s 49us/step - loss: 0.6918 - acc: 0.5202 - val_loss: 0.6909 - val_acc: 0.5350\n",
      "Epoch 37/500\n",
      "3424/3424 [==============================] - ETA: 0s - loss: 0.6909 - acc: 0.540 - ETA: 0s - loss: 0.6939 - acc: 0.490 - ETA: 0s - loss: 0.6943 - acc: 0.494 - ETA: 0s - loss: 0.6933 - acc: 0.506 - 0s 55us/step - loss: 0.6933 - acc: 0.5066 - val_loss: 0.6905 - val_acc: 0.5350\n",
      "Epoch 38/500\n",
      "3424/3424 [==============================] - ETA: 0s - loss: 0.6908 - acc: 0.520 - ETA: 0s - loss: 0.6930 - acc: 0.507 - ETA: 0s - loss: 0.6915 - acc: 0.525 - ETA: 0s - loss: 0.6917 - acc: 0.521 - 0s 55us/step - loss: 0.6919 - acc: 0.5190 - val_loss: 0.6905 - val_acc: 0.5368\n",
      "Epoch 39/500\n",
      "3424/3424 [==============================] - ETA: 0s - loss: 0.6940 - acc: 0.500 - ETA: 0s - loss: 0.6913 - acc: 0.521 - ETA: 0s - loss: 0.6921 - acc: 0.516 - 0s 50us/step - loss: 0.6921 - acc: 0.5164 - val_loss: 0.6908 - val_acc: 0.5345\n",
      "Epoch 40/500\n",
      "3424/3424 [==============================] - ETA: 0s - loss: 0.6932 - acc: 0.500 - ETA: 0s - loss: 0.6927 - acc: 0.507 - ETA: 0s - loss: 0.6922 - acc: 0.513 - ETA: 0s - loss: 0.6920 - acc: 0.518 - 0s 58us/step - loss: 0.6920 - acc: 0.5185 - val_loss: 0.6905 - val_acc: 0.5345\n",
      "Epoch 41/500\n",
      "3424/3424 [==============================] - ETA: 0s - loss: 0.6927 - acc: 0.495 - ETA: 0s - loss: 0.6922 - acc: 0.518 - ETA: 0s - loss: 0.6922 - acc: 0.520 - ETA: 0s - loss: 0.6919 - acc: 0.521 - 0s 59us/step - loss: 0.6922 - acc: 0.5184 - val_loss: 0.6906 - val_acc: 0.5350\n",
      "Epoch 42/500\n",
      "3424/3424 [==============================] - ETA: 0s - loss: 0.6939 - acc: 0.500 - ETA: 0s - loss: 0.6925 - acc: 0.505 - ETA: 0s - loss: 0.6927 - acc: 0.511 - ETA: 0s - loss: 0.6922 - acc: 0.515 - 0s 60us/step - loss: 0.6919 - acc: 0.5191 - val_loss: 0.6905 - val_acc: 0.5356\n",
      "Epoch 43/500\n",
      "3424/3424 [==============================] - ETA: 0s - loss: 0.6916 - acc: 0.530 - ETA: 0s - loss: 0.6904 - acc: 0.537 - ETA: 0s - loss: 0.6910 - acc: 0.531 - 0s 51us/step - loss: 0.6919 - acc: 0.5185 - val_loss: 0.6903 - val_acc: 0.5339\n",
      "Epoch 44/500\n",
      "3424/3424 [==============================] - ETA: 0s - loss: 0.6962 - acc: 0.475 - ETA: 0s - loss: 0.6923 - acc: 0.514 - ETA: 0s - loss: 0.6918 - acc: 0.517 - ETA: 0s - loss: 0.6920 - acc: 0.518 - 0s 55us/step - loss: 0.6920 - acc: 0.5187 - val_loss: 0.6904 - val_acc: 0.5356\n",
      "Epoch 45/500\n",
      "3424/3424 [==============================] - ETA: 0s - loss: 0.6950 - acc: 0.470 - ETA: 0s - loss: 0.6921 - acc: 0.512 - ETA: 0s - loss: 0.6924 - acc: 0.511 - ETA: 0s - loss: 0.6919 - acc: 0.517 - 0s 59us/step - loss: 0.6918 - acc: 0.5191 - val_loss: 0.6907 - val_acc: 0.5339\n",
      "Epoch 46/500\n",
      "3424/3424 [==============================] - ETA: 0s - loss: 0.6947 - acc: 0.485 - ETA: 0s - loss: 0.6917 - acc: 0.516 - ETA: 0s - loss: 0.6912 - acc: 0.519 - ETA: 0s - loss: 0.6918 - acc: 0.522 - ETA: 0s - loss: 0.6918 - acc: 0.520 - 0s 74us/step - loss: 0.6919 - acc: 0.5196 - val_loss: 0.6903 - val_acc: 0.5356\n",
      "Epoch 47/500\n",
      "3424/3424 [==============================] - ETA: 0s - loss: 0.6934 - acc: 0.490 - ETA: 0s - loss: 0.6920 - acc: 0.514 - ETA: 0s - loss: 0.6914 - acc: 0.524 - ETA: 0s - loss: 0.6914 - acc: 0.522 - 0s 69us/step - loss: 0.6918 - acc: 0.5199 - val_loss: 0.6904 - val_acc: 0.5380\n",
      "Epoch 48/500\n",
      "3424/3424 [==============================] - ETA: 0s - loss: 0.6858 - acc: 0.605 - ETA: 0s - loss: 0.6923 - acc: 0.521 - ETA: 0s - loss: 0.6915 - acc: 0.519 - 0s 51us/step - loss: 0.6915 - acc: 0.5197 - val_loss: 0.6907 - val_acc: 0.5356\n",
      "Epoch 49/500\n",
      "3424/3424 [==============================] - ETA: 0s - loss: 0.6890 - acc: 0.475 - ETA: 0s - loss: 0.6910 - acc: 0.528 - ETA: 0s - loss: 0.6916 - acc: 0.522 - ETA: 0s - loss: 0.6914 - acc: 0.521 - 0s 53us/step - loss: 0.6914 - acc: 0.5218 - val_loss: 0.6902 - val_acc: 0.5350\n",
      "Epoch 50/500\n",
      "3424/3424 [==============================] - ETA: 0s - loss: 0.6838 - acc: 0.590 - ETA: 0s - loss: 0.6884 - acc: 0.548 - ETA: 0s - loss: 0.6927 - acc: 0.528 - ETA: 0s - loss: 0.6928 - acc: 0.518 - 0s 58us/step - loss: 0.6930 - acc: 0.5166 - val_loss: 0.6901 - val_acc: 0.5345\n",
      "Epoch 51/500\n",
      "3424/3424 [==============================] - ETA: 0s - loss: 0.6876 - acc: 0.545 - ETA: 0s - loss: 0.6904 - acc: 0.526 - ETA: 0s - loss: 0.6912 - acc: 0.522 - ETA: 0s - loss: 0.6914 - acc: 0.524 - 0s 59us/step - loss: 0.6920 - acc: 0.5190 - val_loss: 0.6901 - val_acc: 0.5362\n",
      "Epoch 52/500\n",
      "3424/3424 [==============================] - ETA: 0s - loss: 0.6948 - acc: 0.525 - ETA: 0s - loss: 0.6923 - acc: 0.516 - ETA: 0s - loss: 0.6919 - acc: 0.518 - ETA: 0s - loss: 0.6923 - acc: 0.515 - 0s 58us/step - loss: 0.6921 - acc: 0.5181 - val_loss: 0.6910 - val_acc: 0.5356\n",
      "Epoch 53/500\n",
      "3424/3424 [==============================] - ETA: 0s - loss: 0.6993 - acc: 0.440 - ETA: 0s - loss: 0.6909 - acc: 0.523 - ETA: 0s - loss: 0.6913 - acc: 0.525 - ETA: 0s - loss: 0.6916 - acc: 0.522 - 0s 57us/step - loss: 0.6916 - acc: 0.5204 - val_loss: 0.6904 - val_acc: 0.5374\n",
      "Epoch 54/500\n",
      "3424/3424 [==============================] - ETA: 0s - loss: 0.6864 - acc: 0.585 - ETA: 0s - loss: 0.6924 - acc: 0.517 - ETA: 0s - loss: 0.6922 - acc: 0.518 - ETA: 0s - loss: 0.6919 - acc: 0.523 - 0s 53us/step - loss: 0.6919 - acc: 0.5229 - val_loss: 0.6938 - val_acc: 0.5105\n",
      "Epoch 55/500\n",
      "3424/3424 [==============================] - ETA: 0s - loss: 0.7056 - acc: 0.415 - ETA: 0s - loss: 0.6930 - acc: 0.512 - ETA: 0s - loss: 0.6925 - acc: 0.510 - ETA: 0s - loss: 0.6924 - acc: 0.516 - 0s 55us/step - loss: 0.6925 - acc: 0.5152 - val_loss: 0.6903 - val_acc: 0.5350\n",
      "Epoch 56/500\n",
      "3424/3424 [==============================] - ETA: 0s - loss: 0.6970 - acc: 0.460 - ETA: 0s - loss: 0.6922 - acc: 0.522 - ETA: 0s - loss: 0.6915 - acc: 0.528 - ETA: 0s - loss: 0.6919 - acc: 0.520 - 0s 55us/step - loss: 0.6920 - acc: 0.5200 - val_loss: 0.6905 - val_acc: 0.5356\n",
      "Epoch 57/500\n",
      "3424/3424 [==============================] - ETA: 0s - loss: 0.6875 - acc: 0.525 - ETA: 0s - loss: 0.6926 - acc: 0.512 - ETA: 0s - loss: 0.6927 - acc: 0.513 - ETA: 0s - loss: 0.6925 - acc: 0.515 - 0s 62us/step - loss: 0.6919 - acc: 0.5191 - val_loss: 0.6904 - val_acc: 0.5368\n",
      "Epoch 58/500\n",
      "3424/3424 [==============================] - ETA: 0s - loss: 0.6935 - acc: 0.510 - ETA: 0s - loss: 0.6927 - acc: 0.518 - ETA: 0s - loss: 0.6920 - acc: 0.519 - 0s 50us/step - loss: 0.6919 - acc: 0.5190 - val_loss: 0.6903 - val_acc: 0.5362\n",
      "Epoch 59/500\n",
      "3424/3424 [==============================] - ETA: 0s - loss: 0.6943 - acc: 0.490 - ETA: 0s - loss: 0.6926 - acc: 0.509 - ETA: 0s - loss: 0.6919 - acc: 0.511 - ETA: 0s - loss: 0.6919 - acc: 0.517 - 0s 55us/step - loss: 0.6918 - acc: 0.5196 - val_loss: 0.6913 - val_acc: 0.5345\n",
      "Epoch 60/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3424/3424 [==============================] - ETA: 0s - loss: 0.6931 - acc: 0.500 - ETA: 0s - loss: 0.6917 - acc: 0.510 - ETA: 0s - loss: 0.6917 - acc: 0.520 - ETA: 0s - loss: 0.6922 - acc: 0.515 - 0s 56us/step - loss: 0.6919 - acc: 0.5191 - val_loss: 0.6905 - val_acc: 0.5356\n",
      "Epoch 61/500\n",
      "3424/3424 [==============================] - ETA: 0s - loss: 0.6856 - acc: 0.620 - ETA: 0s - loss: 0.6920 - acc: 0.516 - ETA: 0s - loss: 0.6924 - acc: 0.513 - ETA: 0s - loss: 0.6918 - acc: 0.518 - 0s 57us/step - loss: 0.6918 - acc: 0.5193 - val_loss: 0.6905 - val_acc: 0.5345\n",
      "Epoch 62/500\n",
      "3424/3424 [==============================] - ETA: 0s - loss: 0.6958 - acc: 0.470 - ETA: 0s - loss: 0.6921 - acc: 0.525 - ETA: 0s - loss: 0.6923 - acc: 0.512 - ETA: 0s - loss: 0.6916 - acc: 0.520 - 0s 60us/step - loss: 0.6917 - acc: 0.5196 - val_loss: 0.6903 - val_acc: 0.5356\n",
      "Epoch 63/500\n",
      "3424/3424 [==============================] - ETA: 0s - loss: 0.6899 - acc: 0.550 - ETA: 0s - loss: 0.6911 - acc: 0.535 - ETA: 0s - loss: 0.6923 - acc: 0.518 - ETA: 0s - loss: 0.6923 - acc: 0.515 - 0s 57us/step - loss: 0.6918 - acc: 0.5196 - val_loss: 0.6902 - val_acc: 0.5356\n",
      "Epoch 64/500\n",
      "3424/3424 [==============================] - ETA: 0s - loss: 0.6855 - acc: 0.535 - ETA: 0s - loss: 0.6898 - acc: 0.540 - ETA: 0s - loss: 0.6901 - acc: 0.537 - ETA: 0s - loss: 0.6919 - acc: 0.517 - 0s 54us/step - loss: 0.6919 - acc: 0.5180 - val_loss: 0.6897 - val_acc: 0.5356\n",
      "Epoch 65/500\n",
      "3424/3424 [==============================] - ETA: 0s - loss: 0.6969 - acc: 0.460 - ETA: 0s - loss: 0.6904 - acc: 0.537 - ETA: 0s - loss: 0.6910 - acc: 0.531 - ETA: 0s - loss: 0.6916 - acc: 0.520 - 0s 57us/step - loss: 0.6915 - acc: 0.5194 - val_loss: 0.6920 - val_acc: 0.5292\n",
      "Epoch 66/500\n",
      "3424/3424 [==============================] - ETA: 0s - loss: 0.6928 - acc: 0.445 - ETA: 0s - loss: 0.6910 - acc: 0.517 - ETA: 0s - loss: 0.6916 - acc: 0.520 - ETA: 0s - loss: 0.6919 - acc: 0.518 - 0s 59us/step - loss: 0.6918 - acc: 0.5171 - val_loss: 0.6905 - val_acc: 0.5356\n",
      "Epoch 67/500\n",
      "3424/3424 [==============================] - ETA: 0s - loss: 0.6976 - acc: 0.450 - ETA: 0s - loss: 0.6937 - acc: 0.498 - ETA: 0s - loss: 0.6928 - acc: 0.510 - ETA: 0s - loss: 0.6919 - acc: 0.515 - 0s 57us/step - loss: 0.6917 - acc: 0.5196 - val_loss: 0.6903 - val_acc: 0.5362\n",
      "Epoch 68/500\n",
      "3424/3424 [==============================] - ETA: 0s - loss: 0.6882 - acc: 0.510 - ETA: 0s - loss: 0.6922 - acc: 0.510 - ETA: 0s - loss: 0.6916 - acc: 0.520 - ETA: 0s - loss: 0.6917 - acc: 0.518 - 0s 55us/step - loss: 0.6917 - acc: 0.5197 - val_loss: 0.6908 - val_acc: 0.5368\n",
      "Epoch 69/500\n",
      "3424/3424 [==============================] - ETA: 0s - loss: 0.6937 - acc: 0.495 - ETA: 0s - loss: 0.6934 - acc: 0.495 - ETA: 0s - loss: 0.6931 - acc: 0.507 - ETA: 0s - loss: 0.6925 - acc: 0.515 - 0s 62us/step - loss: 0.6923 - acc: 0.5187 - val_loss: 0.6903 - val_acc: 0.5350\n",
      "Epoch 70/500\n",
      "3424/3424 [==============================] - ETA: 0s - loss: 0.6926 - acc: 0.520 - ETA: 0s - loss: 0.6926 - acc: 0.516 - ETA: 0s - loss: 0.6914 - acc: 0.520 - ETA: 0s - loss: 0.6920 - acc: 0.519 - 0s 61us/step - loss: 0.6919 - acc: 0.5197 - val_loss: 0.6901 - val_acc: 0.5350\n",
      "Epoch 71/500\n",
      "3424/3424 [==============================] - ETA: 0s - loss: 0.6868 - acc: 0.590 - ETA: 0s - loss: 0.6896 - acc: 0.535 - ETA: 0s - loss: 0.6916 - acc: 0.525 - ETA: 0s - loss: 0.6916 - acc: 0.524 - ETA: 0s - loss: 0.6919 - acc: 0.520 - 0s 76us/step - loss: 0.6918 - acc: 0.5203 - val_loss: 0.6907 - val_acc: 0.5362\n",
      "Epoch 72/500\n",
      "3424/3424 [==============================] - ETA: 0s - loss: 0.6877 - acc: 0.580 - ETA: 0s - loss: 0.6936 - acc: 0.511 - ETA: 0s - loss: 0.6927 - acc: 0.517 - ETA: 0s - loss: 0.6921 - acc: 0.523 - 0s 70us/step - loss: 0.6936 - acc: 0.5174 - val_loss: 0.6902 - val_acc: 0.5368\n",
      "Epoch 73/500\n",
      "3424/3424 [==============================] - ETA: 0s - loss: 0.6930 - acc: 0.530 - ETA: 0s - loss: 0.6928 - acc: 0.509 - ETA: 0s - loss: 0.6934 - acc: 0.501 - ETA: 0s - loss: 0.6925 - acc: 0.514 - 0s 64us/step - loss: 0.6920 - acc: 0.5196 - val_loss: 0.6913 - val_acc: 0.5350\n",
      "Epoch 74/500\n",
      "3424/3424 [==============================] - ETA: 0s - loss: 0.6957 - acc: 0.480 - ETA: 0s - loss: 0.6912 - acc: 0.528 - ETA: 0s - loss: 0.6926 - acc: 0.517 - ETA: 0s - loss: 0.6927 - acc: 0.513 - 0s 58us/step - loss: 0.6922 - acc: 0.5185 - val_loss: 0.6907 - val_acc: 0.5350\n",
      "Epoch 75/500\n",
      "3424/3424 [==============================] - ETA: 0s - loss: 0.6973 - acc: 0.470 - ETA: 0s - loss: 0.6921 - acc: 0.525 - ETA: 0s - loss: 0.6923 - acc: 0.517 - ETA: 0s - loss: 0.6922 - acc: 0.520 - 0s 60us/step - loss: 0.6920 - acc: 0.5197 - val_loss: 0.6907 - val_acc: 0.5345\n",
      "Epoch 76/500\n",
      "3424/3424 [==============================] - ETA: 0s - loss: 0.6905 - acc: 0.500 - ETA: 0s - loss: 0.6936 - acc: 0.499 - ETA: 0s - loss: 0.6922 - acc: 0.520 - ETA: 0s - loss: 0.6922 - acc: 0.520 - 0s 66us/step - loss: 0.6924 - acc: 0.5181 - val_loss: 0.6911 - val_acc: 0.5345\n",
      "Epoch 77/500\n",
      "3424/3424 [==============================] - ETA: 0s - loss: 0.6879 - acc: 0.570 - ETA: 0s - loss: 0.6918 - acc: 0.522 - ETA: 0s - loss: 0.6923 - acc: 0.516 - ETA: 0s - loss: 0.6921 - acc: 0.520 - 0s 59us/step - loss: 0.6921 - acc: 0.5194 - val_loss: 0.6910 - val_acc: 0.5339\n",
      "Epoch 78/500\n",
      "3424/3424 [==============================] - ETA: 0s - loss: 0.6945 - acc: 0.510 - ETA: 0s - loss: 0.6916 - acc: 0.525 - ETA: 0s - loss: 0.6906 - acc: 0.532 - ETA: 0s - loss: 0.6918 - acc: 0.522 - 0s 59us/step - loss: 0.6919 - acc: 0.5200 - val_loss: 0.6897 - val_acc: 0.5339\n",
      "Epoch 79/500\n",
      "3424/3424 [==============================] - ETA: 0s - loss: 0.6966 - acc: 0.470 - ETA: 0s - loss: 0.6924 - acc: 0.517 - ETA: 0s - loss: 0.6924 - acc: 0.525 - ETA: 0s - loss: 0.6926 - acc: 0.518 - 0s 58us/step - loss: 0.6924 - acc: 0.5188 - val_loss: 0.6905 - val_acc: 0.5345\n",
      "Epoch 80/500\n",
      "3424/3424 [==============================] - ETA: 0s - loss: 0.6955 - acc: 0.480 - ETA: 0s - loss: 0.6929 - acc: 0.514 - ETA: 0s - loss: 0.6927 - acc: 0.515 - ETA: 0s - loss: 0.6920 - acc: 0.520 - 0s 57us/step - loss: 0.6919 - acc: 0.5191 - val_loss: 0.6898 - val_acc: 0.5327\n",
      "Epoch 81/500\n",
      "3424/3424 [==============================] - ETA: 0s - loss: 0.6915 - acc: 0.530 - ETA: 0s - loss: 0.6929 - acc: 0.500 - ETA: 0s - loss: 0.6920 - acc: 0.514 - ETA: 0s - loss: 0.6919 - acc: 0.520 - 0s 57us/step - loss: 0.6919 - acc: 0.5193 - val_loss: 0.6905 - val_acc: 0.5321\n",
      "Epoch 82/500\n",
      "3424/3424 [==============================] - ETA: 0s - loss: 0.7009 - acc: 0.420 - ETA: 0s - loss: 0.6927 - acc: 0.511 - ETA: 0s - loss: 0.6917 - acc: 0.520 - ETA: 0s - loss: 0.6920 - acc: 0.518 - 0s 59us/step - loss: 0.6919 - acc: 0.5188 - val_loss: 0.6905 - val_acc: 0.5321\n",
      "Epoch 83/500\n",
      "3424/3424 [==============================] - ETA: 0s - loss: 0.6930 - acc: 0.570 - ETA: 0s - loss: 0.6907 - acc: 0.529 - ETA: 0s - loss: 0.6914 - acc: 0.521 - ETA: 0s - loss: 0.6918 - acc: 0.522 - 0s 61us/step - loss: 0.6920 - acc: 0.5191 - val_loss: 0.6904 - val_acc: 0.5345\n",
      "Epoch 84/500\n",
      "3424/3424 [==============================] - ETA: 0s - loss: 0.6954 - acc: 0.480 - ETA: 0s - loss: 0.6901 - acc: 0.545 - ETA: 0s - loss: 0.6919 - acc: 0.520 - ETA: 0s - loss: 0.6920 - acc: 0.519 - 0s 59us/step - loss: 0.6918 - acc: 0.5190 - val_loss: 0.6906 - val_acc: 0.5339\n",
      "Epoch 85/500\n",
      "3424/3424 [==============================] - ETA: 0s - loss: 0.6973 - acc: 0.450 - ETA: 0s - loss: 0.6916 - acc: 0.520 - ETA: 0s - loss: 0.6920 - acc: 0.515 - ETA: 0s - loss: 0.6920 - acc: 0.516 - 0s 69us/step - loss: 0.6919 - acc: 0.5197 - val_loss: 0.6906 - val_acc: 0.5339\n",
      "Epoch 86/500\n",
      "3424/3424 [==============================] - ETA: 0s - loss: 0.6900 - acc: 0.560 - ETA: 0s - loss: 0.6933 - acc: 0.499 - ETA: 0s - loss: 0.6920 - acc: 0.516 - ETA: 0s - loss: 0.6916 - acc: 0.519 - 0s 61us/step - loss: 0.6918 - acc: 0.5197 - val_loss: 0.6907 - val_acc: 0.5333\n",
      "Epoch 87/500\n",
      "3424/3424 [==============================] - ETA: 0s - loss: 0.6924 - acc: 0.520 - ETA: 0s - loss: 0.6910 - acc: 0.535 - ETA: 0s - loss: 0.6915 - acc: 0.529 - ETA: 0s - loss: 0.6922 - acc: 0.520 - 0s 59us/step - loss: 0.6923 - acc: 0.5187 - val_loss: 0.6915 - val_acc: 0.5310\n",
      "Epoch 88/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3424/3424 [==============================] - ETA: 0s - loss: 0.6938 - acc: 0.500 - ETA: 0s - loss: 0.6915 - acc: 0.521 - ETA: 0s - loss: 0.6922 - acc: 0.516 - ETA: 0s - loss: 0.6920 - acc: 0.519 - 0s 62us/step - loss: 0.6920 - acc: 0.5196 - val_loss: 0.6910 - val_acc: 0.5327\n",
      "Epoch 89/500\n",
      "3424/3424 [==============================] - ETA: 0s - loss: 0.6937 - acc: 0.500 - ETA: 0s - loss: 0.6915 - acc: 0.519 - ETA: 0s - loss: 0.6922 - acc: 0.518 - ETA: 0s - loss: 0.6921 - acc: 0.519 - 0s 58us/step - loss: 0.6921 - acc: 0.5199 - val_loss: 0.6910 - val_acc: 0.5339\n",
      "Epoch 90/500\n",
      "3424/3424 [==============================] - ETA: 0s - loss: 0.6937 - acc: 0.500 - ETA: 0s - loss: 0.6922 - acc: 0.523 - ETA: 0s - loss: 0.6912 - acc: 0.527 - ETA: 0s - loss: 0.6919 - acc: 0.520 - 0s 56us/step - loss: 0.6920 - acc: 0.5190 - val_loss: 0.6909 - val_acc: 0.5321\n",
      "Epoch 91/500\n",
      "3424/3424 [==============================] - ETA: 0s - loss: 0.6866 - acc: 0.600 - ETA: 0s - loss: 0.6908 - acc: 0.536 - ETA: 0s - loss: 0.6922 - acc: 0.512 - ETA: 0s - loss: 0.6916 - acc: 0.521 - 0s 57us/step - loss: 0.6918 - acc: 0.5193 - val_loss: 0.6906 - val_acc: 0.5327\n",
      "Epoch 92/500\n",
      "3424/3424 [==============================] - ETA: 0s - loss: 0.6903 - acc: 0.550 - ETA: 0s - loss: 0.6897 - acc: 0.542 - ETA: 0s - loss: 0.6910 - acc: 0.526 - ETA: 0s - loss: 0.6913 - acc: 0.522 - 0s 60us/step - loss: 0.6917 - acc: 0.5196 - val_loss: 0.6901 - val_acc: 0.5327\n",
      "Epoch 93/500\n",
      "3424/3424 [==============================] - ETA: 0s - loss: 0.6931 - acc: 0.510 - ETA: 0s - loss: 0.6923 - acc: 0.527 - ETA: 0s - loss: 0.6927 - acc: 0.522 - ETA: 0s - loss: 0.6922 - acc: 0.521 - 0s 62us/step - loss: 0.6922 - acc: 0.5194 - val_loss: 0.6908 - val_acc: 0.5327\n",
      "Epoch 94/500\n",
      "3424/3424 [==============================] - ETA: 0s - loss: 0.6917 - acc: 0.530 - ETA: 0s - loss: 0.6917 - acc: 0.515 - ETA: 0s - loss: 0.6914 - acc: 0.523 - ETA: 0s - loss: 0.6918 - acc: 0.520 - 0s 60us/step - loss: 0.6918 - acc: 0.5197 - val_loss: 0.6914 - val_acc: 0.5350\n",
      "Epoch 95/500\n",
      "3424/3424 [==============================] - ETA: 0s - loss: 0.6924 - acc: 0.520 - ETA: 0s - loss: 0.6910 - acc: 0.522 - ETA: 0s - loss: 0.6926 - acc: 0.515 - ETA: 0s - loss: 0.6925 - acc: 0.512 - 0s 62us/step - loss: 0.6923 - acc: 0.5187 - val_loss: 0.6914 - val_acc: 0.5356\n",
      "Epoch 96/500\n",
      "3424/3424 [==============================] - ETA: 0s - loss: 0.6903 - acc: 0.550 - ETA: 0s - loss: 0.6915 - acc: 0.524 - ETA: 0s - loss: 0.6918 - acc: 0.522 - ETA: 0s - loss: 0.6922 - acc: 0.518 - 0s 63us/step - loss: 0.6921 - acc: 0.5190 - val_loss: 0.6904 - val_acc: 0.5356\n",
      "Epoch 97/500\n",
      "3424/3424 [==============================] - ETA: 0s - loss: 0.6938 - acc: 0.500 - ETA: 0s - loss: 0.6915 - acc: 0.521 - ETA: 0s - loss: 0.6918 - acc: 0.522 - ETA: 0s - loss: 0.6919 - acc: 0.520 - 0s 55us/step - loss: 0.6920 - acc: 0.5193 - val_loss: 0.6905 - val_acc: 0.5356\n",
      "Epoch 98/500\n",
      "3424/3424 [==============================] - ETA: 0s - loss: 0.6938 - acc: 0.500 - ETA: 0s - loss: 0.6907 - acc: 0.532 - ETA: 0s - loss: 0.6902 - acc: 0.536 - ETA: 0s - loss: 0.6916 - acc: 0.521 - 0s 57us/step - loss: 0.6917 - acc: 0.5196 - val_loss: 0.6906 - val_acc: 0.5333\n",
      "Epoch 99/500\n",
      "3424/3424 [==============================] - ETA: 0s - loss: 0.6912 - acc: 0.560 - ETA: 0s - loss: 0.6924 - acc: 0.509 - ETA: 0s - loss: 0.6910 - acc: 0.525 - ETA: 0s - loss: 0.6918 - acc: 0.521 - 0s 61us/step - loss: 0.6920 - acc: 0.5190 - val_loss: 0.6912 - val_acc: 0.5339\n",
      "Epoch 100/500\n",
      "3424/3424 [==============================] - ETA: 0s - loss: 0.6938 - acc: 0.500 - ETA: 0s - loss: 0.6924 - acc: 0.504 - ETA: 0s - loss: 0.6919 - acc: 0.520 - ETA: 0s - loss: 0.6919 - acc: 0.519 - 0s 57us/step - loss: 0.6919 - acc: 0.5196 - val_loss: 0.6911 - val_acc: 0.5333\n",
      "Epoch 101/500\n",
      "3424/3424 [==============================] - ETA: 0s - loss: 0.6945 - acc: 0.490 - ETA: 0s - loss: 0.6923 - acc: 0.518 - ETA: 0s - loss: 0.6914 - acc: 0.520 - ETA: 0s - loss: 0.6916 - acc: 0.519 - 0s 55us/step - loss: 0.6917 - acc: 0.5193 - val_loss: 0.6900 - val_acc: 0.5321\n",
      "Epoch 102/500\n",
      "3424/3424 [==============================] - ETA: 0s - loss: 0.6953 - acc: 0.480 - ETA: 0s - loss: 0.6921 - acc: 0.522 - ETA: 0s - loss: 0.6915 - acc: 0.525 - ETA: 0s - loss: 0.6921 - acc: 0.519 - 0s 56us/step - loss: 0.6921 - acc: 0.5197 - val_loss: 0.6909 - val_acc: 0.5345\n",
      "Epoch 103/500\n",
      "3424/3424 [==============================] - ETA: 0s - loss: 0.6872 - acc: 0.590 - ETA: 0s - loss: 0.6930 - acc: 0.506 - ETA: 0s - loss: 0.6923 - acc: 0.510 - ETA: 0s - loss: 0.6916 - acc: 0.521 - 0s 60us/step - loss: 0.6919 - acc: 0.5190 - val_loss: 0.6913 - val_acc: 0.5333\n",
      "Epoch 104/500\n",
      "3424/3424 [==============================] - ETA: 0s - loss: 0.6901 - acc: 0.550 - ETA: 0s - loss: 0.6928 - acc: 0.511 - ETA: 0s - loss: 0.6923 - acc: 0.512 - ETA: 0s - loss: 0.6921 - acc: 0.513 - 0s 68us/step - loss: 0.6920 - acc: 0.5194 - val_loss: 0.6908 - val_acc: 0.5356\n",
      "Epoch 105/500\n",
      "3424/3424 [==============================] - ETA: 0s - loss: 0.6883 - acc: 0.530 - ETA: 0s - loss: 0.6905 - acc: 0.520 - ETA: 0s - loss: 0.6907 - acc: 0.524 - ETA: 0s - loss: 0.6920 - acc: 0.520 - 0s 62us/step - loss: 0.6920 - acc: 0.5191 - val_loss: 0.6911 - val_acc: 0.5321\n",
      "Epoch 106/500\n",
      "3424/3424 [==============================] - ETA: 0s - loss: 0.6962 - acc: 0.470 - ETA: 0s - loss: 0.6921 - acc: 0.508 - ETA: 0s - loss: 0.6917 - acc: 0.515 - ETA: 0s - loss: 0.6917 - acc: 0.514 - ETA: 0s - loss: 0.6921 - acc: 0.518 - 0s 72us/step - loss: 0.6921 - acc: 0.5183 - val_loss: 0.6910 - val_acc: 0.5321\n",
      "Epoch 107/500\n",
      "3424/3424 [==============================] - ETA: 0s - loss: 0.6859 - acc: 0.610 - ETA: 0s - loss: 0.6918 - acc: 0.525 - ETA: 0s - loss: 0.6911 - acc: 0.536 - ETA: 0s - loss: 0.6919 - acc: 0.523 - 0s 59us/step - loss: 0.6923 - acc: 0.5188 - val_loss: 0.6917 - val_acc: 0.5304\n",
      "Epoch 108/500\n",
      "3424/3424 [==============================] - ETA: 0s - loss: 0.6885 - acc: 0.570 - ETA: 0s - loss: 0.6928 - acc: 0.512 - ETA: 0s - loss: 0.6929 - acc: 0.513 - ETA: 0s - loss: 0.6921 - acc: 0.521 - 0s 56us/step - loss: 0.6923 - acc: 0.5184 - val_loss: 0.6908 - val_acc: 0.5345\n",
      "Epoch 109/500\n",
      "3424/3424 [==============================] - ETA: 0s - loss: 0.6894 - acc: 0.560 - ETA: 0s - loss: 0.6921 - acc: 0.515 - ETA: 0s - loss: 0.6930 - acc: 0.511 - ETA: 0s - loss: 0.6923 - acc: 0.518 - 0s 60us/step - loss: 0.6923 - acc: 0.5188 - val_loss: 0.6909 - val_acc: 0.5350\n",
      "Epoch 110/500\n",
      "3424/3424 [==============================] - ETA: 0s - loss: 0.6960 - acc: 0.470 - ETA: 0s - loss: 0.6920 - acc: 0.523 - ETA: 0s - loss: 0.6923 - acc: 0.520 - ETA: 0s - loss: 0.6916 - acc: 0.523 - 0s 62us/step - loss: 0.6919 - acc: 0.5194 - val_loss: 0.6903 - val_acc: 0.5327\n",
      "Epoch 111/500\n",
      "3424/3424 [==============================] - ETA: 0s - loss: 0.6887 - acc: 0.450 - ETA: 0s - loss: 0.6905 - acc: 0.530 - ETA: 0s - loss: 0.6920 - acc: 0.515 - ETA: 0s - loss: 0.6920 - acc: 0.519 - 0s 58us/step - loss: 0.6920 - acc: 0.5190 - val_loss: 0.6918 - val_acc: 0.5304\n",
      "Epoch 112/500\n",
      "3424/3424 [==============================] - ETA: 0s - loss: 0.6888 - acc: 0.560 - ETA: 0s - loss: 0.6923 - acc: 0.520 - ETA: 0s - loss: 0.6923 - acc: 0.519 - ETA: 0s - loss: 0.6922 - acc: 0.519 - 0s 58us/step - loss: 0.6921 - acc: 0.5193 - val_loss: 0.6908 - val_acc: 0.5333\n",
      "Epoch 113/500\n",
      "3424/3424 [==============================] - ETA: 0s - loss: 0.6901 - acc: 0.530 - ETA: 0s - loss: 0.6927 - acc: 0.506 - ETA: 0s - loss: 0.6917 - acc: 0.518 - ETA: 0s - loss: 0.6915 - acc: 0.521 - 0s 65us/step - loss: 0.6919 - acc: 0.5190 - val_loss: 0.6913 - val_acc: 0.5333\n",
      "Epoch 114/500\n",
      "3424/3424 [==============================] - ETA: 0s - loss: 0.6938 - acc: 0.500 - ETA: 0s - loss: 0.6920 - acc: 0.525 - ETA: 0s - loss: 0.6906 - acc: 0.525 - ETA: 0s - loss: 0.6920 - acc: 0.518 - 0s 63us/step - loss: 0.6920 - acc: 0.5196 - val_loss: 0.6907 - val_acc: 0.5345\n",
      "Epoch 115/500\n",
      "3424/3424 [==============================] - ETA: 0s - loss: 0.6887 - acc: 0.570 - ETA: 0s - loss: 0.6932 - acc: 0.508 - ETA: 0s - loss: 0.6927 - acc: 0.513 - ETA: 0s - loss: 0.6914 - acc: 0.522 - 0s 58us/step - loss: 0.6922 - acc: 0.5200 - val_loss: 0.6899 - val_acc: 0.5333\n",
      "Epoch 116/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3424/3424 [==============================] - ETA: 0s - loss: 0.6862 - acc: 0.520 - ETA: 0s - loss: 0.6930 - acc: 0.504 - ETA: 0s - loss: 0.6926 - acc: 0.504 - ETA: 0s - loss: 0.6919 - acc: 0.517 - 0s 57us/step - loss: 0.6918 - acc: 0.5191 - val_loss: 0.6908 - val_acc: 0.5350\n",
      "Epoch 117/500\n",
      "3424/3424 [==============================] - ETA: 0s - loss: 0.6924 - acc: 0.520 - ETA: 0s - loss: 0.6916 - acc: 0.524 - ETA: 0s - loss: 0.6921 - acc: 0.521 - ETA: 0s - loss: 0.6916 - acc: 0.525 - 0s 59us/step - loss: 0.6921 - acc: 0.5199 - val_loss: 0.6907 - val_acc: 0.5350\n",
      "Epoch 118/500\n",
      "3424/3424 [==============================] - ETA: 0s - loss: 0.6892 - acc: 0.560 - ETA: 0s - loss: 0.6919 - acc: 0.517 - ETA: 0s - loss: 0.6917 - acc: 0.520 - ETA: 0s - loss: 0.6916 - acc: 0.518 - 0s 55us/step - loss: 0.6917 - acc: 0.5191 - val_loss: 0.6902 - val_acc: 0.5339\n",
      "Epoch 119/500\n",
      "3424/3424 [==============================] - ETA: 0s - loss: 0.6916 - acc: 0.530 - ETA: 0s - loss: 0.6919 - acc: 0.520 - ETA: 0s - loss: 0.6927 - acc: 0.510 - ETA: 0s - loss: 0.6924 - acc: 0.515 - 0s 60us/step - loss: 0.6921 - acc: 0.5191 - val_loss: 0.6912 - val_acc: 0.5345\n",
      "Epoch 120/500\n",
      "3424/3424 [==============================] - ETA: 0s - loss: 0.6953 - acc: 0.480 - ETA: 0s - loss: 0.6914 - acc: 0.530 - ETA: 0s - loss: 0.6917 - acc: 0.523 - ETA: 0s - loss: 0.6920 - acc: 0.523 - 0s 60us/step - loss: 0.6922 - acc: 0.5190 - val_loss: 0.6923 - val_acc: 0.5333\n",
      "Epoch 121/500\n",
      "3424/3424 [==============================] - ETA: 0s - loss: 0.7010 - acc: 0.450 - ETA: 0s - loss: 0.6927 - acc: 0.517 - ETA: 0s - loss: 0.6925 - acc: 0.517 - ETA: 0s - loss: 0.6925 - acc: 0.516 - 0s 60us/step - loss: 0.6923 - acc: 0.5191 - val_loss: 0.6909 - val_acc: 0.5356\n",
      "Epoch 122/500\n",
      "3424/3424 [==============================] - ETA: 0s - loss: 0.6974 - acc: 0.480 - ETA: 0s - loss: 0.6905 - acc: 0.528 - ETA: 0s - loss: 0.6917 - acc: 0.527 - ETA: 0s - loss: 0.6923 - acc: 0.518 - 0s 61us/step - loss: 0.6922 - acc: 0.5196 - val_loss: 0.6914 - val_acc: 0.5333\n",
      "Epoch 123/500\n",
      "3424/3424 [==============================] - ETA: 0s - loss: 0.6931 - acc: 0.510 - ETA: 0s - loss: 0.6916 - acc: 0.530 - ETA: 0s - loss: 0.6931 - acc: 0.508 - ETA: 0s - loss: 0.6925 - acc: 0.516 - 0s 68us/step - loss: 0.6924 - acc: 0.5184 - val_loss: 0.6921 - val_acc: 0.5310\n",
      "Epoch 124/500\n",
      "3424/3424 [==============================] - ETA: 0s - loss: 0.6977 - acc: 0.450 - ETA: 0s - loss: 0.6919 - acc: 0.518 - ETA: 0s - loss: 0.6911 - acc: 0.521 - ETA: 0s - loss: 0.6915 - acc: 0.521 - 0s 60us/step - loss: 0.6919 - acc: 0.5188 - val_loss: 0.6908 - val_acc: 0.5350\n",
      "Epoch 125/500\n",
      "3424/3424 [==============================] - ETA: 0s - loss: 0.6847 - acc: 0.620 - ETA: 0s - loss: 0.6905 - acc: 0.537 - ETA: 0s - loss: 0.6914 - acc: 0.522 - ETA: 0s - loss: 0.6917 - acc: 0.520 - 0s 55us/step - loss: 0.6918 - acc: 0.5199 - val_loss: 0.6909 - val_acc: 0.5350\n",
      "Epoch 126/500\n",
      "3424/3424 [==============================] - ETA: 0s - loss: 0.6790 - acc: 0.560 - ETA: 0s - loss: 0.6927 - acc: 0.503 - ETA: 0s - loss: 0.6923 - acc: 0.509 - ETA: 0s - loss: 0.6918 - acc: 0.518 - 0s 63us/step - loss: 0.6918 - acc: 0.5193 - val_loss: 0.6926 - val_acc: 0.5315\n",
      "Epoch 127/500\n",
      "3424/3424 [==============================] - ETA: 0s - loss: 0.6939 - acc: 0.500 - ETA: 0s - loss: 0.6933 - acc: 0.499 - ETA: 0s - loss: 0.6931 - acc: 0.507 - ETA: 0s - loss: 0.6920 - acc: 0.519 - 0s 59us/step - loss: 0.6919 - acc: 0.5193 - val_loss: 0.6893 - val_acc: 0.5362\n",
      "Epoch 128/500\n",
      "3424/3424 [==============================] - ETA: 0s - loss: 0.6917 - acc: 0.460 - ETA: 0s - loss: 0.6931 - acc: 0.519 - ETA: 0s - loss: 0.6924 - acc: 0.519 - ETA: 0s - loss: 0.6924 - acc: 0.519 - 0s 54us/step - loss: 0.6924 - acc: 0.5191 - val_loss: 0.6916 - val_acc: 0.5327\n",
      "Epoch 129/500\n",
      "3424/3424 [==============================] - ETA: 0s - loss: 0.6939 - acc: 0.500 - ETA: 0s - loss: 0.6904 - acc: 0.522 - ETA: 0s - loss: 0.6937 - acc: 0.519 - ETA: 0s - loss: 0.6931 - acc: 0.519 - 0s 62us/step - loss: 0.6930 - acc: 0.5187 - val_loss: 0.6913 - val_acc: 0.5333\n",
      "Epoch 130/500\n",
      "3424/3424 [==============================] - ETA: 0s - loss: 0.6970 - acc: 0.460 - ETA: 0s - loss: 0.6925 - acc: 0.515 - ETA: 0s - loss: 0.6925 - acc: 0.515 - ETA: 0s - loss: 0.6923 - acc: 0.517 - 0s 56us/step - loss: 0.6923 - acc: 0.5188 - val_loss: 0.6920 - val_acc: 0.5310\n",
      "Epoch 131/500\n",
      "3424/3424 [==============================] - ETA: 0s - loss: 0.6860 - acc: 0.595 - ETA: 0s - loss: 0.6925 - acc: 0.508 - ETA: 0s - loss: 0.6925 - acc: 0.513 - ETA: 0s - loss: 0.6922 - acc: 0.517 - 0s 57us/step - loss: 0.6921 - acc: 0.5185 - val_loss: 0.6905 - val_acc: 0.5362\n",
      "Epoch 132/500\n",
      "3424/3424 [==============================] - ETA: 0s - loss: 0.6990 - acc: 0.430 - ETA: 0s - loss: 0.6915 - acc: 0.510 - ETA: 0s - loss: 0.6919 - acc: 0.514 - ETA: 0s - loss: 0.6920 - acc: 0.519 - 0s 55us/step - loss: 0.6921 - acc: 0.5187 - val_loss: 0.6917 - val_acc: 0.5310\n",
      "Epoch 133/500\n",
      "3424/3424 [==============================] - ETA: 0s - loss: 0.6946 - acc: 0.490 - ETA: 0s - loss: 0.6935 - acc: 0.502 - ETA: 0s - loss: 0.6922 - acc: 0.515 - ETA: 0s - loss: 0.6921 - acc: 0.520 - 0s 54us/step - loss: 0.6922 - acc: 0.5190 - val_loss: 0.6920 - val_acc: 0.5339\n",
      "Epoch 134/500\n",
      "3424/3424 [==============================] - ETA: 0s - loss: 0.6886 - acc: 0.570 - ETA: 0s - loss: 0.6916 - acc: 0.514 - ETA: 0s - loss: 0.6921 - acc: 0.517 - 0s 50us/step - loss: 0.6922 - acc: 0.5188 - val_loss: 0.6907 - val_acc: 0.5356\n",
      "Epoch 135/500\n",
      "3424/3424 [==============================] - ETA: 0s - loss: 0.6887 - acc: 0.570 - ETA: 0s - loss: 0.6913 - acc: 0.526 - ETA: 0s - loss: 0.6917 - acc: 0.520 - ETA: 0s - loss: 0.6916 - acc: 0.522 - 0s 55us/step - loss: 0.6918 - acc: 0.5196 - val_loss: 0.6905 - val_acc: 0.5356\n",
      "Epoch 136/500\n",
      "3424/3424 [==============================] - ETA: 0s - loss: 0.6960 - acc: 0.470 - ETA: 0s - loss: 0.6947 - acc: 0.487 - ETA: 0s - loss: 0.6933 - acc: 0.500 - ETA: 0s - loss: 0.6917 - acc: 0.521 - 0s 56us/step - loss: 0.6921 - acc: 0.5194 - val_loss: 0.6902 - val_acc: 0.5350\n",
      "Epoch 137/500\n",
      "3424/3424 [==============================] - ETA: 0s - loss: 0.6924 - acc: 0.520 - ETA: 0s - loss: 0.6908 - acc: 0.533 - ETA: 0s - loss: 0.6918 - acc: 0.520 - ETA: 0s - loss: 0.6919 - acc: 0.519 - 0s 54us/step - loss: 0.6919 - acc: 0.5190 - val_loss: 0.6915 - val_acc: 0.5339\n",
      "Epoch 138/500\n",
      "3424/3424 [==============================] - ETA: 0s - loss: 0.6885 - acc: 0.570 - ETA: 0s - loss: 0.6924 - acc: 0.517 - ETA: 0s - loss: 0.6925 - acc: 0.520 - ETA: 0s - loss: 0.6919 - acc: 0.519 - 0s 59us/step - loss: 0.6919 - acc: 0.5199 - val_loss: 0.6899 - val_acc: 0.5362\n",
      "Epoch 139/500\n",
      "3424/3424 [==============================] - ETA: 0s - loss: 0.6901 - acc: 0.550 - ETA: 0s - loss: 0.6908 - acc: 0.515 - ETA: 0s - loss: 0.6919 - acc: 0.515 - ETA: 0s - loss: 0.6921 - acc: 0.520 - 0s 58us/step - loss: 0.6921 - acc: 0.5194 - val_loss: 0.6915 - val_acc: 0.5321\n",
      "Epoch 140/500\n",
      "3424/3424 [==============================] - ETA: 0s - loss: 0.6991 - acc: 0.440 - ETA: 0s - loss: 0.6926 - acc: 0.510 - ETA: 0s - loss: 0.6926 - acc: 0.513 - ETA: 0s - loss: 0.6921 - acc: 0.518 - 0s 55us/step - loss: 0.6920 - acc: 0.5194 - val_loss: 0.6916 - val_acc: 0.5339\n",
      "Epoch 141/500\n",
      "3424/3424 [==============================] - ETA: 0s - loss: 0.6835 - acc: 0.530 - ETA: 0s - loss: 0.6909 - acc: 0.525 - ETA: 0s - loss: 0.6921 - acc: 0.517 - ETA: 0s - loss: 0.6922 - acc: 0.516 - 0s 55us/step - loss: 0.6921 - acc: 0.5188 - val_loss: 0.6905 - val_acc: 0.5362\n",
      "Epoch 142/500\n",
      "3424/3424 [==============================] - ETA: 0s - loss: 0.6868 - acc: 0.590 - ETA: 0s - loss: 0.6913 - acc: 0.525 - ETA: 0s - loss: 0.6916 - acc: 0.521 - ETA: 0s - loss: 0.6917 - acc: 0.522 - 0s 60us/step - loss: 0.6919 - acc: 0.5194 - val_loss: 0.6904 - val_acc: 0.5362\n",
      "Epoch 143/500\n",
      "3424/3424 [==============================] - ETA: 0s - loss: 0.6811 - acc: 0.570 - ETA: 0s - loss: 0.6907 - acc: 0.532 - ETA: 0s - loss: 0.6921 - acc: 0.524 - ETA: 0s - loss: 0.6923 - acc: 0.519 - 0s 56us/step - loss: 0.6923 - acc: 0.5190 - val_loss: 0.6908 - val_acc: 0.5350\n",
      "Epoch 144/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3424/3424 [==============================] - ETA: 0s - loss: 0.6989 - acc: 0.440 - ETA: 0s - loss: 0.6916 - acc: 0.515 - ETA: 0s - loss: 0.6919 - acc: 0.506 - ETA: 0s - loss: 0.6918 - acc: 0.519 - 0s 62us/step - loss: 0.6916 - acc: 0.5203 - val_loss: 0.6899 - val_acc: 0.5362\n",
      "Epoch 145/500\n",
      "3424/3424 [==============================] - ETA: 0s - loss: 0.6907 - acc: 0.540 - ETA: 0s - loss: 0.6910 - acc: 0.519 - ETA: 0s - loss: 0.6918 - acc: 0.519 - ETA: 0s - loss: 0.6915 - acc: 0.521 - 0s 58us/step - loss: 0.6918 - acc: 0.5190 - val_loss: 0.6911 - val_acc: 0.5339\n",
      "Epoch 146/500\n",
      "3424/3424 [==============================] - ETA: 0s - loss: 0.6964 - acc: 0.470 - ETA: 0s - loss: 0.6918 - acc: 0.526 - ETA: 0s - loss: 0.6922 - acc: 0.519 - ETA: 0s - loss: 0.6918 - acc: 0.522 - 0s 63us/step - loss: 0.6921 - acc: 0.5190 - val_loss: 0.6908 - val_acc: 0.5350\n",
      "Epoch 147/500\n",
      "3424/3424 [==============================] - ETA: 0s - loss: 0.6908 - acc: 0.540 - ETA: 0s - loss: 0.6924 - acc: 0.508 - ETA: 0s - loss: 0.6917 - acc: 0.526 - ETA: 0s - loss: 0.6918 - acc: 0.518 - ETA: 0s - loss: 0.6920 - acc: 0.517 - 0s 72us/step - loss: 0.6918 - acc: 0.5194 - val_loss: 0.6904 - val_acc: 0.5356\n",
      "Epoch 148/500\n",
      "3424/3424 [==============================] - ETA: 0s - loss: 0.6916 - acc: 0.530 - ETA: 0s - loss: 0.6928 - acc: 0.510 - ETA: 0s - loss: 0.6920 - acc: 0.514 - ETA: 0s - loss: 0.6924 - acc: 0.518 - 0s 60us/step - loss: 0.6922 - acc: 0.5191 - val_loss: 0.6912 - val_acc: 0.5333\n",
      "Epoch 149/500\n",
      "3424/3424 [==============================] - ETA: 0s - loss: 0.6896 - acc: 0.545 - ETA: 0s - loss: 0.6920 - acc: 0.523 - ETA: 0s - loss: 0.6916 - acc: 0.528 - ETA: 0s - loss: 0.6927 - acc: 0.516 - ETA: 0s - loss: 0.6922 - acc: 0.517 - 0s 81us/step - loss: 0.6922 - acc: 0.5185 - val_loss: 0.6907 - val_acc: 0.5350\n",
      "Epoch 150/500\n",
      "3424/3424 [==============================] - ETA: 0s - loss: 0.6885 - acc: 0.570 - ETA: 0s - loss: 0.6916 - acc: 0.523 - ETA: 0s - loss: 0.6916 - acc: 0.527 - ETA: 0s - loss: 0.6923 - acc: 0.518 - ETA: 0s - loss: 0.6920 - acc: 0.519 - 0s 73us/step - loss: 0.6921 - acc: 0.5196 - val_loss: 0.6904 - val_acc: 0.5362\n",
      "Epoch 151/500\n",
      "3424/3424 [==============================] - ETA: 0s - loss: 0.6992 - acc: 0.430 - ETA: 0s - loss: 0.6913 - acc: 0.516 - ETA: 0s - loss: 0.6931 - acc: 0.506 - ETA: 0s - loss: 0.6922 - acc: 0.513 - 0s 59us/step - loss: 0.6917 - acc: 0.5199 - val_loss: 0.6906 - val_acc: 0.5362\n",
      "Epoch 152/500\n",
      "3424/3424 [==============================] - ETA: 0s - loss: 0.6895 - acc: 0.560 - ETA: 0s - loss: 0.6915 - acc: 0.528 - ETA: 0s - loss: 0.6931 - acc: 0.517 - ETA: 0s - loss: 0.6926 - acc: 0.515 - 0s 66us/step - loss: 0.6924 - acc: 0.5188 - val_loss: 0.6907 - val_acc: 0.5362\n",
      "Epoch 153/500\n",
      "3424/3424 [==============================] - ETA: 0s - loss: 0.6938 - acc: 0.500 - ETA: 0s - loss: 0.6924 - acc: 0.518 - ETA: 0s - loss: 0.6923 - acc: 0.520 - ETA: 0s - loss: 0.6924 - acc: 0.517 - 0s 57us/step - loss: 0.6922 - acc: 0.5193 - val_loss: 0.6904 - val_acc: 0.5362\n",
      "Epoch 154/500\n",
      "3424/3424 [==============================] - ETA: 0s - loss: 0.6924 - acc: 0.520 - ETA: 0s - loss: 0.6918 - acc: 0.521 - ETA: 0s - loss: 0.6925 - acc: 0.511 - ETA: 0s - loss: 0.6924 - acc: 0.513 - 0s 66us/step - loss: 0.6921 - acc: 0.5193 - val_loss: 0.6903 - val_acc: 0.5362\n",
      "Epoch 155/500\n",
      "3424/3424 [==============================] - ETA: 0s - loss: 0.6887 - acc: 0.570 - ETA: 0s - loss: 0.6912 - acc: 0.534 - ETA: 0s - loss: 0.6913 - acc: 0.522 - ETA: 0s - loss: 0.6921 - acc: 0.517 - 0s 70us/step - loss: 0.6920 - acc: 0.5196 - val_loss: 0.6906 - val_acc: 0.5362\n",
      "Epoch 156/500\n",
      "3424/3424 [==============================] - ETA: 0s - loss: 0.6911 - acc: 0.510 - ETA: 0s - loss: 0.6923 - acc: 0.512 - ETA: 0s - loss: 0.6914 - acc: 0.524 - ETA: 0s - loss: 0.6911 - acc: 0.524 - 0s 59us/step - loss: 0.6914 - acc: 0.5197 - val_loss: 0.6901 - val_acc: 0.5362\n",
      "Epoch 157/500\n",
      "3424/3424 [==============================] - ETA: 0s - loss: 0.6919 - acc: 0.525 - ETA: 0s - loss: 0.6928 - acc: 0.507 - ETA: 0s - loss: 0.6919 - acc: 0.519 - ETA: 0s - loss: 0.6918 - acc: 0.521 - 0s 57us/step - loss: 0.6922 - acc: 0.5193 - val_loss: 0.6907 - val_acc: 0.5350\n",
      "Epoch 158/500\n",
      "3424/3424 [==============================] - ETA: 0s - loss: 0.6931 - acc: 0.510 - ETA: 0s - loss: 0.6945 - acc: 0.494 - ETA: 0s - loss: 0.6931 - acc: 0.510 - ETA: 0s - loss: 0.6927 - acc: 0.513 - 0s 59us/step - loss: 0.6922 - acc: 0.5191 - val_loss: 0.6908 - val_acc: 0.5350\n",
      "Epoch 159/500\n",
      "3424/3424 [==============================] - ETA: 0s - loss: 0.6891 - acc: 0.550 - ETA: 0s - loss: 0.6905 - acc: 0.526 - ETA: 0s - loss: 0.6917 - acc: 0.516 - ETA: 0s - loss: 0.6916 - acc: 0.521 - 0s 61us/step - loss: 0.6916 - acc: 0.5199 - val_loss: 0.6896 - val_acc: 0.5362\n",
      "Epoch 160/500\n",
      "3424/3424 [==============================] - ETA: 0s - loss: 0.6946 - acc: 0.490 - ETA: 0s - loss: 0.6913 - acc: 0.534 - ETA: 0s - loss: 0.6919 - acc: 0.522 - ETA: 0s - loss: 0.6920 - acc: 0.522 - 0s 62us/step - loss: 0.6923 - acc: 0.5184 - val_loss: 0.6913 - val_acc: 0.5333\n",
      "Epoch 161/500\n",
      "3424/3424 [==============================] - ETA: 0s - loss: 0.6931 - acc: 0.510 - ETA: 0s - loss: 0.6921 - acc: 0.524 - ETA: 0s - loss: 0.6920 - acc: 0.521 - ETA: 0s - loss: 0.6923 - acc: 0.518 - 0s 59us/step - loss: 0.6923 - acc: 0.5185 - val_loss: 0.6911 - val_acc: 0.5345\n",
      "Epoch 162/500\n",
      "3424/3424 [==============================] - ETA: 0s - loss: 0.6931 - acc: 0.510 - ETA: 0s - loss: 0.6916 - acc: 0.524 - ETA: 0s - loss: 0.6919 - acc: 0.516 - ETA: 0s - loss: 0.6920 - acc: 0.515 - 0s 59us/step - loss: 0.6918 - acc: 0.5196 - val_loss: 0.6902 - val_acc: 0.5362\n",
      "Epoch 163/500\n",
      "3424/3424 [==============================] - ETA: 0s - loss: 0.6924 - acc: 0.520 - ETA: 0s - loss: 0.6928 - acc: 0.515 - ETA: 0s - loss: 0.6916 - acc: 0.526 - ETA: 0s - loss: 0.6919 - acc: 0.520 - 0s 59us/step - loss: 0.6920 - acc: 0.5193 - val_loss: 0.6902 - val_acc: 0.5362\n",
      "Epoch 164/500\n",
      "3424/3424 [==============================] - ETA: 0s - loss: 0.6900 - acc: 0.550 - ETA: 0s - loss: 0.6918 - acc: 0.526 - ETA: 0s - loss: 0.6912 - acc: 0.524 - ETA: 0s - loss: 0.6921 - acc: 0.518 - 0s 59us/step - loss: 0.6922 - acc: 0.5185 - val_loss: 0.6911 - val_acc: 0.5345\n",
      "Epoch 165/500\n",
      "3424/3424 [==============================] - ETA: 0s - loss: 0.6939 - acc: 0.500 - ETA: 0s - loss: 0.6924 - acc: 0.514 - ETA: 0s - loss: 0.6921 - acc: 0.516 - ETA: 0s - loss: 0.6922 - acc: 0.518 - 0s 57us/step - loss: 0.6922 - acc: 0.5194 - val_loss: 0.6903 - val_acc: 0.5362\n",
      "Epoch 166/500\n",
      "3424/3424 [==============================] - ETA: 0s - loss: 0.6962 - acc: 0.470 - ETA: 0s - loss: 0.6925 - acc: 0.517 - ETA: 0s - loss: 0.6913 - acc: 0.530 - ETA: 0s - loss: 0.6919 - acc: 0.519 - 0s 56us/step - loss: 0.6920 - acc: 0.5194 - val_loss: 0.6900 - val_acc: 0.5362\n",
      "Epoch 167/500\n",
      "3424/3424 [==============================] - ETA: 0s - loss: 0.6994 - acc: 0.430 - ETA: 0s - loss: 0.6923 - acc: 0.511 - ETA: 0s - loss: 0.6915 - acc: 0.523 - ETA: 0s - loss: 0.6917 - acc: 0.522 - 0s 62us/step - loss: 0.6919 - acc: 0.5193 - val_loss: 0.6905 - val_acc: 0.5362\n",
      "Epoch 168/500\n",
      "3424/3424 [==============================] - ETA: 0s - loss: 0.6916 - acc: 0.530 - ETA: 0s - loss: 0.6924 - acc: 0.512 - ETA: 0s - loss: 0.6923 - acc: 0.513 - ETA: 0s - loss: 0.6923 - acc: 0.514 - 0s 63us/step - loss: 0.6920 - acc: 0.5191 - val_loss: 0.6908 - val_acc: 0.5350\n",
      "Epoch 169/500\n",
      "3424/3424 [==============================] - ETA: 0s - loss: 0.6938 - acc: 0.500 - ETA: 0s - loss: 0.6920 - acc: 0.525 - ETA: 0s - loss: 0.6929 - acc: 0.511 - ETA: 0s - loss: 0.6924 - acc: 0.516 - 0s 65us/step - loss: 0.6922 - acc: 0.5190 - val_loss: 0.6914 - val_acc: 0.5327\n",
      "Epoch 170/500\n",
      "3424/3424 [==============================] - ETA: 0s - loss: 0.6976 - acc: 0.450 - ETA: 0s - loss: 0.6915 - acc: 0.528 - ETA: 0s - loss: 0.6927 - acc: 0.514 - ETA: 0s - loss: 0.6925 - acc: 0.514 - 0s 58us/step - loss: 0.6923 - acc: 0.5187 - val_loss: 0.6910 - val_acc: 0.5350\n",
      "Epoch 171/500\n",
      "3424/3424 [==============================] - ETA: 0s - loss: 0.6872 - acc: 0.590 - ETA: 0s - loss: 0.6905 - acc: 0.542 - ETA: 0s - loss: 0.6910 - acc: 0.532 - ETA: 0s - loss: 0.6917 - acc: 0.521 - 0s 58us/step - loss: 0.6920 - acc: 0.5194 - val_loss: 0.6903 - val_acc: 0.5362\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 172/500\n",
      "3424/3424 [==============================] - ETA: 0s - loss: 0.6908 - acc: 0.540 - ETA: 0s - loss: 0.6903 - acc: 0.538 - ETA: 0s - loss: 0.6914 - acc: 0.526 - ETA: 0s - loss: 0.6917 - acc: 0.524 - 0s 60us/step - loss: 0.6921 - acc: 0.5193 - val_loss: 0.6903 - val_acc: 0.5362\n",
      "Epoch 173/500\n",
      "3424/3424 [==============================] - ETA: 0s - loss: 0.6859 - acc: 0.560 - ETA: 0s - loss: 0.6924 - acc: 0.516 - ETA: 0s - loss: 0.6929 - acc: 0.508 - ETA: 0s - loss: 0.6920 - acc: 0.514 - ETA: 0s - loss: 0.6920 - acc: 0.518 - 0s 73us/step - loss: 0.6919 - acc: 0.5193 - val_loss: 0.6902 - val_acc: 0.5362\n",
      "Epoch 174/500\n",
      "3424/3424 [==============================] - ETA: 0s - loss: 0.6872 - acc: 0.590 - ETA: 0s - loss: 0.6911 - acc: 0.519 - ETA: 0s - loss: 0.6920 - acc: 0.513 - ETA: 0s - loss: 0.6917 - acc: 0.519 - 0s 60us/step - loss: 0.6918 - acc: 0.5200 - val_loss: 0.6908 - val_acc: 0.5350\n",
      "Epoch 175/500\n",
      "3424/3424 [==============================] - ETA: 0s - loss: 0.6900 - acc: 0.520 - ETA: 0s - loss: 0.6921 - acc: 0.525 - ETA: 0s - loss: 0.6924 - acc: 0.515 - ETA: 0s - loss: 0.6922 - acc: 0.515 - 0s 59us/step - loss: 0.6920 - acc: 0.5196 - val_loss: 0.6900 - val_acc: 0.5362\n",
      "Epoch 176/500\n",
      "3424/3424 [==============================] - ETA: 0s - loss: 0.6968 - acc: 0.460 - ETA: 0s - loss: 0.6905 - acc: 0.529 - ETA: 0s - loss: 0.6916 - acc: 0.518 - ETA: 0s - loss: 0.6915 - acc: 0.518 - 0s 57us/step - loss: 0.6919 - acc: 0.5196 - val_loss: 0.6899 - val_acc: 0.5362\n",
      "Epoch 177/500\n",
      "3424/3424 [==============================] - ETA: 0s - loss: 0.7067 - acc: 0.460 - ETA: 0s - loss: 0.6932 - acc: 0.515 - ETA: 0s - loss: 0.6930 - acc: 0.515 - ETA: 0s - loss: 0.6925 - acc: 0.521 - 0s 59us/step - loss: 0.6927 - acc: 0.5181 - val_loss: 0.6913 - val_acc: 0.5327\n",
      "Epoch 178/500\n",
      "3424/3424 [==============================] - ETA: 0s - loss: 0.6931 - acc: 0.510 - ETA: 0s - loss: 0.6915 - acc: 0.530 - ETA: 0s - loss: 0.6922 - acc: 0.522 - ETA: 0s - loss: 0.6923 - acc: 0.520 - ETA: 0s - loss: 0.6924 - acc: 0.518 - 0s 73us/step - loss: 0.6925 - acc: 0.5181 - val_loss: 0.6913 - val_acc: 0.5327\n",
      "Epoch 179/500\n",
      "3424/3424 [==============================] - ETA: 0s - loss: 0.6939 - acc: 0.500 - ETA: 0s - loss: 0.6929 - acc: 0.512 - ETA: 0s - loss: 0.6929 - acc: 0.512 - ETA: 0s - loss: 0.6925 - acc: 0.517 - 0s 57us/step - loss: 0.6925 - acc: 0.5181 - val_loss: 0.6914 - val_acc: 0.5333\n",
      "Epoch 180/500\n",
      "3424/3424 [==============================] - ETA: 0s - loss: 0.6931 - acc: 0.510 - ETA: 0s - loss: 0.6932 - acc: 0.508 - ETA: 0s - loss: 0.6925 - acc: 0.517 - ETA: 0s - loss: 0.6921 - acc: 0.522 - 0s 62us/step - loss: 0.6925 - acc: 0.5181 - val_loss: 0.6914 - val_acc: 0.5327\n",
      "Epoch 181/500\n",
      "3424/3424 [==============================] - ETA: 0s - loss: 0.6878 - acc: 0.580 - ETA: 0s - loss: 0.6927 - acc: 0.515 - ETA: 0s - loss: 0.6920 - acc: 0.524 - ETA: 0s - loss: 0.6922 - acc: 0.521 - 0s 57us/step - loss: 0.6925 - acc: 0.5181 - val_loss: 0.6914 - val_acc: 0.5327\n",
      "Epoch 182/500\n",
      "3424/3424 [==============================] - ETA: 0s - loss: 0.6954 - acc: 0.480 - ETA: 0s - loss: 0.6932 - acc: 0.509 - ETA: 0s - loss: 0.6925 - acc: 0.517 - ETA: 0s - loss: 0.6923 - acc: 0.521 - 0s 61us/step - loss: 0.6925 - acc: 0.5181 - val_loss: 0.6914 - val_acc: 0.5333\n",
      "Epoch 183/500\n",
      "3424/3424 [==============================] - ETA: 0s - loss: 0.6886 - acc: 0.570 - ETA: 0s - loss: 0.6931 - acc: 0.510 - ETA: 0s - loss: 0.6924 - acc: 0.519 - ETA: 0s - loss: 0.6930 - acc: 0.511 - 0s 61us/step - loss: 0.6925 - acc: 0.5181 - val_loss: 0.6914 - val_acc: 0.5333\n",
      "Epoch 184/500\n",
      "3424/3424 [==============================] - ETA: 0s - loss: 0.6938 - acc: 0.500 - ETA: 0s - loss: 0.6927 - acc: 0.515 - ETA: 0s - loss: 0.6917 - acc: 0.529 - ETA: 0s - loss: 0.6924 - acc: 0.519 - 0s 62us/step - loss: 0.6925 - acc: 0.5181 - val_loss: 0.6914 - val_acc: 0.5333\n",
      "Epoch 185/500\n",
      "3424/3424 [==============================] - ETA: 0s - loss: 0.6916 - acc: 0.530 - ETA: 0s - loss: 0.6924 - acc: 0.520 - ETA: 0s - loss: 0.6929 - acc: 0.512 - ETA: 0s - loss: 0.6928 - acc: 0.514 - ETA: 0s - loss: 0.6925 - acc: 0.517 - 0s 73us/step - loss: 0.6925 - acc: 0.5181 - val_loss: 0.6914 - val_acc: 0.5333\n",
      "Epoch 186/500\n",
      "3424/3424 [==============================] - ETA: 0s - loss: 0.6924 - acc: 0.520 - ETA: 0s - loss: 0.6923 - acc: 0.521 - ETA: 0s - loss: 0.6922 - acc: 0.522 - ETA: 0s - loss: 0.6924 - acc: 0.519 - 0s 60us/step - loss: 0.6925 - acc: 0.5181 - val_loss: 0.6914 - val_acc: 0.5333\n",
      "Epoch 187/500\n",
      "3424/3424 [==============================] - ETA: 0s - loss: 0.6967 - acc: 0.460 - ETA: 0s - loss: 0.6924 - acc: 0.518 - ETA: 0s - loss: 0.6920 - acc: 0.525 - ETA: 0s - loss: 0.6927 - acc: 0.515 - ETA: 0s - loss: 0.6925 - acc: 0.517 - 0s 74us/step - loss: 0.6925 - acc: 0.5181 - val_loss: 0.6914 - val_acc: 0.5333\n",
      "Epoch 188/500\n",
      "3424/3424 [==============================] - ETA: 0s - loss: 0.6902 - acc: 0.550 - ETA: 0s - loss: 0.6924 - acc: 0.520 - ETA: 0s - loss: 0.6922 - acc: 0.522 - ETA: 0s - loss: 0.6925 - acc: 0.517 - 0s 59us/step - loss: 0.6925 - acc: 0.5181 - val_loss: 0.6914 - val_acc: 0.5333\n",
      "Epoch 189/500\n",
      "3424/3424 [==============================] - ETA: 0s - loss: 0.6966 - acc: 0.460 - ETA: 0s - loss: 0.6911 - acc: 0.538 - ETA: 0s - loss: 0.6919 - acc: 0.527 - ETA: 0s - loss: 0.6924 - acc: 0.519 - 0s 58us/step - loss: 0.6925 - acc: 0.5181 - val_loss: 0.6914 - val_acc: 0.5333\n",
      "Epoch 190/500\n",
      "3424/3424 [==============================] - ETA: 0s - loss: 0.6988 - acc: 0.430 - ETA: 0s - loss: 0.6944 - acc: 0.491 - ETA: 0s - loss: 0.6931 - acc: 0.510 - ETA: 0s - loss: 0.6927 - acc: 0.516 - 0s 61us/step - loss: 0.6925 - acc: 0.5181 - val_loss: 0.6915 - val_acc: 0.5333\n",
      "Epoch 191/500\n",
      "3424/3424 [==============================] - ETA: 0s - loss: 0.6875 - acc: 0.590 - ETA: 0s - loss: 0.6921 - acc: 0.524 - ETA: 0s - loss: 0.6920 - acc: 0.524 - ETA: 0s - loss: 0.6925 - acc: 0.517 - 0s 58us/step - loss: 0.6925 - acc: 0.5181 - val_loss: 0.6914 - val_acc: 0.5333\n",
      "Epoch 192/500\n",
      "3424/3424 [==============================] - ETA: 0s - loss: 0.6938 - acc: 0.500 - ETA: 0s - loss: 0.6943 - acc: 0.493 - ETA: 0s - loss: 0.6933 - acc: 0.507 - ETA: 0s - loss: 0.6922 - acc: 0.522 - 0s 59us/step - loss: 0.6925 - acc: 0.5181 - val_loss: 0.6914 - val_acc: 0.5333\n",
      "Epoch 193/500\n",
      "3424/3424 [==============================] - ETA: 0s - loss: 0.6916 - acc: 0.530 - ETA: 0s - loss: 0.6918 - acc: 0.528 - ETA: 0s - loss: 0.6924 - acc: 0.518 - ETA: 0s - loss: 0.6916 - acc: 0.530 - 0s 68us/step - loss: 0.6925 - acc: 0.5181 - val_loss: 0.6914 - val_acc: 0.5327\n",
      "Epoch 194/500\n",
      "3424/3424 [==============================] - ETA: 0s - loss: 0.6977 - acc: 0.450 - ETA: 0s - loss: 0.6929 - acc: 0.513 - ETA: 0s - loss: 0.6925 - acc: 0.518 - ETA: 0s - loss: 0.6923 - acc: 0.521 - 0s 69us/step - loss: 0.6925 - acc: 0.5181 - val_loss: 0.6914 - val_acc: 0.5333\n",
      "Epoch 195/500\n",
      "3424/3424 [==============================] - ETA: 0s - loss: 0.6873 - acc: 0.590 - ETA: 0s - loss: 0.6920 - acc: 0.525 - ETA: 0s - loss: 0.6917 - acc: 0.529 - ETA: 0s - loss: 0.6923 - acc: 0.521 - 0s 68us/step - loss: 0.6925 - acc: 0.5181 - val_loss: 0.6914 - val_acc: 0.5327\n",
      "Epoch 196/500\n",
      "3424/3424 [==============================] - ETA: 0s - loss: 0.6939 - acc: 0.500 - ETA: 0s - loss: 0.6924 - acc: 0.520 - ETA: 0s - loss: 0.6920 - acc: 0.525 - ETA: 0s - loss: 0.6924 - acc: 0.518 - 0s 66us/step - loss: 0.6925 - acc: 0.5181 - val_loss: 0.6914 - val_acc: 0.5333\n",
      "Epoch 197/500\n",
      "3424/3424 [==============================] - ETA: 0s - loss: 0.6924 - acc: 0.520 - ETA: 0s - loss: 0.6928 - acc: 0.513 - ETA: 0s - loss: 0.6924 - acc: 0.519 - ETA: 0s - loss: 0.6918 - acc: 0.528 - ETA: 0s - loss: 0.6920 - acc: 0.525 - 0s 75us/step - loss: 0.6925 - acc: 0.5181 - val_loss: 0.6914 - val_acc: 0.5333\n",
      "Epoch 198/500\n",
      "3424/3424 [==============================] - ETA: 0s - loss: 0.6866 - acc: 0.600 - ETA: 0s - loss: 0.6919 - acc: 0.526 - ETA: 0s - loss: 0.6924 - acc: 0.518 - ETA: 0s - loss: 0.6924 - acc: 0.520 - ETA: 0s - loss: 0.6924 - acc: 0.519 - 0s 76us/step - loss: 0.6925 - acc: 0.5181 - val_loss: 0.6914 - val_acc: 0.5333\n",
      "Epoch 199/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3424/3424 [==============================] - ETA: 0s - loss: 0.6901 - acc: 0.550 - ETA: 0s - loss: 0.6929 - acc: 0.511 - ETA: 0s - loss: 0.6927 - acc: 0.515 - ETA: 0s - loss: 0.6923 - acc: 0.521 - 0s 62us/step - loss: 0.6925 - acc: 0.5181 - val_loss: 0.6914 - val_acc: 0.5333\n",
      "Epoch 200/500\n",
      "3424/3424 [==============================] - ETA: 0s - loss: 0.6989 - acc: 0.430 - ETA: 0s - loss: 0.6929 - acc: 0.512 - ETA: 0s - loss: 0.6923 - acc: 0.521 - ETA: 0s - loss: 0.6920 - acc: 0.525 - ETA: 0s - loss: 0.6924 - acc: 0.520 - 0s 73us/step - loss: 0.6925 - acc: 0.5181 - val_loss: 0.6914 - val_acc: 0.5333\n",
      "Epoch 201/500\n",
      "3424/3424 [==============================] - ETA: 0s - loss: 0.6945 - acc: 0.490 - ETA: 0s - loss: 0.6921 - acc: 0.524 - ETA: 0s - loss: 0.6924 - acc: 0.519 - ETA: 0s - loss: 0.6925 - acc: 0.517 - 0s 66us/step - loss: 0.6925 - acc: 0.5181 - val_loss: 0.6914 - val_acc: 0.5333\n",
      "Epoch 202/500\n",
      "3424/3424 [==============================] - ETA: 0s - loss: 0.6896 - acc: 0.560 - ETA: 0s - loss: 0.6937 - acc: 0.500 - ETA: 0s - loss: 0.6927 - acc: 0.515 - ETA: 0s - loss: 0.6925 - acc: 0.518 - 0s 59us/step - loss: 0.6925 - acc: 0.5181 - val_loss: 0.6914 - val_acc: 0.5333\n",
      "Epoch 203/500\n",
      "3424/3424 [==============================] - ETA: 0s - loss: 0.6931 - acc: 0.510 - ETA: 0s - loss: 0.6911 - acc: 0.537 - ETA: 0s - loss: 0.6916 - acc: 0.530 - ETA: 0s - loss: 0.6924 - acc: 0.519 - 0s 63us/step - loss: 0.6925 - acc: 0.5181 - val_loss: 0.6914 - val_acc: 0.5333\n",
      "Epoch 204/500\n",
      "3424/3424 [==============================] - ETA: 0s - loss: 0.6939 - acc: 0.500 - ETA: 0s - loss: 0.6927 - acc: 0.515 - ETA: 0s - loss: 0.6929 - acc: 0.512 - ETA: 0s - loss: 0.6928 - acc: 0.514 - 0s 64us/step - loss: 0.6925 - acc: 0.5181 - val_loss: 0.6914 - val_acc: 0.5333\n",
      "Epoch 205/500\n",
      "3424/3424 [==============================] - ETA: 0s - loss: 0.6938 - acc: 0.500 - ETA: 0s - loss: 0.6930 - acc: 0.511 - ETA: 0s - loss: 0.6924 - acc: 0.518 - ETA: 0s - loss: 0.6925 - acc: 0.517 - 0s 65us/step - loss: 0.6925 - acc: 0.5181 - val_loss: 0.6914 - val_acc: 0.5333\n",
      "Epoch 206/500\n",
      "3424/3424 [==============================] - ETA: 0s - loss: 0.6931 - acc: 0.510 - ETA: 0s - loss: 0.6920 - acc: 0.524 - ETA: 0s - loss: 0.6919 - acc: 0.525 - ETA: 0s - loss: 0.6926 - acc: 0.517 - 0s 60us/step - loss: 0.6925 - acc: 0.5181 - val_loss: 0.6914 - val_acc: 0.5333\n",
      "Epoch 207/500\n",
      "3424/3424 [==============================] - ETA: 0s - loss: 0.6887 - acc: 0.570 - ETA: 0s - loss: 0.6931 - acc: 0.510 - ETA: 0s - loss: 0.6924 - acc: 0.520 - ETA: 0s - loss: 0.6923 - acc: 0.520 - ETA: 0s - loss: 0.6926 - acc: 0.516 - 0s 80us/step - loss: 0.6925 - acc: 0.5181 - val_loss: 0.6914 - val_acc: 0.5333\n",
      "Epoch 208/500\n",
      "3424/3424 [==============================] - ETA: 0s - loss: 0.6946 - acc: 0.490 - ETA: 0s - loss: 0.6931 - acc: 0.510 - ETA: 0s - loss: 0.6927 - acc: 0.515 - ETA: 0s - loss: 0.6928 - acc: 0.513 - ETA: 0s - loss: 0.6926 - acc: 0.516 - 0s 82us/step - loss: 0.6925 - acc: 0.5181 - val_loss: 0.6914 - val_acc: 0.5333\n",
      "Epoch 209/500\n",
      "3424/3424 [==============================] - ETA: 0s - loss: 0.6909 - acc: 0.540 - ETA: 0s - loss: 0.6933 - acc: 0.507 - ETA: 0s - loss: 0.6928 - acc: 0.513 - ETA: 0s - loss: 0.6929 - acc: 0.512 - 0s 67us/step - loss: 0.6925 - acc: 0.5181 - val_loss: 0.6914 - val_acc: 0.5333\n",
      "Epoch 210/500\n",
      "3424/3424 [==============================] - ETA: 0s - loss: 0.6867 - acc: 0.600 - ETA: 0s - loss: 0.6918 - acc: 0.528 - ETA: 0s - loss: 0.6920 - acc: 0.525 - ETA: 0s - loss: 0.6926 - acc: 0.516 - 0s 62us/step - loss: 0.6925 - acc: 0.5181 - val_loss: 0.6914 - val_acc: 0.5333\n",
      "Epoch 211/500\n",
      "3424/3424 [==============================] - ETA: 0s - loss: 0.6828 - acc: 0.650 - ETA: 0s - loss: 0.6921 - acc: 0.523 - ETA: 0s - loss: 0.6917 - acc: 0.529 - ETA: 0s - loss: 0.6923 - acc: 0.520 - 0s 60us/step - loss: 0.6925 - acc: 0.5181 - val_loss: 0.6914 - val_acc: 0.5333\n",
      "Epoch 212/500\n",
      "3424/3424 [==============================] - ETA: 0s - loss: 0.6909 - acc: 0.540 - ETA: 0s - loss: 0.6922 - acc: 0.521 - ETA: 0s - loss: 0.6922 - acc: 0.521 - ETA: 0s - loss: 0.6923 - acc: 0.520 - 0s 57us/step - loss: 0.6925 - acc: 0.5181 - val_loss: 0.6914 - val_acc: 0.5327\n",
      "Epoch 213/500\n",
      "3424/3424 [==============================] - ETA: 0s - loss: 0.6946 - acc: 0.490 - ETA: 0s - loss: 0.6920 - acc: 0.525 - ETA: 0s - loss: 0.6926 - acc: 0.516 - ETA: 0s - loss: 0.6925 - acc: 0.518 - 0s 59us/step - loss: 0.6925 - acc: 0.5181 - val_loss: 0.6914 - val_acc: 0.5333\n",
      "Epoch 214/500\n",
      "3424/3424 [==============================] - ETA: 0s - loss: 0.6924 - acc: 0.520 - ETA: 0s - loss: 0.6926 - acc: 0.516 - ETA: 0s - loss: 0.6920 - acc: 0.525 - ETA: 0s - loss: 0.6922 - acc: 0.521 - 0s 61us/step - loss: 0.6925 - acc: 0.5181 - val_loss: 0.6914 - val_acc: 0.5333\n",
      "Epoch 215/500\n",
      "3424/3424 [==============================] - ETA: 0s - loss: 0.6916 - acc: 0.530 - ETA: 0s - loss: 0.6913 - acc: 0.534 - ETA: 0s - loss: 0.6923 - acc: 0.521 - ETA: 0s - loss: 0.6919 - acc: 0.526 - ETA: 0s - loss: 0.6924 - acc: 0.519 - 0s 69us/step - loss: 0.6925 - acc: 0.5181 - val_loss: 0.6914 - val_acc: 0.5327\n",
      "Epoch 216/500\n",
      "3424/3424 [==============================] - ETA: 0s - loss: 0.6977 - acc: 0.450 - ETA: 0s - loss: 0.6928 - acc: 0.514 - ETA: 0s - loss: 0.6931 - acc: 0.510 - ETA: 0s - loss: 0.6923 - acc: 0.520 - 0s 65us/step - loss: 0.6925 - acc: 0.5181 - val_loss: 0.6914 - val_acc: 0.5333\n",
      "Epoch 217/500\n",
      "3424/3424 [==============================] - ETA: 0s - loss: 0.6916 - acc: 0.530 - ETA: 0s - loss: 0.6926 - acc: 0.516 - ETA: 0s - loss: 0.6927 - acc: 0.515 - ETA: 0s - loss: 0.6925 - acc: 0.517 - 0s 63us/step - loss: 0.6925 - acc: 0.5181 - val_loss: 0.6914 - val_acc: 0.5333\n",
      "Epoch 218/500\n",
      "3424/3424 [==============================] - ETA: 0s - loss: 0.6945 - acc: 0.490 - ETA: 0s - loss: 0.6927 - acc: 0.515 - ETA: 0s - loss: 0.6920 - acc: 0.524 - ETA: 0s - loss: 0.6922 - acc: 0.521 - 0s 58us/step - loss: 0.6925 - acc: 0.5181 - val_loss: 0.6914 - val_acc: 0.5327\n",
      "Epoch 219/500\n",
      "3424/3424 [==============================] - ETA: 0s - loss: 0.6885 - acc: 0.570 - ETA: 0s - loss: 0.6942 - acc: 0.495 - ETA: 0s - loss: 0.6931 - acc: 0.510 - ETA: 0s - loss: 0.6928 - acc: 0.514 - 0s 59us/step - loss: 0.6925 - acc: 0.5181 - val_loss: 0.6914 - val_acc: 0.5333\n",
      "Epoch 220/500\n",
      "3424/3424 [==============================] - ETA: 0s - loss: 0.6909 - acc: 0.540 - ETA: 0s - loss: 0.6909 - acc: 0.540 - ETA: 0s - loss: 0.6918 - acc: 0.527 - ETA: 0s - loss: 0.6923 - acc: 0.521 - 0s 59us/step - loss: 0.6925 - acc: 0.5181 - val_loss: 0.6913 - val_acc: 0.5327\n",
      "Epoch 221/500\n",
      "3424/3424 [==============================] - ETA: 0s - loss: 0.6908 - acc: 0.540 - ETA: 0s - loss: 0.6930 - acc: 0.511 - ETA: 0s - loss: 0.6923 - acc: 0.521 - ETA: 0s - loss: 0.6924 - acc: 0.519 - 0s 62us/step - loss: 0.6925 - acc: 0.5181 - val_loss: 0.6913 - val_acc: 0.5327\n",
      "Epoch 222/500\n",
      "3424/3424 [==============================] - ETA: 0s - loss: 0.6892 - acc: 0.560 - ETA: 0s - loss: 0.6918 - acc: 0.527 - ETA: 0s - loss: 0.6915 - acc: 0.531 - ETA: 0s - loss: 0.6928 - acc: 0.514 - 0s 58us/step - loss: 0.6925 - acc: 0.5181 - val_loss: 0.6913 - val_acc: 0.5327\n",
      "Epoch 223/500\n",
      "3424/3424 [==============================] - ETA: 0s - loss: 0.6955 - acc: 0.480 - ETA: 0s - loss: 0.6931 - acc: 0.510 - ETA: 0s - loss: 0.6924 - acc: 0.519 - ETA: 0s - loss: 0.6924 - acc: 0.519 - 0s 58us/step - loss: 0.6925 - acc: 0.5181 - val_loss: 0.6913 - val_acc: 0.5327\n",
      "Epoch 224/500\n",
      "3424/3424 [==============================] - ETA: 0s - loss: 0.6900 - acc: 0.550 - ETA: 0s - loss: 0.6933 - acc: 0.507 - ETA: 0s - loss: 0.6928 - acc: 0.514 - ETA: 0s - loss: 0.6922 - acc: 0.522 - 0s 60us/step - loss: 0.6925 - acc: 0.5181 - val_loss: 0.6913 - val_acc: 0.5327\n",
      "Epoch 225/500\n",
      "3424/3424 [==============================] - ETA: 0s - loss: 0.6962 - acc: 0.470 - ETA: 0s - loss: 0.6937 - acc: 0.502 - ETA: 0s - loss: 0.6925 - acc: 0.518 - ETA: 0s - loss: 0.6926 - acc: 0.516 - 0s 56us/step - loss: 0.6925 - acc: 0.5181 - val_loss: 0.6914 - val_acc: 0.5327\n",
      "Epoch 226/500\n",
      "3424/3424 [==============================] - ETA: 0s - loss: 0.6916 - acc: 0.530 - ETA: 0s - loss: 0.6921 - acc: 0.523 - ETA: 0s - loss: 0.6927 - acc: 0.515 - ETA: 0s - loss: 0.6924 - acc: 0.519 - 0s 58us/step - loss: 0.6925 - acc: 0.5181 - val_loss: 0.6914 - val_acc: 0.5327\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 227/500\n",
      "3424/3424 [==============================] - ETA: 0s - loss: 0.6923 - acc: 0.520 - ETA: 0s - loss: 0.6915 - acc: 0.531 - ETA: 0s - loss: 0.6917 - acc: 0.529 - ETA: 0s - loss: 0.6924 - acc: 0.519 - 0s 60us/step - loss: 0.6925 - acc: 0.5181 - val_loss: 0.6914 - val_acc: 0.5327\n",
      "Epoch 228/500\n",
      "3424/3424 [==============================] - ETA: 0s - loss: 0.6969 - acc: 0.460 - ETA: 0s - loss: 0.6940 - acc: 0.498 - ETA: 0s - loss: 0.6927 - acc: 0.515 - ETA: 0s - loss: 0.6926 - acc: 0.516 - 0s 63us/step - loss: 0.6925 - acc: 0.5181 - val_loss: 0.6914 - val_acc: 0.5327\n",
      "Epoch 229/500\n",
      "3424/3424 [==============================] - ETA: 0s - loss: 0.6954 - acc: 0.480 - ETA: 0s - loss: 0.6930 - acc: 0.511 - ETA: 0s - loss: 0.6924 - acc: 0.519 - ETA: 0s - loss: 0.6922 - acc: 0.521 - 0s 60us/step - loss: 0.6925 - acc: 0.5181 - val_loss: 0.6913 - val_acc: 0.5327\n",
      "Epoch 230/500\n",
      "3424/3424 [==============================] - ETA: 0s - loss: 0.6955 - acc: 0.480 - ETA: 0s - loss: 0.6909 - acc: 0.538 - ETA: 0s - loss: 0.6923 - acc: 0.521 - ETA: 0s - loss: 0.6928 - acc: 0.514 - 0s 62us/step - loss: 0.6925 - acc: 0.5181 - val_loss: 0.6913 - val_acc: 0.5327\n",
      "Epoch 231/500\n",
      "3424/3424 [==============================] - ETA: 0s - loss: 0.6962 - acc: 0.470 - ETA: 0s - loss: 0.6924 - acc: 0.519 - ETA: 0s - loss: 0.6920 - acc: 0.524 - ETA: 0s - loss: 0.6920 - acc: 0.524 - 0s 65us/step - loss: 0.6925 - acc: 0.5181 - val_loss: 0.6913 - val_acc: 0.5327\n",
      "Epoch 232/500\n",
      "3424/3424 [==============================] - ETA: 0s - loss: 0.6980 - acc: 0.450 - ETA: 0s - loss: 0.6922 - acc: 0.521 - ETA: 0s - loss: 0.6925 - acc: 0.518 - ETA: 0s - loss: 0.6925 - acc: 0.517 - 0s 58us/step - loss: 0.6925 - acc: 0.5181 - val_loss: 0.6914 - val_acc: 0.5327\n",
      "Epoch 233/500\n",
      "3424/3424 [==============================] - ETA: 0s - loss: 0.6908 - acc: 0.540 - ETA: 0s - loss: 0.6922 - acc: 0.521 - ETA: 0s - loss: 0.6922 - acc: 0.521 - ETA: 0s - loss: 0.6923 - acc: 0.521 - 0s 59us/step - loss: 0.6925 - acc: 0.5181 - val_loss: 0.6913 - val_acc: 0.5327\n",
      "Epoch 234/500\n",
      "3424/3424 [==============================] - ETA: 0s - loss: 0.6986 - acc: 0.440 - ETA: 0s - loss: 0.6939 - acc: 0.500 - ETA: 0s - loss: 0.6928 - acc: 0.514 - ETA: 0s - loss: 0.6927 - acc: 0.515 - 0s 59us/step - loss: 0.6925 - acc: 0.5181 - val_loss: 0.6914 - val_acc: 0.5333\n",
      "Epoch 235/500\n",
      "3424/3424 [==============================] - ETA: 0s - loss: 0.6946 - acc: 0.490 - ETA: 0s - loss: 0.6923 - acc: 0.521 - ETA: 0s - loss: 0.6920 - acc: 0.525 - ETA: 0s - loss: 0.6927 - acc: 0.516 - 0s 62us/step - loss: 0.6925 - acc: 0.5181 - val_loss: 0.6914 - val_acc: 0.5327\n",
      "Epoch 236/500\n",
      "3424/3424 [==============================] - ETA: 0s - loss: 0.6908 - acc: 0.540 - ETA: 0s - loss: 0.6923 - acc: 0.520 - ETA: 0s - loss: 0.6928 - acc: 0.514 - ETA: 0s - loss: 0.6927 - acc: 0.515 - 0s 63us/step - loss: 0.6925 - acc: 0.5181 - val_loss: 0.6914 - val_acc: 0.5333\n",
      "Epoch 237/500\n",
      "3424/3424 [==============================] - ETA: 0s - loss: 0.6857 - acc: 0.610 - ETA: 0s - loss: 0.6926 - acc: 0.517 - ETA: 0s - loss: 0.6929 - acc: 0.513 - ETA: 0s - loss: 0.6928 - acc: 0.513 - 0s 63us/step - loss: 0.6925 - acc: 0.5181 - val_loss: 0.6914 - val_acc: 0.5333\n",
      "Epoch 238/500\n",
      "3424/3424 [==============================] - ETA: 0s - loss: 0.6952 - acc: 0.480 - ETA: 0s - loss: 0.6952 - acc: 0.481 - ETA: 0s - loss: 0.6942 - acc: 0.493 - ETA: 0s - loss: 0.6930 - acc: 0.512 - 0s 63us/step - loss: 0.6925 - acc: 0.5181 - val_loss: 0.6914 - val_acc: 0.5333\n",
      "Epoch 239/500\n",
      "3424/3424 [==============================] - ETA: 0s - loss: 0.6909 - acc: 0.540 - ETA: 0s - loss: 0.6923 - acc: 0.520 - ETA: 0s - loss: 0.6926 - acc: 0.517 - ETA: 0s - loss: 0.6928 - acc: 0.514 - 0s 65us/step - loss: 0.6925 - acc: 0.5181 - val_loss: 0.6914 - val_acc: 0.5333\n",
      "Epoch 240/500\n",
      "3424/3424 [==============================] - ETA: 0s - loss: 0.6909 - acc: 0.540 - ETA: 0s - loss: 0.6948 - acc: 0.487 - ETA: 0s - loss: 0.6928 - acc: 0.514 - ETA: 0s - loss: 0.6930 - acc: 0.511 - 0s 63us/step - loss: 0.6925 - acc: 0.5181 - val_loss: 0.6914 - val_acc: 0.5333\n",
      "Epoch 241/500\n",
      "3424/3424 [==============================] - ETA: 0s - loss: 0.6916 - acc: 0.530 - ETA: 0s - loss: 0.6939 - acc: 0.500 - ETA: 0s - loss: 0.6929 - acc: 0.512 - ETA: 0s - loss: 0.6928 - acc: 0.514 - ETA: 0s - loss: 0.6924 - acc: 0.519 - 0s 77us/step - loss: 0.6925 - acc: 0.5181 - val_loss: 0.6914 - val_acc: 0.5327\n",
      "Epoch 242/500\n",
      "3424/3424 [==============================] - ETA: 0s - loss: 0.6878 - acc: 0.580 - ETA: 0s - loss: 0.6934 - acc: 0.507 - ETA: 0s - loss: 0.6928 - acc: 0.514 - ETA: 0s - loss: 0.6922 - acc: 0.522 - 0s 64us/step - loss: 0.6925 - acc: 0.5181 - val_loss: 0.6914 - val_acc: 0.5327\n",
      "Epoch 243/500\n",
      "3424/3424 [==============================] - ETA: 0s - loss: 0.6908 - acc: 0.540 - ETA: 0s - loss: 0.6923 - acc: 0.520 - ETA: 0s - loss: 0.6927 - acc: 0.515 - ETA: 0s - loss: 0.6928 - acc: 0.514 - ETA: 0s - loss: 0.6923 - acc: 0.520 - 0s 72us/step - loss: 0.6925 - acc: 0.5181 - val_loss: 0.6914 - val_acc: 0.5333\n",
      "Epoch 244/500\n",
      "3424/3424 [==============================] - ETA: 0s - loss: 0.6924 - acc: 0.520 - ETA: 0s - loss: 0.6924 - acc: 0.520 - ETA: 0s - loss: 0.6923 - acc: 0.520 - ETA: 0s - loss: 0.6925 - acc: 0.517 - ETA: 0s - loss: 0.6923 - acc: 0.521 - 0s 76us/step - loss: 0.6925 - acc: 0.5181 - val_loss: 0.6914 - val_acc: 0.5333\n",
      "Epoch 245/500\n",
      "3424/3424 [==============================] - ETA: 0s - loss: 0.6901 - acc: 0.550 - ETA: 0s - loss: 0.6935 - acc: 0.504 - ETA: 0s - loss: 0.6919 - acc: 0.526 - ETA: 0s - loss: 0.6925 - acc: 0.518 - 0s 62us/step - loss: 0.6925 - acc: 0.5181 - val_loss: 0.6914 - val_acc: 0.5333\n",
      "Epoch 246/500\n",
      "3424/3424 [==============================] - ETA: 0s - loss: 0.6887 - acc: 0.570 - ETA: 0s - loss: 0.6935 - acc: 0.504 - ETA: 0s - loss: 0.6927 - acc: 0.515 - ETA: 0s - loss: 0.6924 - acc: 0.520 - 0s 62us/step - loss: 0.6925 - acc: 0.5181 - val_loss: 0.6914 - val_acc: 0.5333\n",
      "Epoch 247/500\n",
      "3424/3424 [==============================] - ETA: 0s - loss: 0.6924 - acc: 0.520 - ETA: 0s - loss: 0.6918 - acc: 0.527 - ETA: 0s - loss: 0.6917 - acc: 0.529 - ETA: 0s - loss: 0.6923 - acc: 0.520 - 0s 61us/step - loss: 0.6925 - acc: 0.5181 - val_loss: 0.6914 - val_acc: 0.5333\n",
      "Epoch 248/500\n",
      "3424/3424 [==============================] - ETA: 0s - loss: 0.6938 - acc: 0.500 - ETA: 0s - loss: 0.6914 - acc: 0.533 - ETA: 0s - loss: 0.6922 - acc: 0.522 - ETA: 0s - loss: 0.6923 - acc: 0.521 - 0s 61us/step - loss: 0.6925 - acc: 0.5181 - val_loss: 0.6914 - val_acc: 0.5333\n",
      "Epoch 249/500\n",
      "3424/3424 [==============================] - ETA: 0s - loss: 0.6909 - acc: 0.540 - ETA: 0s - loss: 0.6937 - acc: 0.500 - ETA: 0s - loss: 0.6930 - acc: 0.511 - ETA: 0s - loss: 0.6926 - acc: 0.516 - 0s 63us/step - loss: 0.6925 - acc: 0.5181 - val_loss: 0.6915 - val_acc: 0.5333\n",
      "Epoch 250/500\n",
      "3424/3424 [==============================] - ETA: 0s - loss: 0.6842 - acc: 0.640 - ETA: 0s - loss: 0.6937 - acc: 0.501 - ETA: 0s - loss: 0.6933 - acc: 0.506 - ETA: 0s - loss: 0.6922 - acc: 0.522 - 0s 63us/step - loss: 0.6925 - acc: 0.5181 - val_loss: 0.6915 - val_acc: 0.5333\n",
      "Epoch 251/500\n",
      "3424/3424 [==============================] - ETA: 0s - loss: 0.6896 - acc: 0.560 - ETA: 0s - loss: 0.6911 - acc: 0.538 - ETA: 0s - loss: 0.6918 - acc: 0.528 - ETA: 0s - loss: 0.6925 - acc: 0.518 - 0s 59us/step - loss: 0.6925 - acc: 0.5181 - val_loss: 0.6914 - val_acc: 0.5333\n",
      "Epoch 252/500\n",
      "3424/3424 [==============================] - ETA: 0s - loss: 0.6867 - acc: 0.600 - ETA: 0s - loss: 0.6927 - acc: 0.515 - ETA: 0s - loss: 0.6929 - acc: 0.511 - ETA: 0s - loss: 0.6930 - acc: 0.511 - 0s 61us/step - loss: 0.6925 - acc: 0.5181 - val_loss: 0.6915 - val_acc: 0.5333\n",
      "Epoch 253/500\n",
      "3424/3424 [==============================] - ETA: 0s - loss: 0.6931 - acc: 0.510 - ETA: 0s - loss: 0.6929 - acc: 0.513 - ETA: 0s - loss: 0.6923 - acc: 0.520 - ETA: 0s - loss: 0.6932 - acc: 0.508 - 0s 62us/step - loss: 0.6925 - acc: 0.5181 - val_loss: 0.6915 - val_acc: 0.5333\n",
      "Epoch 254/500\n",
      "3424/3424 [==============================] - ETA: 0s - loss: 0.6951 - acc: 0.480 - ETA: 0s - loss: 0.6919 - acc: 0.527 - ETA: 0s - loss: 0.6919 - acc: 0.526 - ETA: 0s - loss: 0.6922 - acc: 0.521 - 0s 60us/step - loss: 0.6925 - acc: 0.5181 - val_loss: 0.6914 - val_acc: 0.5333\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 255/500\n",
      "3424/3424 [==============================] - ETA: 0s - loss: 0.6931 - acc: 0.510 - ETA: 0s - loss: 0.6924 - acc: 0.519 - ETA: 0s - loss: 0.6922 - acc: 0.521 - ETA: 0s - loss: 0.6923 - acc: 0.520 - 0s 61us/step - loss: 0.6925 - acc: 0.5181 - val_loss: 0.6914 - val_acc: 0.5333\n",
      "Epoch 256/500\n",
      "3424/3424 [==============================] - ETA: 0s - loss: 0.6894 - acc: 0.560 - ETA: 0s - loss: 0.6911 - acc: 0.536 - ETA: 0s - loss: 0.6923 - acc: 0.520 - ETA: 0s - loss: 0.6925 - acc: 0.518 - 0s 61us/step - loss: 0.6925 - acc: 0.5181 - val_loss: 0.6914 - val_acc: 0.5333\n",
      "Epoch 257/500\n",
      "3424/3424 [==============================] - ETA: 0s - loss: 0.6864 - acc: 0.600 - ETA: 0s - loss: 0.6900 - acc: 0.552 - ETA: 0s - loss: 0.6910 - acc: 0.537 - ETA: 0s - loss: 0.6923 - acc: 0.521 - 0s 60us/step - loss: 0.6925 - acc: 0.5181 - val_loss: 0.6914 - val_acc: 0.5333\n",
      "Epoch 258/500\n",
      "3424/3424 [==============================] - ETA: 0s - loss: 0.6908 - acc: 0.540 - ETA: 0s - loss: 0.6913 - acc: 0.535 - ETA: 0s - loss: 0.6921 - acc: 0.523 - ETA: 0s - loss: 0.6925 - acc: 0.517 - 0s 57us/step - loss: 0.6925 - acc: 0.5181 - val_loss: 0.6914 - val_acc: 0.5333\n",
      "Epoch 259/500\n",
      "3424/3424 [==============================] - ETA: 0s - loss: 0.6938 - acc: 0.500 - ETA: 0s - loss: 0.6937 - acc: 0.500 - ETA: 0s - loss: 0.6930 - acc: 0.511 - ETA: 0s - loss: 0.6929 - acc: 0.512 - 0s 64us/step - loss: 0.6925 - acc: 0.5181 - val_loss: 0.6914 - val_acc: 0.5333\n",
      "Epoch 260/500\n",
      "3424/3424 [==============================] - ETA: 0s - loss: 0.6952 - acc: 0.480 - ETA: 0s - loss: 0.6928 - acc: 0.513 - ETA: 0s - loss: 0.6921 - acc: 0.522 - ETA: 0s - loss: 0.6926 - acc: 0.516 - 0s 57us/step - loss: 0.6925 - acc: 0.5181 - val_loss: 0.6914 - val_acc: 0.5333\n",
      "Epoch 261/500\n",
      "3424/3424 [==============================] - ETA: 0s - loss: 0.6953 - acc: 0.480 - ETA: 0s - loss: 0.6921 - acc: 0.524 - ETA: 0s - loss: 0.6926 - acc: 0.517 - ETA: 0s - loss: 0.6924 - acc: 0.519 - 0s 58us/step - loss: 0.6925 - acc: 0.5181 - val_loss: 0.6914 - val_acc: 0.5333\n",
      "Epoch 262/500\n",
      "3424/3424 [==============================] - ETA: 0s - loss: 0.6967 - acc: 0.460 - ETA: 0s - loss: 0.6940 - acc: 0.496 - ETA: 0s - loss: 0.6927 - acc: 0.514 - ETA: 0s - loss: 0.6925 - acc: 0.518 - 0s 63us/step - loss: 0.6925 - acc: 0.5181 - val_loss: 0.6914 - val_acc: 0.5333\n",
      "Epoch 263/500\n",
      "3424/3424 [==============================] - ETA: 0s - loss: 0.6974 - acc: 0.450 - ETA: 0s - loss: 0.6927 - acc: 0.515 - ETA: 0s - loss: 0.6928 - acc: 0.513 - ETA: 0s - loss: 0.6926 - acc: 0.516 - 0s 58us/step - loss: 0.6925 - acc: 0.5181 - val_loss: 0.6914 - val_acc: 0.5333\n",
      "Epoch 264/500\n",
      "3424/3424 [==============================] - ETA: 0s - loss: 0.6895 - acc: 0.560 - ETA: 0s - loss: 0.6918 - acc: 0.527 - ETA: 0s - loss: 0.6919 - acc: 0.526 - ETA: 0s - loss: 0.6922 - acc: 0.522 - 0s 60us/step - loss: 0.6925 - acc: 0.5181 - val_loss: 0.6914 - val_acc: 0.5333\n",
      "Epoch 265/500\n",
      "3424/3424 [==============================] - ETA: 0s - loss: 0.6976 - acc: 0.450 - ETA: 0s - loss: 0.6929 - acc: 0.512 - ETA: 0s - loss: 0.6930 - acc: 0.511 - ETA: 0s - loss: 0.6927 - acc: 0.515 - 0s 64us/step - loss: 0.6925 - acc: 0.5181 - val_loss: 0.6914 - val_acc: 0.5333\n",
      "Epoch 266/500\n",
      "3424/3424 [==============================] - ETA: 0s - loss: 0.6888 - acc: 0.570 - ETA: 0s - loss: 0.6912 - acc: 0.535 - ETA: 0s - loss: 0.6926 - acc: 0.516 - ETA: 0s - loss: 0.6923 - acc: 0.520 - 0s 58us/step - loss: 0.6925 - acc: 0.5181 - val_loss: 0.6914 - val_acc: 0.5333\n",
      "Epoch 267/500\n",
      "3424/3424 [==============================] - ETA: 0s - loss: 0.6967 - acc: 0.460 - ETA: 0s - loss: 0.6934 - acc: 0.505 - ETA: 0s - loss: 0.6932 - acc: 0.507 - ETA: 0s - loss: 0.6933 - acc: 0.507 - 0s 66us/step - loss: 0.6925 - acc: 0.5181 - val_loss: 0.6915 - val_acc: 0.5333\n",
      "Epoch 268/500\n",
      "3424/3424 [==============================] - ETA: 0s - loss: 0.6910 - acc: 0.540 - ETA: 0s - loss: 0.6922 - acc: 0.523 - ETA: 0s - loss: 0.6923 - acc: 0.521 - ETA: 0s - loss: 0.6923 - acc: 0.521 - 0s 63us/step - loss: 0.6925 - acc: 0.5181 - val_loss: 0.6914 - val_acc: 0.5327\n",
      "Epoch 269/500\n",
      "3424/3424 [==============================] - ETA: 0s - loss: 0.6923 - acc: 0.520 - ETA: 0s - loss: 0.6935 - acc: 0.504 - ETA: 0s - loss: 0.6923 - acc: 0.521 - ETA: 0s - loss: 0.6923 - acc: 0.521 - 0s 65us/step - loss: 0.6925 - acc: 0.5181 - val_loss: 0.6914 - val_acc: 0.5327\n",
      "Epoch 270/500\n",
      "3424/3424 [==============================] - ETA: 0s - loss: 0.6893 - acc: 0.560 - ETA: 0s - loss: 0.6922 - acc: 0.521 - ETA: 0s - loss: 0.6917 - acc: 0.528 - ETA: 0s - loss: 0.6923 - acc: 0.521 - 0s 63us/step - loss: 0.6925 - acc: 0.5181 - val_loss: 0.6914 - val_acc: 0.5327\n",
      "Epoch 271/500\n",
      "3424/3424 [==============================] - ETA: 0s - loss: 0.6908 - acc: 0.540 - ETA: 0s - loss: 0.6922 - acc: 0.522 - ETA: 0s - loss: 0.6924 - acc: 0.520 - ETA: 0s - loss: 0.6925 - acc: 0.517 - 0s 66us/step - loss: 0.6925 - acc: 0.5181 - val_loss: 0.6914 - val_acc: 0.5333\n",
      "Epoch 272/500\n",
      "3424/3424 [==============================] - ETA: 0s - loss: 0.6866 - acc: 0.600 - ETA: 0s - loss: 0.6934 - acc: 0.505 - ETA: 0s - loss: 0.6925 - acc: 0.517 - ETA: 0s - loss: 0.6926 - acc: 0.517 - 0s 64us/step - loss: 0.6925 - acc: 0.5181 - val_loss: 0.6914 - val_acc: 0.5333\n",
      "Epoch 273/500\n",
      "3424/3424 [==============================] - ETA: 0s - loss: 0.6916 - acc: 0.530 - ETA: 0s - loss: 0.6934 - acc: 0.505 - ETA: 0s - loss: 0.6922 - acc: 0.521 - ETA: 0s - loss: 0.6922 - acc: 0.522 - 0s 68us/step - loss: 0.6925 - acc: 0.5181 - val_loss: 0.6914 - val_acc: 0.5333\n",
      "Epoch 274/500\n",
      "3424/3424 [==============================] - ETA: 0s - loss: 0.6901 - acc: 0.550 - ETA: 0s - loss: 0.6923 - acc: 0.520 - ETA: 0s - loss: 0.6920 - acc: 0.525 - ETA: 0s - loss: 0.6924 - acc: 0.520 - 0s 59us/step - loss: 0.6925 - acc: 0.5181 - val_loss: 0.6914 - val_acc: 0.5333\n",
      "Epoch 275/500\n",
      "3424/3424 [==============================] - ETA: 0s - loss: 0.6975 - acc: 0.450 - ETA: 0s - loss: 0.6921 - acc: 0.523 - ETA: 0s - loss: 0.6923 - acc: 0.521 - ETA: 0s - loss: 0.6922 - acc: 0.522 - 0s 66us/step - loss: 0.6925 - acc: 0.5181 - val_loss: 0.6914 - val_acc: 0.5333\n",
      "Epoch 276/500\n",
      "3424/3424 [==============================] - ETA: 0s - loss: 0.6886 - acc: 0.570 - ETA: 0s - loss: 0.6928 - acc: 0.513 - ETA: 0s - loss: 0.6924 - acc: 0.518 - ETA: 0s - loss: 0.6927 - acc: 0.514 - 0s 64us/step - loss: 0.6925 - acc: 0.5181 - val_loss: 0.6914 - val_acc: 0.5333\n",
      "Epoch 277/500\n",
      "3424/3424 [==============================] - ETA: 0s - loss: 0.6902 - acc: 0.550 - ETA: 0s - loss: 0.6921 - acc: 0.523 - ETA: 0s - loss: 0.6927 - acc: 0.514 - ETA: 0s - loss: 0.6926 - acc: 0.517 - 0s 68us/step - loss: 0.6925 - acc: 0.5181 - val_loss: 0.6914 - val_acc: 0.5333\n",
      "Epoch 278/500\n",
      "3424/3424 [==============================] - ETA: 0s - loss: 0.6924 - acc: 0.520 - ETA: 0s - loss: 0.6917 - acc: 0.529 - ETA: 0s - loss: 0.6924 - acc: 0.518 - ETA: 0s - loss: 0.6922 - acc: 0.521 - 0s 64us/step - loss: 0.6925 - acc: 0.5181 - val_loss: 0.6914 - val_acc: 0.5333\n",
      "Epoch 279/500\n",
      "3424/3424 [==============================] - ETA: 0s - loss: 0.6886 - acc: 0.570 - ETA: 0s - loss: 0.6926 - acc: 0.516 - ETA: 0s - loss: 0.6925 - acc: 0.518 - ETA: 0s - loss: 0.6922 - acc: 0.522 - 0s 61us/step - loss: 0.6925 - acc: 0.5181 - val_loss: 0.6914 - val_acc: 0.5333\n",
      "Epoch 280/500\n",
      "3424/3424 [==============================] - ETA: 0s - loss: 0.6894 - acc: 0.560 - ETA: 0s - loss: 0.6925 - acc: 0.518 - ETA: 0s - loss: 0.6923 - acc: 0.520 - ETA: 0s - loss: 0.6925 - acc: 0.517 - 0s 60us/step - loss: 0.6925 - acc: 0.5181 - val_loss: 0.6914 - val_acc: 0.5333\n",
      "Epoch 281/500\n",
      "3424/3424 [==============================] - ETA: 0s - loss: 0.6953 - acc: 0.480 - ETA: 0s - loss: 0.6930 - acc: 0.511 - ETA: 0s - loss: 0.6936 - acc: 0.503 - ETA: 0s - loss: 0.6932 - acc: 0.509 - ETA: 0s - loss: 0.6926 - acc: 0.516 - 0s 77us/step - loss: 0.6925 - acc: 0.5181 - val_loss: 0.6914 - val_acc: 0.5333\n",
      "Epoch 282/500\n",
      "3424/3424 [==============================] - ETA: 0s - loss: 0.6909 - acc: 0.540 - ETA: 0s - loss: 0.6920 - acc: 0.525 - ETA: 0s - loss: 0.6926 - acc: 0.516 - ETA: 0s - loss: 0.6924 - acc: 0.519 - 0s 61us/step - loss: 0.6925 - acc: 0.5181 - val_loss: 0.6914 - val_acc: 0.5333\n",
      "Epoch 283/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3424/3424 [==============================] - ETA: 0s - loss: 0.7029 - acc: 0.380 - ETA: 0s - loss: 0.6937 - acc: 0.502 - ETA: 0s - loss: 0.6930 - acc: 0.511 - ETA: 0s - loss: 0.6924 - acc: 0.519 - 0s 66us/step - loss: 0.6925 - acc: 0.5181 - val_loss: 0.6914 - val_acc: 0.5333\n",
      "Epoch 284/500\n",
      "3424/3424 [==============================] - ETA: 0s - loss: 0.6931 - acc: 0.510 - ETA: 0s - loss: 0.6931 - acc: 0.510 - ETA: 0s - loss: 0.6924 - acc: 0.519 - ETA: 0s - loss: 0.6923 - acc: 0.520 - ETA: 0s - loss: 0.6922 - acc: 0.521 - 0s 73us/step - loss: 0.6925 - acc: 0.5181 - val_loss: 0.6914 - val_acc: 0.5327\n",
      "Epoch 285/500\n",
      "3424/3424 [==============================] - ETA: 0s - loss: 0.6886 - acc: 0.570 - ETA: 0s - loss: 0.6924 - acc: 0.520 - ETA: 0s - loss: 0.6927 - acc: 0.515 - ETA: 0s - loss: 0.6927 - acc: 0.515 - 0s 60us/step - loss: 0.6925 - acc: 0.5181 - val_loss: 0.6914 - val_acc: 0.5333\n",
      "Epoch 286/500\n",
      "3424/3424 [==============================] - ETA: 0s - loss: 0.6887 - acc: 0.570 - ETA: 0s - loss: 0.6923 - acc: 0.520 - ETA: 0s - loss: 0.6922 - acc: 0.522 - ETA: 0s - loss: 0.6922 - acc: 0.521 - 0s 63us/step - loss: 0.6925 - acc: 0.5181 - val_loss: 0.6914 - val_acc: 0.5333\n",
      "Epoch 287/500\n",
      "3424/3424 [==============================] - ETA: 0s - loss: 0.6909 - acc: 0.540 - ETA: 0s - loss: 0.6931 - acc: 0.510 - ETA: 0s - loss: 0.6923 - acc: 0.521 - ETA: 0s - loss: 0.6927 - acc: 0.515 - 0s 63us/step - loss: 0.6925 - acc: 0.5181 - val_loss: 0.6914 - val_acc: 0.5333\n",
      "Epoch 288/500\n",
      "3424/3424 [==============================] - ETA: 0s - loss: 0.6961 - acc: 0.470 - ETA: 0s - loss: 0.6923 - acc: 0.520 - ETA: 0s - loss: 0.6927 - acc: 0.515 - ETA: 0s - loss: 0.6925 - acc: 0.517 - 0s 64us/step - loss: 0.6925 - acc: 0.5181 - val_loss: 0.6913 - val_acc: 0.5327\n",
      "Epoch 289/500\n",
      "3424/3424 [==============================] - ETA: 0s - loss: 0.6931 - acc: 0.510 - ETA: 0s - loss: 0.6918 - acc: 0.527 - ETA: 0s - loss: 0.6920 - acc: 0.524 - ETA: 0s - loss: 0.6920 - acc: 0.524 - 0s 65us/step - loss: 0.6925 - acc: 0.5181 - val_loss: 0.6913 - val_acc: 0.5327\n",
      "Epoch 290/500\n",
      "3424/3424 [==============================] - ETA: 0s - loss: 0.6931 - acc: 0.510 - ETA: 0s - loss: 0.6917 - acc: 0.528 - ETA: 0s - loss: 0.6918 - acc: 0.527 - ETA: 0s - loss: 0.6925 - acc: 0.519 - 0s 64us/step - loss: 0.6925 - acc: 0.5181 - val_loss: 0.6913 - val_acc: 0.5327\n",
      "Epoch 291/500\n",
      "3424/3424 [==============================] - ETA: 0s - loss: 0.6830 - acc: 0.640 - ETA: 0s - loss: 0.6906 - acc: 0.542 - ETA: 0s - loss: 0.6923 - acc: 0.520 - ETA: 0s - loss: 0.6925 - acc: 0.518 - 0s 62us/step - loss: 0.6925 - acc: 0.5181 - val_loss: 0.6914 - val_acc: 0.5333\n",
      "Epoch 292/500\n",
      "3424/3424 [==============================] - ETA: 0s - loss: 0.6931 - acc: 0.510 - ETA: 0s - loss: 0.6929 - acc: 0.512 - ETA: 0s - loss: 0.6931 - acc: 0.510 - ETA: 0s - loss: 0.6926 - acc: 0.516 - 0s 62us/step - loss: 0.6925 - acc: 0.5181 - val_loss: 0.6914 - val_acc: 0.5333\n",
      "Epoch 293/500\n",
      "3424/3424 [==============================] - ETA: 0s - loss: 0.6938 - acc: 0.500 - ETA: 0s - loss: 0.6932 - acc: 0.509 - ETA: 0s - loss: 0.6923 - acc: 0.520 - ETA: 0s - loss: 0.6928 - acc: 0.514 - 0s 62us/step - loss: 0.6925 - acc: 0.5181 - val_loss: 0.6914 - val_acc: 0.5333\n",
      "Epoch 294/500\n",
      "3424/3424 [==============================] - ETA: 0s - loss: 0.6924 - acc: 0.520 - ETA: 0s - loss: 0.6919 - acc: 0.526 - ETA: 0s - loss: 0.6920 - acc: 0.525 - ETA: 0s - loss: 0.6920 - acc: 0.524 - 0s 63us/step - loss: 0.6925 - acc: 0.5181 - val_loss: 0.6913 - val_acc: 0.5327\n",
      "Epoch 295/500\n",
      "3424/3424 [==============================] - ETA: 0s - loss: 0.6970 - acc: 0.460 - ETA: 0s - loss: 0.6915 - acc: 0.531 - ETA: 0s - loss: 0.6928 - acc: 0.514 - ETA: 0s - loss: 0.6927 - acc: 0.516 - 0s 60us/step - loss: 0.6925 - acc: 0.5181 - val_loss: 0.6913 - val_acc: 0.5327\n",
      "Epoch 296/500\n",
      "3424/3424 [==============================] - ETA: 0s - loss: 0.6939 - acc: 0.500 - ETA: 0s - loss: 0.6934 - acc: 0.507 - ETA: 0s - loss: 0.6921 - acc: 0.523 - ETA: 0s - loss: 0.6925 - acc: 0.518 - 0s 60us/step - loss: 0.6925 - acc: 0.5181 - val_loss: 0.6913 - val_acc: 0.5327\n",
      "Epoch 297/500\n",
      "3424/3424 [==============================] - ETA: 0s - loss: 0.6954 - acc: 0.480 - ETA: 0s - loss: 0.6912 - acc: 0.535 - ETA: 0s - loss: 0.6922 - acc: 0.522 - ETA: 0s - loss: 0.6924 - acc: 0.519 - 0s 56us/step - loss: 0.6925 - acc: 0.5181 - val_loss: 0.6913 - val_acc: 0.5327\n",
      "Epoch 298/500\n",
      "3424/3424 [==============================] - ETA: 0s - loss: 0.6931 - acc: 0.510 - ETA: 0s - loss: 0.6911 - acc: 0.536 - ETA: 0s - loss: 0.6920 - acc: 0.524 - ETA: 0s - loss: 0.6929 - acc: 0.513 - 0s 64us/step - loss: 0.6925 - acc: 0.5181 - val_loss: 0.6913 - val_acc: 0.5327\n",
      "Epoch 299/500\n",
      "3424/3424 [==============================] - ETA: 0s - loss: 0.6947 - acc: 0.490 - ETA: 0s - loss: 0.6926 - acc: 0.517 - ETA: 0s - loss: 0.6925 - acc: 0.517 - ETA: 0s - loss: 0.6925 - acc: 0.517 - 0s 65us/step - loss: 0.6925 - acc: 0.5181 - val_loss: 0.6914 - val_acc: 0.5333\n",
      "Epoch 300/500\n",
      "3424/3424 [==============================] - ETA: 0s - loss: 0.6968 - acc: 0.460 - ETA: 0s - loss: 0.6919 - acc: 0.526 - ETA: 0s - loss: 0.6919 - acc: 0.526 - ETA: 0s - loss: 0.6921 - acc: 0.523 - 0s 67us/step - loss: 0.6925 - acc: 0.5181 - val_loss: 0.6914 - val_acc: 0.5333\n",
      "Epoch 301/500\n",
      "3424/3424 [==============================] - ETA: 0s - loss: 0.6968 - acc: 0.460 - ETA: 0s - loss: 0.6916 - acc: 0.530 - ETA: 0s - loss: 0.6924 - acc: 0.518 - ETA: 0s - loss: 0.6928 - acc: 0.514 - 0s 63us/step - loss: 0.6925 - acc: 0.5181 - val_loss: 0.6914 - val_acc: 0.5333\n",
      "Epoch 302/500\n",
      "3424/3424 [==============================] - ETA: 0s - loss: 0.6917 - acc: 0.530 - ETA: 0s - loss: 0.6914 - acc: 0.534 - ETA: 0s - loss: 0.6929 - acc: 0.512 - ETA: 0s - loss: 0.6923 - acc: 0.521 - 0s 63us/step - loss: 0.6925 - acc: 0.5181 - val_loss: 0.6914 - val_acc: 0.5333\n",
      "Epoch 303/500\n",
      "3424/3424 [==============================] - ETA: 0s - loss: 0.6896 - acc: 0.560 - ETA: 0s - loss: 0.6919 - acc: 0.527 - ETA: 0s - loss: 0.6925 - acc: 0.518 - ETA: 0s - loss: 0.6931 - acc: 0.509 - 0s 65us/step - loss: 0.6925 - acc: 0.5181 - val_loss: 0.6915 - val_acc: 0.5333\n",
      "Epoch 304/500\n",
      "3424/3424 [==============================] - ETA: 0s - loss: 0.6917 - acc: 0.530 - ETA: 0s - loss: 0.6925 - acc: 0.517 - ETA: 0s - loss: 0.6923 - acc: 0.521 - ETA: 0s - loss: 0.6925 - acc: 0.518 - 0s 60us/step - loss: 0.6925 - acc: 0.5181 - val_loss: 0.6914 - val_acc: 0.5333\n",
      "Epoch 305/500\n",
      "3424/3424 [==============================] - ETA: 0s - loss: 0.6931 - acc: 0.510 - ETA: 0s - loss: 0.6912 - acc: 0.536 - ETA: 0s - loss: 0.6914 - acc: 0.533 - ETA: 0s - loss: 0.6922 - acc: 0.521 - 0s 59us/step - loss: 0.6925 - acc: 0.5181 - val_loss: 0.6914 - val_acc: 0.5327\n",
      "Epoch 306/500\n",
      "3424/3424 [==============================] - ETA: 0s - loss: 0.6908 - acc: 0.540 - ETA: 0s - loss: 0.6910 - acc: 0.537 - ETA: 0s - loss: 0.6913 - acc: 0.534 - ETA: 0s - loss: 0.6925 - acc: 0.518 - 0s 68us/step - loss: 0.6925 - acc: 0.5181 - val_loss: 0.6914 - val_acc: 0.5333\n",
      "Epoch 307/500\n",
      "3424/3424 [==============================] - ETA: 0s - loss: 0.6976 - acc: 0.450 - ETA: 0s - loss: 0.6916 - acc: 0.530 - ETA: 0s - loss: 0.6930 - acc: 0.511 - ETA: 0s - loss: 0.6929 - acc: 0.513 - 0s 62us/step - loss: 0.6925 - acc: 0.5181 - val_loss: 0.6915 - val_acc: 0.5333\n",
      "Epoch 308/500\n",
      "3424/3424 [==============================] - ETA: 0s - loss: 0.6896 - acc: 0.560 - ETA: 0s - loss: 0.6933 - acc: 0.506 - ETA: 0s - loss: 0.6931 - acc: 0.509 - ETA: 0s - loss: 0.6928 - acc: 0.513 - 0s 67us/step - loss: 0.6925 - acc: 0.5181 - val_loss: 0.6914 - val_acc: 0.5333\n",
      "Epoch 309/500\n",
      "3424/3424 [==============================] - ETA: 0s - loss: 0.6882 - acc: 0.580 - ETA: 0s - loss: 0.6905 - acc: 0.546 - ETA: 0s - loss: 0.6922 - acc: 0.523 - ETA: 0s - loss: 0.6922 - acc: 0.522 - 0s 61us/step - loss: 0.6925 - acc: 0.5181 - val_loss: 0.6914 - val_acc: 0.5333\n",
      "Epoch 310/500\n",
      "3424/3424 [==============================] - ETA: 0s - loss: 0.6895 - acc: 0.560 - ETA: 0s - loss: 0.6935 - acc: 0.503 - ETA: 0s - loss: 0.6922 - acc: 0.523 - ETA: 0s - loss: 0.6927 - acc: 0.515 - 0s 63us/step - loss: 0.6925 - acc: 0.5181 - val_loss: 0.6915 - val_acc: 0.5333\n",
      "Epoch 311/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3424/3424 [==============================] - ETA: 0s - loss: 0.6910 - acc: 0.540 - ETA: 0s - loss: 0.6921 - acc: 0.523 - ETA: 0s - loss: 0.6923 - acc: 0.520 - ETA: 0s - loss: 0.6923 - acc: 0.521 - 0s 65us/step - loss: 0.6925 - acc: 0.5181 - val_loss: 0.6915 - val_acc: 0.5333\n",
      "Epoch 312/500\n",
      "3424/3424 [==============================] - ETA: 0s - loss: 0.6903 - acc: 0.550 - ETA: 0s - loss: 0.6915 - acc: 0.532 - ETA: 0s - loss: 0.6924 - acc: 0.518 - ETA: 0s - loss: 0.6926 - acc: 0.516 - 0s 68us/step - loss: 0.6925 - acc: 0.5181 - val_loss: 0.6915 - val_acc: 0.5333\n",
      "Epoch 313/500\n",
      "3424/3424 [==============================] - ETA: 0s - loss: 0.6903 - acc: 0.550 - ETA: 0s - loss: 0.6919 - acc: 0.527 - ETA: 0s - loss: 0.6919 - acc: 0.526 - ETA: 0s - loss: 0.6926 - acc: 0.516 - 0s 65us/step - loss: 0.6925 - acc: 0.5181 - val_loss: 0.6915 - val_acc: 0.5333\n",
      "Epoch 314/500\n",
      "3424/3424 [==============================] - ETA: 0s - loss: 0.6931 - acc: 0.510 - ETA: 0s - loss: 0.6928 - acc: 0.513 - ETA: 0s - loss: 0.6922 - acc: 0.522 - ETA: 0s - loss: 0.6924 - acc: 0.519 - 0s 58us/step - loss: 0.6925 - acc: 0.5181 - val_loss: 0.6915 - val_acc: 0.5333\n",
      "Epoch 315/500\n",
      "3424/3424 [==============================] - ETA: 0s - loss: 0.6897 - acc: 0.560 - ETA: 0s - loss: 0.6938 - acc: 0.497 - ETA: 0s - loss: 0.6926 - acc: 0.517 - ETA: 0s - loss: 0.6924 - acc: 0.520 - 0s 56us/step - loss: 0.6925 - acc: 0.5181 - val_loss: 0.6915 - val_acc: 0.5333\n",
      "Epoch 316/500\n",
      "3424/3424 [==============================] - ETA: 0s - loss: 0.6964 - acc: 0.460 - ETA: 0s - loss: 0.6918 - acc: 0.529 - ETA: 0s - loss: 0.6921 - acc: 0.523 - ETA: 0s - loss: 0.6924 - acc: 0.520 - 0s 62us/step - loss: 0.6925 - acc: 0.5181 - val_loss: 0.6915 - val_acc: 0.5333\n",
      "Epoch 317/500\n",
      "3424/3424 [==============================] - ETA: 0s - loss: 0.6951 - acc: 0.480 - ETA: 0s - loss: 0.6928 - acc: 0.514 - ETA: 0s - loss: 0.6931 - acc: 0.508 - ETA: 0s - loss: 0.6925 - acc: 0.518 - 0s 62us/step - loss: 0.6925 - acc: 0.5181 - val_loss: 0.6915 - val_acc: 0.5333\n",
      "Epoch 318/500\n",
      "3424/3424 [==============================] - ETA: 0s - loss: 0.6930 - acc: 0.510 - ETA: 0s - loss: 0.6928 - acc: 0.513 - ETA: 0s - loss: 0.6929 - acc: 0.512 - ETA: 0s - loss: 0.6923 - acc: 0.520 - 0s 67us/step - loss: 0.6925 - acc: 0.5181 - val_loss: 0.6915 - val_acc: 0.5333\n",
      "Epoch 319/500\n",
      "3424/3424 [==============================] - ETA: 0s - loss: 0.6903 - acc: 0.550 - ETA: 0s - loss: 0.6918 - acc: 0.529 - ETA: 0s - loss: 0.6929 - acc: 0.512 - ETA: 0s - loss: 0.6925 - acc: 0.518 - 0s 57us/step - loss: 0.6925 - acc: 0.5181 - val_loss: 0.6915 - val_acc: 0.5333\n",
      "Epoch 320/500\n",
      "3424/3424 [==============================] - ETA: 0s - loss: 0.6951 - acc: 0.480 - ETA: 0s - loss: 0.6919 - acc: 0.527 - ETA: 0s - loss: 0.6927 - acc: 0.515 - ETA: 0s - loss: 0.6927 - acc: 0.515 - 0s 60us/step - loss: 0.6925 - acc: 0.5181 - val_loss: 0.6914 - val_acc: 0.5333\n",
      "Epoch 321/500\n",
      "3424/3424 [==============================] - ETA: 0s - loss: 0.6917 - acc: 0.530 - ETA: 0s - loss: 0.6920 - acc: 0.525 - ETA: 0s - loss: 0.6927 - acc: 0.514 - ETA: 0s - loss: 0.6925 - acc: 0.517 - 0s 62us/step - loss: 0.6925 - acc: 0.5181 - val_loss: 0.6914 - val_acc: 0.5333\n",
      "Epoch 322/500\n",
      "3424/3424 [==============================] - ETA: 0s - loss: 0.6860 - acc: 0.610 - ETA: 0s - loss: 0.6930 - acc: 0.510 - ETA: 0s - loss: 0.6934 - acc: 0.505 - ETA: 0s - loss: 0.6932 - acc: 0.508 - 0s 69us/step - loss: 0.6925 - acc: 0.5181 - val_loss: 0.6915 - val_acc: 0.5333\n",
      "Epoch 323/500\n",
      "3424/3424 [==============================] - ETA: 0s - loss: 0.6938 - acc: 0.500 - ETA: 0s - loss: 0.6920 - acc: 0.525 - ETA: 0s - loss: 0.6926 - acc: 0.516 - ETA: 0s - loss: 0.6923 - acc: 0.520 - ETA: 0s - loss: 0.6927 - acc: 0.515 - 0s 80us/step - loss: 0.6925 - acc: 0.5181 - val_loss: 0.6914 - val_acc: 0.5333\n",
      "Epoch 324/500\n",
      "3424/3424 [==============================] - ETA: 0s - loss: 0.6980 - acc: 0.440 - ETA: 0s - loss: 0.6931 - acc: 0.510 - ETA: 0s - loss: 0.6924 - acc: 0.518 - ETA: 0s - loss: 0.6932 - acc: 0.508 - ETA: 0s - loss: 0.6925 - acc: 0.518 - 0s 77us/step - loss: 0.6925 - acc: 0.5181 - val_loss: 0.6914 - val_acc: 0.5333\n",
      "Epoch 325/500\n",
      "3424/3424 [==============================] - ETA: 0s - loss: 0.6916 - acc: 0.530 - ETA: 0s - loss: 0.6921 - acc: 0.524 - ETA: 0s - loss: 0.6923 - acc: 0.521 - ETA: 0s - loss: 0.6928 - acc: 0.513 - 0s 63us/step - loss: 0.6925 - acc: 0.5181 - val_loss: 0.6914 - val_acc: 0.5333\n",
      "Epoch 326/500\n",
      "3424/3424 [==============================] - ETA: 0s - loss: 0.6916 - acc: 0.530 - ETA: 0s - loss: 0.6922 - acc: 0.521 - ETA: 0s - loss: 0.6918 - acc: 0.527 - ETA: 0s - loss: 0.6922 - acc: 0.521 - 0s 62us/step - loss: 0.6925 - acc: 0.5181 - val_loss: 0.6913 - val_acc: 0.5327\n",
      "Epoch 327/500\n",
      "3424/3424 [==============================] - ETA: 0s - loss: 0.6939 - acc: 0.500 - ETA: 0s - loss: 0.6926 - acc: 0.517 - ETA: 0s - loss: 0.6931 - acc: 0.510 - ETA: 0s - loss: 0.6928 - acc: 0.514 - ETA: 0s - loss: 0.6927 - acc: 0.516 - 0s 80us/step - loss: 0.6925 - acc: 0.5181 - val_loss: 0.6914 - val_acc: 0.5333\n",
      "Epoch 328/500\n",
      "3424/3424 [==============================] - ETA: 0s - loss: 0.6923 - acc: 0.520 - ETA: 0s - loss: 0.6920 - acc: 0.525 - ETA: 0s - loss: 0.6924 - acc: 0.519 - ETA: 0s - loss: 0.6930 - acc: 0.511 - ETA: 0s - loss: 0.6925 - acc: 0.517 - 0s 76us/step - loss: 0.6925 - acc: 0.5181 - val_loss: 0.6914 - val_acc: 0.5327\n",
      "Epoch 329/500\n",
      "3424/3424 [==============================] - ETA: 0s - loss: 0.6871 - acc: 0.590 - ETA: 0s - loss: 0.6915 - acc: 0.531 - ETA: 0s - loss: 0.6908 - acc: 0.539 - ETA: 0s - loss: 0.6919 - acc: 0.525 - ETA: 0s - loss: 0.6921 - acc: 0.523 - ETA: 0s - loss: 0.6925 - acc: 0.518 - 0s 90us/step - loss: 0.6925 - acc: 0.5181 - val_loss: 0.6913 - val_acc: 0.5327\n",
      "Epoch 330/500\n",
      "3424/3424 [==============================] - ETA: 0s - loss: 0.6907 - acc: 0.540 - ETA: 0s - loss: 0.6918 - acc: 0.527 - ETA: 0s - loss: 0.6923 - acc: 0.520 - ETA: 0s - loss: 0.6928 - acc: 0.513 - 0s 65us/step - loss: 0.6925 - acc: 0.5181 - val_loss: 0.6914 - val_acc: 0.5327\n",
      "Epoch 331/500\n",
      "3424/3424 [==============================] - ETA: 0s - loss: 0.6962 - acc: 0.470 - ETA: 0s - loss: 0.6933 - acc: 0.507 - ETA: 0s - loss: 0.6927 - acc: 0.515 - ETA: 0s - loss: 0.6926 - acc: 0.516 - 0s 60us/step - loss: 0.6925 - acc: 0.5181 - val_loss: 0.6914 - val_acc: 0.5327\n",
      "Epoch 332/500\n",
      "3424/3424 [==============================] - ETA: 0s - loss: 0.6970 - acc: 0.460 - ETA: 0s - loss: 0.6919 - acc: 0.525 - ETA: 0s - loss: 0.6917 - acc: 0.527 - ETA: 0s - loss: 0.6928 - acc: 0.514 - 0s 64us/step - loss: 0.6925 - acc: 0.5181 - val_loss: 0.6913 - val_acc: 0.5327\n",
      "Epoch 333/500\n",
      "3424/3424 [==============================] - ETA: 0s - loss: 0.6861 - acc: 0.600 - ETA: 0s - loss: 0.6926 - acc: 0.517 - ETA: 0s - loss: 0.6927 - acc: 0.515 - ETA: 0s - loss: 0.6927 - acc: 0.515 - ETA: 0s - loss: 0.6924 - acc: 0.519 - ETA: 0s - loss: 0.6925 - acc: 0.518 - 0s 91us/step - loss: 0.6925 - acc: 0.5181 - val_loss: 0.6913 - val_acc: 0.5327\n",
      "Epoch 334/500\n",
      "3424/3424 [==============================] - ETA: 0s - loss: 0.6923 - acc: 0.520 - ETA: 0s - loss: 0.6929 - acc: 0.512 - ETA: 0s - loss: 0.6930 - acc: 0.512 - ETA: 0s - loss: 0.6924 - acc: 0.519 - ETA: 0s - loss: 0.6923 - acc: 0.520 - 0s 76us/step - loss: 0.6925 - acc: 0.5181 - val_loss: 0.6914 - val_acc: 0.5333\n",
      "Epoch 335/500\n",
      "3424/3424 [==============================] - ETA: 0s - loss: 0.6924 - acc: 0.520 - ETA: 0s - loss: 0.6926 - acc: 0.516 - ETA: 0s - loss: 0.6927 - acc: 0.515 - ETA: 0s - loss: 0.6926 - acc: 0.517 - ETA: 0s - loss: 0.6925 - acc: 0.518 - 0s 74us/step - loss: 0.6925 - acc: 0.5181 - val_loss: 0.6914 - val_acc: 0.5333\n",
      "Epoch 336/500\n",
      "3424/3424 [==============================] - ETA: 0s - loss: 0.6916 - acc: 0.530 - ETA: 0s - loss: 0.6927 - acc: 0.515 - ETA: 0s - loss: 0.6928 - acc: 0.514 - ETA: 0s - loss: 0.6927 - acc: 0.515 - ETA: 0s - loss: 0.6924 - acc: 0.519 - 0s 72us/step - loss: 0.6925 - acc: 0.5181 - val_loss: 0.6914 - val_acc: 0.5333\n",
      "Epoch 337/500\n",
      "3424/3424 [==============================] - ETA: 0s - loss: 0.6895 - acc: 0.560 - ETA: 0s - loss: 0.6922 - acc: 0.523 - ETA: 0s - loss: 0.6915 - acc: 0.532 - ETA: 0s - loss: 0.6924 - acc: 0.520 - 0s 65us/step - loss: 0.6925 - acc: 0.5181 - val_loss: 0.6914 - val_acc: 0.5333\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 338/500\n",
      "3424/3424 [==============================] - ETA: 0s - loss: 0.6902 - acc: 0.550 - ETA: 0s - loss: 0.6924 - acc: 0.519 - ETA: 0s - loss: 0.6925 - acc: 0.517 - ETA: 0s - loss: 0.6929 - acc: 0.513 - 0s 68us/step - loss: 0.6925 - acc: 0.5181 - val_loss: 0.6915 - val_acc: 0.5333\n",
      "Epoch 339/500\n",
      "3424/3424 [==============================] - ETA: 0s - loss: 0.6896 - acc: 0.560 - ETA: 0s - loss: 0.6925 - acc: 0.518 - ETA: 0s - loss: 0.6923 - acc: 0.520 - ETA: 0s - loss: 0.6925 - acc: 0.517 - ETA: 0s - loss: 0.6924 - acc: 0.519 - 0s 81us/step - loss: 0.6925 - acc: 0.5181 - val_loss: 0.6914 - val_acc: 0.5333\n",
      "Epoch 340/500\n",
      "3424/3424 [==============================] - ETA: 0s - loss: 0.6931 - acc: 0.510 - ETA: 0s - loss: 0.6924 - acc: 0.520 - ETA: 0s - loss: 0.6925 - acc: 0.518 - ETA: 0s - loss: 0.6928 - acc: 0.514 - ETA: 0s - loss: 0.6923 - acc: 0.521 - 0s 76us/step - loss: 0.6925 - acc: 0.5181 - val_loss: 0.6914 - val_acc: 0.5333\n",
      "Epoch 341/500\n",
      "3424/3424 [==============================] - ETA: 0s - loss: 0.6967 - acc: 0.460 - ETA: 0s - loss: 0.6931 - acc: 0.510 - ETA: 0s - loss: 0.6922 - acc: 0.522 - ETA: 0s - loss: 0.6922 - acc: 0.522 - ETA: 0s - loss: 0.6924 - acc: 0.519 - 0s 80us/step - loss: 0.6925 - acc: 0.5181 - val_loss: 0.6914 - val_acc: 0.5333\n",
      "Epoch 342/500\n",
      "3424/3424 [==============================] - ETA: 0s - loss: 0.6987 - acc: 0.430 - ETA: 0s - loss: 0.6920 - acc: 0.525 - ETA: 0s - loss: 0.6925 - acc: 0.518 - ETA: 0s - loss: 0.6927 - acc: 0.515 - ETA: 0s - loss: 0.6925 - acc: 0.518 - 0s 73us/step - loss: 0.6925 - acc: 0.5181 - val_loss: 0.6915 - val_acc: 0.5333\n",
      "Epoch 343/500\n",
      "3424/3424 [==============================] - ETA: 0s - loss: 0.6903 - acc: 0.550 - ETA: 0s - loss: 0.6909 - acc: 0.542 - ETA: 0s - loss: 0.6924 - acc: 0.520 - ETA: 0s - loss: 0.6920 - acc: 0.525 - 0s 69us/step - loss: 0.6925 - acc: 0.5181 - val_loss: 0.6914 - val_acc: 0.5333\n",
      "Epoch 344/500\n",
      "3424/3424 [==============================] - ETA: 0s - loss: 0.6895 - acc: 0.560 - ETA: 0s - loss: 0.6915 - acc: 0.532 - ETA: 0s - loss: 0.6927 - acc: 0.514 - ETA: 0s - loss: 0.6924 - acc: 0.519 - 0s 63us/step - loss: 0.6925 - acc: 0.5181 - val_loss: 0.6915 - val_acc: 0.5333\n",
      "Epoch 345/500\n",
      "3424/3424 [==============================] - ETA: 0s - loss: 0.6883 - acc: 0.580 - ETA: 0s - loss: 0.6925 - acc: 0.518 - ETA: 0s - loss: 0.6923 - acc: 0.520 - ETA: 0s - loss: 0.6928 - acc: 0.513 - ETA: 0s - loss: 0.6926 - acc: 0.517 - 0s 84us/step - loss: 0.6925 - acc: 0.5181 - val_loss: 0.6914 - val_acc: 0.5333\n",
      "Epoch 346/500\n",
      "3424/3424 [==============================] - ETA: 0s - loss: 0.6938 - acc: 0.500 - ETA: 0s - loss: 0.6921 - acc: 0.524 - ETA: 0s - loss: 0.6922 - acc: 0.522 - ETA: 0s - loss: 0.6919 - acc: 0.526 - ETA: 0s - loss: 0.6925 - acc: 0.517 - 0s 77us/step - loss: 0.6925 - acc: 0.5181 - val_loss: 0.6914 - val_acc: 0.5333\n",
      "Epoch 347/500\n",
      "3424/3424 [==============================] - ETA: 0s - loss: 0.6873 - acc: 0.590 - ETA: 0s - loss: 0.6917 - acc: 0.530 - ETA: 0s - loss: 0.6923 - acc: 0.520 - ETA: 0s - loss: 0.6924 - acc: 0.519 - 0s 61us/step - loss: 0.6925 - acc: 0.5181 - val_loss: 0.6914 - val_acc: 0.5333\n",
      "Epoch 348/500\n",
      "3424/3424 [==============================] - ETA: 0s - loss: 0.6931 - acc: 0.510 - ETA: 0s - loss: 0.6926 - acc: 0.516 - ETA: 0s - loss: 0.6926 - acc: 0.516 - ETA: 0s - loss: 0.6923 - acc: 0.521 - 0s 61us/step - loss: 0.6925 - acc: 0.5181 - val_loss: 0.6914 - val_acc: 0.5333\n",
      "Epoch 349/500\n",
      "3424/3424 [==============================] - ETA: 0s - loss: 0.6952 - acc: 0.480 - ETA: 0s - loss: 0.6917 - acc: 0.529 - ETA: 0s - loss: 0.6918 - acc: 0.527 - ETA: 0s - loss: 0.6921 - acc: 0.523 - 0s 62us/step - loss: 0.6925 - acc: 0.5181 - val_loss: 0.6914 - val_acc: 0.5333\n",
      "Epoch 350/500\n",
      "3424/3424 [==============================] - ETA: 0s - loss: 0.6902 - acc: 0.550 - ETA: 0s - loss: 0.6916 - acc: 0.530 - ETA: 0s - loss: 0.6913 - acc: 0.535 - ETA: 0s - loss: 0.6922 - acc: 0.522 - 0s 63us/step - loss: 0.6925 - acc: 0.5181 - val_loss: 0.6914 - val_acc: 0.5333\n",
      "Epoch 351/500\n",
      "3424/3424 [==============================] - ETA: 0s - loss: 0.6924 - acc: 0.520 - ETA: 0s - loss: 0.6911 - acc: 0.538 - ETA: 0s - loss: 0.6920 - acc: 0.525 - ETA: 0s - loss: 0.6923 - acc: 0.520 - 0s 61us/step - loss: 0.6925 - acc: 0.5181 - val_loss: 0.6915 - val_acc: 0.5333\n",
      "Epoch 352/500\n",
      "3424/3424 [==============================] - ETA: 0s - loss: 0.6930 - acc: 0.510 - ETA: 0s - loss: 0.6926 - acc: 0.516 - ETA: 0s - loss: 0.6928 - acc: 0.512 - ETA: 0s - loss: 0.6927 - acc: 0.514 - 0s 66us/step - loss: 0.6925 - acc: 0.5181 - val_loss: 0.6915 - val_acc: 0.5333\n",
      "Epoch 353/500\n",
      "3424/3424 [==============================] - ETA: 0s - loss: 0.6930 - acc: 0.510 - ETA: 0s - loss: 0.6930 - acc: 0.510 - ETA: 0s - loss: 0.6927 - acc: 0.514 - ETA: 0s - loss: 0.6926 - acc: 0.516 - 0s 66us/step - loss: 0.6925 - acc: 0.5181 - val_loss: 0.6915 - val_acc: 0.5333\n",
      "Epoch 354/500\n",
      "3424/3424 [==============================] - ETA: 0s - loss: 0.6890 - acc: 0.570 - ETA: 0s - loss: 0.6921 - acc: 0.523 - ETA: 0s - loss: 0.6925 - acc: 0.518 - ETA: 0s - loss: 0.6916 - acc: 0.531 - ETA: 0s - loss: 0.6917 - acc: 0.530 - 0s 84us/step - loss: 0.6925 - acc: 0.5181 - val_loss: 0.6914 - val_acc: 0.5333\n",
      "Epoch 355/500\n",
      "3424/3424 [==============================] - ETA: 0s - loss: 0.6909 - acc: 0.540 - ETA: 0s - loss: 0.6942 - acc: 0.494 - ETA: 0s - loss: 0.6930 - acc: 0.511 - ETA: 0s - loss: 0.6924 - acc: 0.519 - 0s 68us/step - loss: 0.6925 - acc: 0.5181 - val_loss: 0.6915 - val_acc: 0.5333\n",
      "Epoch 356/500\n",
      "3424/3424 [==============================] - ETA: 0s - loss: 0.6964 - acc: 0.460 - ETA: 0s - loss: 0.6944 - acc: 0.490 - ETA: 0s - loss: 0.6936 - acc: 0.501 - ETA: 0s - loss: 0.6930 - acc: 0.510 - ETA: 0s - loss: 0.6925 - acc: 0.518 - 0s 80us/step - loss: 0.6925 - acc: 0.5181 - val_loss: 0.6915 - val_acc: 0.5333\n",
      "Epoch 357/500\n",
      "3424/3424 [==============================] - ETA: 0s - loss: 0.6957 - acc: 0.470 - ETA: 0s - loss: 0.6924 - acc: 0.519 - ETA: 0s - loss: 0.6922 - acc: 0.521 - ETA: 0s - loss: 0.6924 - acc: 0.519 - ETA: 0s - loss: 0.6924 - acc: 0.519 - 0s 76us/step - loss: 0.6925 - acc: 0.5181 - val_loss: 0.6915 - val_acc: 0.5333\n",
      "Epoch 358/500\n",
      "3424/3424 [==============================] - ETA: 0s - loss: 0.6951 - acc: 0.480 - ETA: 0s - loss: 0.6911 - acc: 0.538 - ETA: 0s - loss: 0.6932 - acc: 0.508 - ETA: 0s - loss: 0.6927 - acc: 0.515 - 0s 65us/step - loss: 0.6925 - acc: 0.5181 - val_loss: 0.6915 - val_acc: 0.5333\n",
      "Epoch 359/500\n",
      "3424/3424 [==============================] - ETA: 0s - loss: 0.6856 - acc: 0.620 - ETA: 0s - loss: 0.6907 - acc: 0.544 - ETA: 0s - loss: 0.6914 - acc: 0.533 - ETA: 0s - loss: 0.6928 - acc: 0.514 - 0s 67us/step - loss: 0.6925 - acc: 0.5181 - val_loss: 0.6915 - val_acc: 0.5333\n",
      "Epoch 360/500\n",
      "3424/3424 [==============================] - ETA: 0s - loss: 0.6861 - acc: 0.610 - ETA: 0s - loss: 0.6917 - acc: 0.529 - ETA: 0s - loss: 0.6924 - acc: 0.518 - ETA: 0s - loss: 0.6920 - acc: 0.525 - ETA: 0s - loss: 0.6926 - acc: 0.517 - 0s 77us/step - loss: 0.6925 - acc: 0.5181 - val_loss: 0.6914 - val_acc: 0.5333\n",
      "Epoch 361/500\n",
      "3424/3424 [==============================] - ETA: 0s - loss: 0.6902 - acc: 0.550 - ETA: 0s - loss: 0.6916 - acc: 0.530 - ETA: 0s - loss: 0.6923 - acc: 0.520 - ETA: 0s - loss: 0.6922 - acc: 0.522 - 0s 69us/step - loss: 0.6925 - acc: 0.5181 - val_loss: 0.6914 - val_acc: 0.5333\n",
      "Epoch 362/500\n",
      "3424/3424 [==============================] - ETA: 0s - loss: 0.6938 - acc: 0.500 - ETA: 0s - loss: 0.6917 - acc: 0.529 - ETA: 0s - loss: 0.6918 - acc: 0.527 - ETA: 0s - loss: 0.6924 - acc: 0.520 - 0s 64us/step - loss: 0.6925 - acc: 0.5181 - val_loss: 0.6914 - val_acc: 0.5333\n",
      "Epoch 363/500\n",
      "3424/3424 [==============================] - ETA: 0s - loss: 0.6931 - acc: 0.510 - ETA: 0s - loss: 0.6921 - acc: 0.523 - ETA: 0s - loss: 0.6922 - acc: 0.522 - ETA: 0s - loss: 0.6923 - acc: 0.521 - 0s 64us/step - loss: 0.6925 - acc: 0.5181 - val_loss: 0.6914 - val_acc: 0.5333\n",
      "Epoch 364/500\n",
      "3424/3424 [==============================] - ETA: 0s - loss: 0.6938 - acc: 0.500 - ETA: 0s - loss: 0.6917 - acc: 0.529 - ETA: 0s - loss: 0.6929 - acc: 0.513 - ETA: 0s - loss: 0.6929 - acc: 0.513 - 0s 67us/step - loss: 0.6925 - acc: 0.5181 - val_loss: 0.6914 - val_acc: 0.5333\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 365/500\n",
      "3424/3424 [==============================] - ETA: 0s - loss: 0.6931 - acc: 0.510 - ETA: 0s - loss: 0.6926 - acc: 0.517 - ETA: 0s - loss: 0.6923 - acc: 0.521 - ETA: 0s - loss: 0.6921 - acc: 0.523 - 0s 70us/step - loss: 0.6925 - acc: 0.5181 - val_loss: 0.6914 - val_acc: 0.5333\n",
      "Epoch 366/500\n",
      "3424/3424 [==============================] - ETA: 0s - loss: 0.6989 - acc: 0.430 - ETA: 0s - loss: 0.6933 - acc: 0.507 - ETA: 0s - loss: 0.6924 - acc: 0.520 - ETA: 0s - loss: 0.6924 - acc: 0.519 - 0s 67us/step - loss: 0.6925 - acc: 0.5181 - val_loss: 0.6914 - val_acc: 0.5333\n",
      "Epoch 367/500\n",
      "3424/3424 [==============================] - ETA: 0s - loss: 0.6881 - acc: 0.580 - ETA: 0s - loss: 0.6919 - acc: 0.526 - ETA: 0s - loss: 0.6923 - acc: 0.521 - ETA: 0s - loss: 0.6925 - acc: 0.517 - 0s 68us/step - loss: 0.6925 - acc: 0.5181 - val_loss: 0.6914 - val_acc: 0.5333\n",
      "Epoch 368/500\n",
      "3424/3424 [==============================] - ETA: 0s - loss: 0.6881 - acc: 0.580 - ETA: 0s - loss: 0.6917 - acc: 0.529 - ETA: 0s - loss: 0.6922 - acc: 0.521 - ETA: 0s - loss: 0.6922 - acc: 0.522 - 0s 65us/step - loss: 0.6925 - acc: 0.5181 - val_loss: 0.6914 - val_acc: 0.5333\n",
      "Epoch 369/500\n",
      "3424/3424 [==============================] - ETA: 0s - loss: 0.7043 - acc: 0.360 - ETA: 0s - loss: 0.6946 - acc: 0.490 - ETA: 0s - loss: 0.6921 - acc: 0.523 - ETA: 0s - loss: 0.6923 - acc: 0.521 - 0s 63us/step - loss: 0.6925 - acc: 0.5181 - val_loss: 0.6914 - val_acc: 0.5327\n",
      "Epoch 370/500\n",
      "3424/3424 [==============================] - ETA: 0s - loss: 0.6916 - acc: 0.530 - ETA: 0s - loss: 0.6919 - acc: 0.525 - ETA: 0s - loss: 0.6920 - acc: 0.525 - ETA: 0s - loss: 0.6926 - acc: 0.517 - 0s 68us/step - loss: 0.6925 - acc: 0.5181 - val_loss: 0.6914 - val_acc: 0.5333\n",
      "Epoch 371/500\n",
      "3424/3424 [==============================] - ETA: 0s - loss: 0.6924 - acc: 0.520 - ETA: 0s - loss: 0.6921 - acc: 0.524 - ETA: 0s - loss: 0.6926 - acc: 0.516 - ETA: 0s - loss: 0.6927 - acc: 0.515 - ETA: 0s - loss: 0.6925 - acc: 0.517 - 0s 71us/step - loss: 0.6925 - acc: 0.5181 - val_loss: 0.6914 - val_acc: 0.5333\n",
      "Epoch 372/500\n",
      "3424/3424 [==============================] - ETA: 0s - loss: 0.6901 - acc: 0.550 - ETA: 0s - loss: 0.6926 - acc: 0.517 - ETA: 0s - loss: 0.6925 - acc: 0.518 - ETA: 0s - loss: 0.6921 - acc: 0.523 - 0s 68us/step - loss: 0.6925 - acc: 0.5181 - val_loss: 0.6914 - val_acc: 0.5333\n",
      "Epoch 373/500\n",
      "3424/3424 [==============================] - ETA: 0s - loss: 0.6893 - acc: 0.560 - ETA: 0s - loss: 0.6924 - acc: 0.518 - ETA: 0s - loss: 0.6918 - acc: 0.527 - ETA: 0s - loss: 0.6921 - acc: 0.523 - 0s 66us/step - loss: 0.6925 - acc: 0.5181 - val_loss: 0.6914 - val_acc: 0.5327\n",
      "Epoch 374/500\n",
      "3424/3424 [==============================] - ETA: 0s - loss: 0.6901 - acc: 0.550 - ETA: 0s - loss: 0.6921 - acc: 0.524 - ETA: 0s - loss: 0.6938 - acc: 0.501 - ETA: 0s - loss: 0.6929 - acc: 0.514 - 0s 62us/step - loss: 0.6926 - acc: 0.5181 - val_loss: 0.6914 - val_acc: 0.5333\n",
      "Epoch 375/500\n",
      "3424/3424 [==============================] - ETA: 0s - loss: 0.6982 - acc: 0.440 - ETA: 0s - loss: 0.6923 - acc: 0.521 - ETA: 0s - loss: 0.6924 - acc: 0.518 - ETA: 0s - loss: 0.6923 - acc: 0.521 - 0s 66us/step - loss: 0.6925 - acc: 0.5181 - val_loss: 0.6914 - val_acc: 0.5327\n",
      "Epoch 376/500\n",
      "3424/3424 [==============================] - ETA: 0s - loss: 0.6954 - acc: 0.480 - ETA: 0s - loss: 0.6907 - acc: 0.542 - ETA: 0s - loss: 0.6923 - acc: 0.521 - ETA: 0s - loss: 0.6923 - acc: 0.521 - 0s 64us/step - loss: 0.6925 - acc: 0.5181 - val_loss: 0.6914 - val_acc: 0.5327\n",
      "Epoch 377/500\n",
      "3424/3424 [==============================] - ETA: 0s - loss: 0.6923 - acc: 0.520 - ETA: 0s - loss: 0.6927 - acc: 0.516 - ETA: 0s - loss: 0.6921 - acc: 0.524 - ETA: 0s - loss: 0.6926 - acc: 0.516 - 0s 62us/step - loss: 0.6925 - acc: 0.5181 - val_loss: 0.6914 - val_acc: 0.5333\n",
      "Epoch 378/500\n",
      "3424/3424 [==============================] - ETA: 0s - loss: 0.6931 - acc: 0.510 - ETA: 0s - loss: 0.6944 - acc: 0.492 - ETA: 0s - loss: 0.6936 - acc: 0.502 - ETA: 0s - loss: 0.6932 - acc: 0.508 - 0s 65us/step - loss: 0.6925 - acc: 0.5181 - val_loss: 0.6914 - val_acc: 0.5333\n",
      "Epoch 379/500\n",
      "3424/3424 [==============================] - ETA: 0s - loss: 0.6917 - acc: 0.530 - ETA: 0s - loss: 0.6927 - acc: 0.515 - ETA: 0s - loss: 0.6929 - acc: 0.512 - ETA: 0s - loss: 0.6923 - acc: 0.520 - ETA: 0s - loss: 0.6925 - acc: 0.518 - 0s 71us/step - loss: 0.6925 - acc: 0.5181 - val_loss: 0.6914 - val_acc: 0.5333\n",
      "Epoch 380/500\n",
      "3424/3424 [==============================] - ETA: 0s - loss: 0.6886 - acc: 0.570 - ETA: 0s - loss: 0.6911 - acc: 0.537 - ETA: 0s - loss: 0.6922 - acc: 0.521 - ETA: 0s - loss: 0.6924 - acc: 0.519 - 0s 66us/step - loss: 0.6925 - acc: 0.5181 - val_loss: 0.6914 - val_acc: 0.5333\n",
      "Epoch 381/500\n",
      "3424/3424 [==============================] - ETA: 0s - loss: 0.6924 - acc: 0.520 - ETA: 0s - loss: 0.6916 - acc: 0.530 - ETA: 0s - loss: 0.6926 - acc: 0.517 - ETA: 0s - loss: 0.6922 - acc: 0.521 - 0s 67us/step - loss: 0.6925 - acc: 0.5181 - val_loss: 0.6914 - val_acc: 0.5333\n",
      "Epoch 382/500\n",
      "3424/3424 [==============================] - ETA: 0s - loss: 0.6938 - acc: 0.500 - ETA: 0s - loss: 0.6932 - acc: 0.509 - ETA: 0s - loss: 0.6923 - acc: 0.521 - ETA: 0s - loss: 0.6928 - acc: 0.514 - 0s 62us/step - loss: 0.6925 - acc: 0.5181 - val_loss: 0.6914 - val_acc: 0.5333\n",
      "Epoch 383/500\n",
      "3424/3424 [==============================] - ETA: 0s - loss: 0.6924 - acc: 0.520 - ETA: 0s - loss: 0.6920 - acc: 0.524 - ETA: 0s - loss: 0.6923 - acc: 0.521 - ETA: 0s - loss: 0.6922 - acc: 0.521 - 0s 64us/step - loss: 0.6925 - acc: 0.5181 - val_loss: 0.6914 - val_acc: 0.5333\n",
      "Epoch 384/500\n",
      "3424/3424 [==============================] - ETA: 0s - loss: 0.6916 - acc: 0.530 - ETA: 0s - loss: 0.6917 - acc: 0.528 - ETA: 0s - loss: 0.6918 - acc: 0.527 - ETA: 0s - loss: 0.6924 - acc: 0.519 - 0s 65us/step - loss: 0.6925 - acc: 0.5181 - val_loss: 0.6914 - val_acc: 0.5333\n",
      "Epoch 385/500\n",
      "3424/3424 [==============================] - ETA: 0s - loss: 0.6894 - acc: 0.560 - ETA: 0s - loss: 0.6930 - acc: 0.511 - ETA: 0s - loss: 0.6925 - acc: 0.517 - ETA: 0s - loss: 0.6927 - acc: 0.515 - 0s 64us/step - loss: 0.6925 - acc: 0.5181 - val_loss: 0.6914 - val_acc: 0.5333\n",
      "Epoch 386/500\n",
      "3424/3424 [==============================] - ETA: 0s - loss: 0.6880 - acc: 0.580 - ETA: 0s - loss: 0.6927 - acc: 0.515 - ETA: 0s - loss: 0.6926 - acc: 0.516 - ETA: 0s - loss: 0.6925 - acc: 0.518 - 0s 62us/step - loss: 0.6925 - acc: 0.5181 - val_loss: 0.6914 - val_acc: 0.5333\n",
      "Epoch 387/500\n",
      "3424/3424 [==============================] - ETA: 0s - loss: 0.6909 - acc: 0.540 - ETA: 0s - loss: 0.6913 - acc: 0.534 - ETA: 0s - loss: 0.6918 - acc: 0.527 - ETA: 0s - loss: 0.6920 - acc: 0.524 - 0s 64us/step - loss: 0.6925 - acc: 0.5181 - val_loss: 0.6914 - val_acc: 0.5333\n",
      "Epoch 388/500\n",
      "3424/3424 [==============================] - ETA: 0s - loss: 0.6973 - acc: 0.450 - ETA: 0s - loss: 0.6916 - acc: 0.530 - ETA: 0s - loss: 0.6918 - acc: 0.527 - ETA: 0s - loss: 0.6924 - acc: 0.519 - 0s 68us/step - loss: 0.6925 - acc: 0.5181 - val_loss: 0.6914 - val_acc: 0.5333\n",
      "Epoch 389/500\n",
      "3424/3424 [==============================] - ETA: 0s - loss: 0.6873 - acc: 0.590 - ETA: 0s - loss: 0.6920 - acc: 0.525 - ETA: 0s - loss: 0.6919 - acc: 0.525 - ETA: 0s - loss: 0.6918 - acc: 0.528 - ETA: 0s - loss: 0.6924 - acc: 0.519 - 0s 69us/step - loss: 0.6925 - acc: 0.5181 - val_loss: 0.6914 - val_acc: 0.5333\n",
      "Epoch 390/500\n",
      "3424/3424 [==============================] - ETA: 0s - loss: 0.6997 - acc: 0.420 - ETA: 0s - loss: 0.6933 - acc: 0.507 - ETA: 0s - loss: 0.6937 - acc: 0.501 - ETA: 0s - loss: 0.6931 - acc: 0.510 - 0s 64us/step - loss: 0.6926 - acc: 0.5181 - val_loss: 0.6915 - val_acc: 0.5333\n",
      "Epoch 391/500\n",
      "3424/3424 [==============================] - ETA: 0s - loss: 0.6910 - acc: 0.540 - ETA: 0s - loss: 0.6927 - acc: 0.515 - ETA: 0s - loss: 0.6925 - acc: 0.517 - ETA: 0s - loss: 0.6922 - acc: 0.522 - 0s 65us/step - loss: 0.6925 - acc: 0.5181 - val_loss: 0.6914 - val_acc: 0.5333\n",
      "Epoch 392/500\n",
      "3424/3424 [==============================] - ETA: 0s - loss: 0.6945 - acc: 0.490 - ETA: 0s - loss: 0.6935 - acc: 0.505 - ETA: 0s - loss: 0.6933 - acc: 0.507 - ETA: 0s - loss: 0.6926 - acc: 0.517 - 0s 64us/step - loss: 0.6925 - acc: 0.5181 - val_loss: 0.6914 - val_acc: 0.5333\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 393/500\n",
      "3424/3424 [==============================] - ETA: 0s - loss: 0.6945 - acc: 0.490 - ETA: 0s - loss: 0.6920 - acc: 0.525 - ETA: 0s - loss: 0.6922 - acc: 0.522 - ETA: 0s - loss: 0.6921 - acc: 0.523 - 0s 65us/step - loss: 0.6925 - acc: 0.5181 - val_loss: 0.6914 - val_acc: 0.5333\n",
      "Epoch 394/500\n",
      "3424/3424 [==============================] - ETA: 0s - loss: 0.6880 - acc: 0.580 - ETA: 0s - loss: 0.6920 - acc: 0.525 - ETA: 0s - loss: 0.6927 - acc: 0.515 - ETA: 0s - loss: 0.6924 - acc: 0.520 - ETA: 0s - loss: 0.6924 - acc: 0.519 - 0s 74us/step - loss: 0.6925 - acc: 0.5181 - val_loss: 0.6914 - val_acc: 0.5333\n",
      "Epoch 395/500\n",
      "3424/3424 [==============================] - ETA: 0s - loss: 0.6858 - acc: 0.610 - ETA: 0s - loss: 0.6914 - acc: 0.533 - ETA: 0s - loss: 0.6921 - acc: 0.524 - ETA: 0s - loss: 0.6925 - acc: 0.517 - 0s 65us/step - loss: 0.6925 - acc: 0.5181 - val_loss: 0.6914 - val_acc: 0.5333\n",
      "Epoch 396/500\n",
      "3424/3424 [==============================] - ETA: 0s - loss: 0.6895 - acc: 0.560 - ETA: 0s - loss: 0.6915 - acc: 0.531 - ETA: 0s - loss: 0.6919 - acc: 0.526 - ETA: 0s - loss: 0.6923 - acc: 0.520 - 0s 64us/step - loss: 0.6925 - acc: 0.5181 - val_loss: 0.6914 - val_acc: 0.5333\n",
      "Epoch 397/500\n",
      "3424/3424 [==============================] - ETA: 0s - loss: 0.6916 - acc: 0.530 - ETA: 0s - loss: 0.6919 - acc: 0.526 - ETA: 0s - loss: 0.6926 - acc: 0.516 - ETA: 0s - loss: 0.6929 - acc: 0.512 - 0s 63us/step - loss: 0.6925 - acc: 0.5181 - val_loss: 0.6915 - val_acc: 0.5333\n",
      "Epoch 398/500\n",
      "3424/3424 [==============================] - ETA: 0s - loss: 0.6958 - acc: 0.470 - ETA: 0s - loss: 0.6935 - acc: 0.503 - ETA: 0s - loss: 0.6919 - acc: 0.526 - ETA: 0s - loss: 0.6923 - acc: 0.521 - 0s 64us/step - loss: 0.6925 - acc: 0.5181 - val_loss: 0.6914 - val_acc: 0.5333\n",
      "Epoch 399/500\n",
      "3424/3424 [==============================] - ETA: 0s - loss: 0.6881 - acc: 0.580 - ETA: 0s - loss: 0.6919 - acc: 0.527 - ETA: 0s - loss: 0.6923 - acc: 0.521 - ETA: 0s - loss: 0.6920 - acc: 0.525 - 0s 66us/step - loss: 0.6925 - acc: 0.5181 - val_loss: 0.6914 - val_acc: 0.5333\n",
      "Epoch 400/500\n",
      "3424/3424 [==============================] - ETA: 0s - loss: 0.6909 - acc: 0.540 - ETA: 0s - loss: 0.6904 - acc: 0.547 - ETA: 0s - loss: 0.6925 - acc: 0.518 - ETA: 0s - loss: 0.6926 - acc: 0.516 - 0s 67us/step - loss: 0.6925 - acc: 0.5181 - val_loss: 0.6914 - val_acc: 0.5333\n",
      "Epoch 401/500\n",
      "3424/3424 [==============================] - ETA: 0s - loss: 0.6895 - acc: 0.560 - ETA: 0s - loss: 0.6916 - acc: 0.530 - ETA: 0s - loss: 0.6920 - acc: 0.525 - ETA: 0s - loss: 0.6924 - acc: 0.520 - ETA: 0s - loss: 0.6926 - acc: 0.516 - 0s 75us/step - loss: 0.6925 - acc: 0.5181 - val_loss: 0.6914 - val_acc: 0.5333\n",
      "Epoch 402/500\n",
      "3424/3424 [==============================] - ETA: 0s - loss: 0.6980 - acc: 0.440 - ETA: 0s - loss: 0.6932 - acc: 0.508 - ETA: 0s - loss: 0.6928 - acc: 0.513 - ETA: 0s - loss: 0.6927 - acc: 0.515 - 0s 60us/step - loss: 0.6925 - acc: 0.5181 - val_loss: 0.6915 - val_acc: 0.5333\n",
      "Epoch 403/500\n",
      "3424/3424 [==============================] - ETA: 0s - loss: 0.6896 - acc: 0.560 - ETA: 0s - loss: 0.6917 - acc: 0.529 - ETA: 0s - loss: 0.6923 - acc: 0.521 - ETA: 0s - loss: 0.6925 - acc: 0.518 - 0s 62us/step - loss: 0.6925 - acc: 0.5181 - val_loss: 0.6914 - val_acc: 0.5333\n",
      "Epoch 404/500\n",
      "3424/3424 [==============================] - ETA: 0s - loss: 0.6982 - acc: 0.440 - ETA: 0s - loss: 0.6932 - acc: 0.508 - ETA: 0s - loss: 0.6931 - acc: 0.509 - ETA: 0s - loss: 0.6929 - acc: 0.512 - 0s 67us/step - loss: 0.6925 - acc: 0.5181 - val_loss: 0.6914 - val_acc: 0.5333\n",
      "Epoch 405/500\n",
      "3424/3424 [==============================] - ETA: 0s - loss: 0.7020 - acc: 0.390 - ETA: 0s - loss: 0.6929 - acc: 0.512 - ETA: 0s - loss: 0.6926 - acc: 0.516 - ETA: 0s - loss: 0.6925 - acc: 0.518 - 0s 58us/step - loss: 0.6925 - acc: 0.5181 - val_loss: 0.6914 - val_acc: 0.5333\n",
      "Epoch 406/500\n",
      "3424/3424 [==============================] - ETA: 0s - loss: 0.6872 - acc: 0.590 - ETA: 0s - loss: 0.6916 - acc: 0.530 - ETA: 0s - loss: 0.6923 - acc: 0.521 - ETA: 0s - loss: 0.6925 - acc: 0.517 - 0s 67us/step - loss: 0.6925 - acc: 0.5181 - val_loss: 0.6914 - val_acc: 0.5333\n",
      "Epoch 407/500\n",
      "3424/3424 [==============================] - ETA: 0s - loss: 0.7005 - acc: 0.410 - ETA: 0s - loss: 0.6934 - acc: 0.505 - ETA: 0s - loss: 0.6931 - acc: 0.510 - ETA: 0s - loss: 0.6925 - acc: 0.517 - 0s 67us/step - loss: 0.6925 - acc: 0.5181 - val_loss: 0.6914 - val_acc: 0.5333\n",
      "Epoch 408/500\n",
      "3424/3424 [==============================] - ETA: 0s - loss: 0.6953 - acc: 0.480 - ETA: 0s - loss: 0.6927 - acc: 0.515 - ETA: 0s - loss: 0.6927 - acc: 0.515 - ETA: 0s - loss: 0.6927 - acc: 0.515 - 0s 64us/step - loss: 0.6925 - acc: 0.5181 - val_loss: 0.6913 - val_acc: 0.5327\n",
      "Epoch 409/500\n",
      "3424/3424 [==============================] - ETA: 0s - loss: 0.6962 - acc: 0.470 - ETA: 0s - loss: 0.6920 - acc: 0.524 - ETA: 0s - loss: 0.6925 - acc: 0.518 - ETA: 0s - loss: 0.6923 - acc: 0.521 - ETA: 0s - loss: 0.6925 - acc: 0.518 - 0s 73us/step - loss: 0.6925 - acc: 0.5181 - val_loss: 0.6914 - val_acc: 0.5327\n",
      "Epoch 410/500\n",
      "3424/3424 [==============================] - ETA: 0s - loss: 0.6939 - acc: 0.500 - ETA: 0s - loss: 0.6909 - acc: 0.539 - ETA: 0s - loss: 0.6927 - acc: 0.516 - ETA: 0s - loss: 0.6923 - acc: 0.520 - 0s 66us/step - loss: 0.6925 - acc: 0.5181 - val_loss: 0.6914 - val_acc: 0.5333\n",
      "Epoch 411/500\n",
      "3424/3424 [==============================] - ETA: 0s - loss: 0.6946 - acc: 0.490 - ETA: 0s - loss: 0.6913 - acc: 0.533 - ETA: 0s - loss: 0.6921 - acc: 0.523 - ETA: 0s - loss: 0.6921 - acc: 0.523 - 0s 67us/step - loss: 0.6925 - acc: 0.5181 - val_loss: 0.6914 - val_acc: 0.5333\n",
      "Epoch 412/500\n",
      "3424/3424 [==============================] - ETA: 0s - loss: 0.6953 - acc: 0.480 - ETA: 0s - loss: 0.6930 - acc: 0.510 - ETA: 0s - loss: 0.6919 - acc: 0.527 - ETA: 0s - loss: 0.6926 - acc: 0.516 - 0s 68us/step - loss: 0.6925 - acc: 0.5181 - val_loss: 0.6914 - val_acc: 0.5333\n",
      "Epoch 413/500\n",
      "3424/3424 [==============================] - ETA: 0s - loss: 0.6924 - acc: 0.520 - ETA: 0s - loss: 0.6913 - acc: 0.535 - ETA: 0s - loss: 0.6914 - acc: 0.533 - ETA: 0s - loss: 0.6926 - acc: 0.516 - 0s 62us/step - loss: 0.6925 - acc: 0.5181 - val_loss: 0.6914 - val_acc: 0.5333\n",
      "Epoch 414/500\n",
      "3424/3424 [==============================] - ETA: 0s - loss: 0.6952 - acc: 0.480 - ETA: 0s - loss: 0.6929 - acc: 0.513 - ETA: 0s - loss: 0.6925 - acc: 0.518 - ETA: 0s - loss: 0.6930 - acc: 0.511 - 0s 68us/step - loss: 0.6925 - acc: 0.5181 - val_loss: 0.6914 - val_acc: 0.5333\n",
      "Epoch 415/500\n",
      "3424/3424 [==============================] - ETA: 0s - loss: 0.6945 - acc: 0.490 - ETA: 0s - loss: 0.6923 - acc: 0.521 - ETA: 0s - loss: 0.6920 - acc: 0.524 - ETA: 0s - loss: 0.6923 - acc: 0.520 - ETA: 0s - loss: 0.6924 - acc: 0.518 - ETA: 0s - loss: 0.6924 - acc: 0.519 - 0s 94us/step - loss: 0.6925 - acc: 0.5181 - val_loss: 0.6914 - val_acc: 0.5333\n",
      "Epoch 416/500\n",
      "3424/3424 [==============================] - ETA: 0s - loss: 0.6980 - acc: 0.440 - ETA: 0s - loss: 0.6928 - acc: 0.513 - ETA: 0s - loss: 0.6922 - acc: 0.522 - ETA: 0s - loss: 0.6923 - acc: 0.520 - ETA: 0s - loss: 0.6923 - acc: 0.521 - 0s 80us/step - loss: 0.6925 - acc: 0.5181 - val_loss: 0.6914 - val_acc: 0.5333\n",
      "Epoch 417/500\n",
      "3424/3424 [==============================] - ETA: 0s - loss: 0.6916 - acc: 0.530 - ETA: 0s - loss: 0.6929 - acc: 0.512 - ETA: 0s - loss: 0.6922 - acc: 0.521 - ETA: 0s - loss: 0.6923 - acc: 0.521 - ETA: 0s - loss: 0.6925 - acc: 0.517 - 0s 71us/step - loss: 0.6925 - acc: 0.5181 - val_loss: 0.6914 - val_acc: 0.5333\n",
      "Epoch 418/500\n",
      "3424/3424 [==============================] - ETA: 0s - loss: 0.6895 - acc: 0.560 - ETA: 0s - loss: 0.6919 - acc: 0.526 - ETA: 0s - loss: 0.6917 - acc: 0.529 - ETA: 0s - loss: 0.6920 - acc: 0.525 - ETA: 0s - loss: 0.6923 - acc: 0.520 - ETA: 0s - loss: 0.6926 - acc: 0.517 - 0s 90us/step - loss: 0.6925 - acc: 0.5181 - val_loss: 0.6914 - val_acc: 0.5333\n",
      "Epoch 419/500\n",
      "3424/3424 [==============================] - ETA: 0s - loss: 0.6924 - acc: 0.520 - ETA: 0s - loss: 0.6941 - acc: 0.496 - ETA: 0s - loss: 0.6923 - acc: 0.520 - ETA: 0s - loss: 0.6920 - acc: 0.524 - ETA: 0s - loss: 0.6924 - acc: 0.520 - ETA: 0s - loss: 0.6927 - acc: 0.515 - 0s 99us/step - loss: 0.6925 - acc: 0.5181 - val_loss: 0.6914 - val_acc: 0.5333\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 420/500\n",
      "3424/3424 [==============================] - ETA: 0s - loss: 0.6931 - acc: 0.510 - ETA: 0s - loss: 0.6933 - acc: 0.507 - ETA: 0s - loss: 0.6928 - acc: 0.514 - ETA: 0s - loss: 0.6929 - acc: 0.512 - ETA: 0s - loss: 0.6925 - acc: 0.517 - ETA: 0s - loss: 0.6926 - acc: 0.516 - 0s 92us/step - loss: 0.6925 - acc: 0.5181 - val_loss: 0.6914 - val_acc: 0.5333\n",
      "Epoch 421/500\n",
      "3424/3424 [==============================] - ETA: 0s - loss: 0.6974 - acc: 0.450 - ETA: 0s - loss: 0.6934 - acc: 0.505 - ETA: 0s - loss: 0.6922 - acc: 0.522 - ETA: 0s - loss: 0.6924 - acc: 0.520 - ETA: 0s - loss: 0.6924 - acc: 0.519 - 0s 77us/step - loss: 0.6925 - acc: 0.5181 - val_loss: 0.6914 - val_acc: 0.5333\n",
      "Epoch 422/500\n",
      "3424/3424 [==============================] - ETA: 0s - loss: 0.6931 - acc: 0.510 - ETA: 0s - loss: 0.6930 - acc: 0.510 - ETA: 0s - loss: 0.6924 - acc: 0.520 - ETA: 0s - loss: 0.6923 - acc: 0.521 - 0s 61us/step - loss: 0.6925 - acc: 0.5181 - val_loss: 0.6914 - val_acc: 0.5327\n",
      "Epoch 423/500\n",
      "3424/3424 [==============================] - ETA: 0s - loss: 0.6946 - acc: 0.490 - ETA: 0s - loss: 0.6931 - acc: 0.510 - ETA: 0s - loss: 0.6923 - acc: 0.520 - ETA: 0s - loss: 0.6928 - acc: 0.513 - ETA: 0s - loss: 0.6927 - acc: 0.515 - ETA: 0s - loss: 0.6921 - acc: 0.523 - 0s 99us/step - loss: 0.6925 - acc: 0.5181 - val_loss: 0.6914 - val_acc: 0.5333\n",
      "Epoch 424/500\n",
      "3424/3424 [==============================] - ETA: 0s - loss: 0.6960 - acc: 0.470 - ETA: 0s - loss: 0.6931 - acc: 0.510 - ETA: 0s - loss: 0.6931 - acc: 0.509 - ETA: 0s - loss: 0.6927 - acc: 0.515 - ETA: 0s - loss: 0.6931 - acc: 0.510 - ETA: 0s - loss: 0.6925 - acc: 0.518 - 0s 94us/step - loss: 0.6925 - acc: 0.5181 - val_loss: 0.6914 - val_acc: 0.5333\n",
      "Epoch 425/500\n",
      "3424/3424 [==============================] - ETA: 0s - loss: 0.6916 - acc: 0.530 - ETA: 0s - loss: 0.6926 - acc: 0.517 - ETA: 0s - loss: 0.6925 - acc: 0.518 - ETA: 0s - loss: 0.6925 - acc: 0.518 - 0s 56us/step - loss: 0.6925 - acc: 0.5181 - val_loss: 0.6914 - val_acc: 0.5333\n",
      "Epoch 426/500\n",
      "3424/3424 [==============================] - ETA: 0s - loss: 0.7017 - acc: 0.390 - ETA: 0s - loss: 0.6905 - acc: 0.546 - ETA: 0s - loss: 0.6919 - acc: 0.526 - ETA: 0s - loss: 0.6922 - acc: 0.521 - 0s 63us/step - loss: 0.6925 - acc: 0.5181 - val_loss: 0.6914 - val_acc: 0.5333\n",
      "Epoch 427/500\n",
      "3424/3424 [==============================] - ETA: 0s - loss: 0.6931 - acc: 0.510 - ETA: 0s - loss: 0.6931 - acc: 0.509 - ETA: 0s - loss: 0.6926 - acc: 0.516 - ETA: 0s - loss: 0.6923 - acc: 0.521 - ETA: 0s - loss: 0.6927 - acc: 0.515 - 0s 79us/step - loss: 0.6925 - acc: 0.5181 - val_loss: 0.6915 - val_acc: 0.5333\n",
      "Epoch 428/500\n",
      "3424/3424 [==============================] - ETA: 0s - loss: 0.6917 - acc: 0.530 - ETA: 0s - loss: 0.6923 - acc: 0.521 - ETA: 0s - loss: 0.6919 - acc: 0.526 - ETA: 0s - loss: 0.6924 - acc: 0.520 - ETA: 0s - loss: 0.6926 - acc: 0.516 - 0s 80us/step - loss: 0.6925 - acc: 0.5181 - val_loss: 0.6915 - val_acc: 0.5333\n",
      "Epoch 429/500\n",
      "3424/3424 [==============================] - ETA: 0s - loss: 0.6924 - acc: 0.520 - ETA: 0s - loss: 0.6919 - acc: 0.527 - ETA: 0s - loss: 0.6923 - acc: 0.521 - ETA: 0s - loss: 0.6925 - acc: 0.518 - 0s 61us/step - loss: 0.6925 - acc: 0.5181 - val_loss: 0.6915 - val_acc: 0.5333\n",
      "Epoch 430/500\n",
      "3424/3424 [==============================] - ETA: 0s - loss: 0.6917 - acc: 0.530 - ETA: 0s - loss: 0.6926 - acc: 0.516 - ETA: 0s - loss: 0.6915 - acc: 0.532 - ETA: 0s - loss: 0.6921 - acc: 0.524 - ETA: 0s - loss: 0.6924 - acc: 0.519 - 0s 75us/step - loss: 0.6925 - acc: 0.5181 - val_loss: 0.6915 - val_acc: 0.5333\n",
      "Epoch 431/500\n",
      "3424/3424 [==============================] - ETA: 0s - loss: 0.6979 - acc: 0.440 - ETA: 0s - loss: 0.6924 - acc: 0.520 - ETA: 0s - loss: 0.6920 - acc: 0.526 - ETA: 0s - loss: 0.6928 - acc: 0.514 - ETA: 0s - loss: 0.6925 - acc: 0.518 - 0s 82us/step - loss: 0.6925 - acc: 0.5181 - val_loss: 0.6915 - val_acc: 0.5333\n",
      "Epoch 432/500\n",
      "3424/3424 [==============================] - ETA: 0s - loss: 0.6869 - acc: 0.600 - ETA: 0s - loss: 0.6913 - acc: 0.535 - ETA: 0s - loss: 0.6922 - acc: 0.523 - ETA: 0s - loss: 0.6923 - acc: 0.521 - ETA: 0s - loss: 0.6924 - acc: 0.519 - 0s 73us/step - loss: 0.6925 - acc: 0.5181 - val_loss: 0.6914 - val_acc: 0.5333\n",
      "Epoch 433/500\n",
      "3424/3424 [==============================] - ETA: 0s - loss: 0.6945 - acc: 0.490 - ETA: 0s - loss: 0.6941 - acc: 0.495 - ETA: 0s - loss: 0.6930 - acc: 0.511 - ETA: 0s - loss: 0.6928 - acc: 0.513 - 0s 66us/step - loss: 0.6925 - acc: 0.5181 - val_loss: 0.6915 - val_acc: 0.5333\n",
      "Epoch 434/500\n",
      "3424/3424 [==============================] - ETA: 0s - loss: 0.6917 - acc: 0.530 - ETA: 0s - loss: 0.6926 - acc: 0.516 - ETA: 0s - loss: 0.6919 - acc: 0.527 - ETA: 0s - loss: 0.6922 - acc: 0.522 - 0s 63us/step - loss: 0.6925 - acc: 0.5181 - val_loss: 0.6914 - val_acc: 0.5333\n",
      "Epoch 435/500\n",
      "3424/3424 [==============================] - ETA: 0s - loss: 0.7039 - acc: 0.360 - ETA: 0s - loss: 0.6924 - acc: 0.520 - ETA: 0s - loss: 0.6921 - acc: 0.523 - ETA: 0s - loss: 0.6921 - acc: 0.523 - ETA: 0s - loss: 0.6927 - acc: 0.515 - ETA: 0s - loss: 0.6924 - acc: 0.519 - ETA: 0s - loss: 0.6925 - acc: 0.517 - 0s 112us/step - loss: 0.6925 - acc: 0.5181 - val_loss: 0.6914 - val_acc: 0.5333\n",
      "Epoch 436/500\n",
      "3424/3424 [==============================] - ETA: 0s - loss: 0.6866 - acc: 0.600 - ETA: 0s - loss: 0.6913 - acc: 0.535 - ETA: 0s - loss: 0.6919 - acc: 0.525 - ETA: 0s - loss: 0.6922 - acc: 0.521 - ETA: 0s - loss: 0.6923 - acc: 0.520 - 0s 88us/step - loss: 0.6925 - acc: 0.5181 - val_loss: 0.6914 - val_acc: 0.5333\n",
      "Epoch 437/500\n",
      "3424/3424 [==============================] - ETA: 0s - loss: 0.6916 - acc: 0.530 - ETA: 0s - loss: 0.6927 - acc: 0.515 - ETA: 0s - loss: 0.6927 - acc: 0.515 - ETA: 0s - loss: 0.6924 - acc: 0.519 - ETA: 0s - loss: 0.6925 - acc: 0.518 - 0s 74us/step - loss: 0.6925 - acc: 0.5181 - val_loss: 0.6914 - val_acc: 0.5333\n",
      "Epoch 438/500\n",
      "3424/3424 [==============================] - ETA: 0s - loss: 0.6931 - acc: 0.510 - ETA: 0s - loss: 0.6926 - acc: 0.516 - ETA: 0s - loss: 0.6929 - acc: 0.513 - ETA: 0s - loss: 0.6926 - acc: 0.517 - 0s 67us/step - loss: 0.6925 - acc: 0.5181 - val_loss: 0.6915 - val_acc: 0.5333\n",
      "Epoch 439/500\n",
      "3424/3424 [==============================] - ETA: 0s - loss: 0.6903 - acc: 0.550 - ETA: 0s - loss: 0.6919 - acc: 0.526 - ETA: 0s - loss: 0.6926 - acc: 0.516 - ETA: 0s - loss: 0.6923 - acc: 0.520 - ETA: 0s - loss: 0.6924 - acc: 0.519 - ETA: 0s - loss: 0.6927 - acc: 0.515 - ETA: 0s - loss: 0.6925 - acc: 0.517 - 0s 112us/step - loss: 0.6925 - acc: 0.5181 - val_loss: 0.6914 - val_acc: 0.5333\n",
      "Epoch 440/500\n",
      "3424/3424 [==============================] - ETA: 0s - loss: 0.6888 - acc: 0.570 - ETA: 0s - loss: 0.6928 - acc: 0.513 - ETA: 0s - loss: 0.6927 - acc: 0.515 - ETA: 0s - loss: 0.6925 - acc: 0.517 - ETA: 0s - loss: 0.6927 - acc: 0.515 - 0s 78us/step - loss: 0.6925 - acc: 0.5181 - val_loss: 0.6914 - val_acc: 0.5333\n",
      "Epoch 441/500\n",
      "3424/3424 [==============================] - ETA: 0s - loss: 0.6931 - acc: 0.510 - ETA: 0s - loss: 0.6937 - acc: 0.501 - ETA: 0s - loss: 0.6934 - acc: 0.505 - ETA: 0s - loss: 0.6927 - acc: 0.515 - 0s 63us/step - loss: 0.6925 - acc: 0.5181 - val_loss: 0.6914 - val_acc: 0.5333\n",
      "Epoch 442/500\n",
      "3424/3424 [==============================] - ETA: 0s - loss: 0.6924 - acc: 0.520 - ETA: 0s - loss: 0.6933 - acc: 0.507 - ETA: 0s - loss: 0.6929 - acc: 0.511 - ETA: 0s - loss: 0.6926 - acc: 0.516 - 0s 68us/step - loss: 0.6925 - acc: 0.5181 - val_loss: 0.6914 - val_acc: 0.5333\n",
      "Epoch 443/500\n",
      "3424/3424 [==============================] - ETA: 0s - loss: 0.6924 - acc: 0.520 - ETA: 0s - loss: 0.6919 - acc: 0.526 - ETA: 0s - loss: 0.6923 - acc: 0.521 - ETA: 0s - loss: 0.6927 - acc: 0.515 - 0s 63us/step - loss: 0.6925 - acc: 0.5181 - val_loss: 0.6914 - val_acc: 0.5333\n",
      "Epoch 444/500\n",
      "3424/3424 [==============================] - ETA: 0s - loss: 0.6953 - acc: 0.480 - ETA: 0s - loss: 0.6922 - acc: 0.521 - ETA: 0s - loss: 0.6928 - acc: 0.514 - ETA: 0s - loss: 0.6923 - acc: 0.520 - 0s 64us/step - loss: 0.6925 - acc: 0.5181 - val_loss: 0.6914 - val_acc: 0.5327\n",
      "Epoch 445/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3424/3424 [==============================] - ETA: 0s - loss: 0.6886 - acc: 0.570 - ETA: 0s - loss: 0.6919 - acc: 0.526 - ETA: 0s - loss: 0.6926 - acc: 0.517 - ETA: 0s - loss: 0.6924 - acc: 0.519 - ETA: 0s - loss: 0.6926 - acc: 0.517 - 0s 75us/step - loss: 0.6925 - acc: 0.5181 - val_loss: 0.6913 - val_acc: 0.5327\n",
      "Epoch 446/500\n",
      "3424/3424 [==============================] - ETA: 0s - loss: 0.6877 - acc: 0.580 - ETA: 0s - loss: 0.6933 - acc: 0.507 - ETA: 0s - loss: 0.6927 - acc: 0.515 - ETA: 0s - loss: 0.6925 - acc: 0.518 - ETA: 0s - loss: 0.6927 - acc: 0.515 - ETA: 0s - loss: 0.6925 - acc: 0.518 - 0s 114us/step - loss: 0.6925 - acc: 0.5181 - val_loss: 0.6914 - val_acc: 0.5327\n",
      "Epoch 447/500\n",
      "3424/3424 [==============================] - ETA: 0s - loss: 0.6969 - acc: 0.460 - ETA: 0s - loss: 0.6945 - acc: 0.491 - ETA: 0s - loss: 0.6936 - acc: 0.503 - ETA: 0s - loss: 0.6931 - acc: 0.509 - ETA: 0s - loss: 0.6929 - acc: 0.513 - ETA: 0s - loss: 0.6926 - acc: 0.516 - 0s 98us/step - loss: 0.6925 - acc: 0.5181 - val_loss: 0.6914 - val_acc: 0.5333\n",
      "Epoch 448/500\n",
      "3424/3424 [==============================] - ETA: 0s - loss: 0.6886 - acc: 0.570 - ETA: 0s - loss: 0.6921 - acc: 0.523 - ETA: 0s - loss: 0.6912 - acc: 0.534 - ETA: 0s - loss: 0.6917 - acc: 0.528 - ETA: 0s - loss: 0.6921 - acc: 0.523 - 0s 94us/step - loss: 0.6925 - acc: 0.5181 - val_loss: 0.6913 - val_acc: 0.5327\n",
      "Epoch 449/500\n",
      "3424/3424 [==============================] - ETA: 0s - loss: 0.6923 - acc: 0.520 - ETA: 0s - loss: 0.6920 - acc: 0.523 - ETA: 0s - loss: 0.6930 - acc: 0.512 - ETA: 0s - loss: 0.6926 - acc: 0.516 - ETA: 0s - loss: 0.6925 - acc: 0.517 - ETA: 0s - loss: 0.6927 - acc: 0.516 - 0s 101us/step - loss: 0.6925 - acc: 0.5181 - val_loss: 0.6913 - val_acc: 0.5327\n",
      "Epoch 450/500\n",
      "3424/3424 [==============================] - ETA: 0s - loss: 0.6830 - acc: 0.640 - ETA: 0s - loss: 0.6922 - acc: 0.521 - ETA: 0s - loss: 0.6922 - acc: 0.522 - ETA: 0s - loss: 0.6921 - acc: 0.522 - ETA: 0s - loss: 0.6929 - acc: 0.513 - ETA: 0s - loss: 0.6924 - acc: 0.519 - 0s 91us/step - loss: 0.6925 - acc: 0.5181 - val_loss: 0.6913 - val_acc: 0.5327\n",
      "Epoch 451/500\n",
      "3424/3424 [==============================] - ETA: 0s - loss: 0.6916 - acc: 0.530 - ETA: 0s - loss: 0.6927 - acc: 0.515 - ETA: 0s - loss: 0.6934 - acc: 0.506 - ETA: 0s - loss: 0.6934 - acc: 0.506 - ETA: 0s - loss: 0.6924 - acc: 0.519 - ETA: 0s - loss: 0.6924 - acc: 0.519 - 0s 112us/step - loss: 0.6925 - acc: 0.5181 - val_loss: 0.6914 - val_acc: 0.5333\n",
      "Epoch 452/500\n",
      "3424/3424 [==============================] - ETA: 0s - loss: 0.6976 - acc: 0.450 - ETA: 0s - loss: 0.6916 - acc: 0.530 - ETA: 0s - loss: 0.6935 - acc: 0.505 - ETA: 0s - loss: 0.6938 - acc: 0.500 - ETA: 0s - loss: 0.6935 - acc: 0.504 - ETA: 0s - loss: 0.6925 - acc: 0.518 - ETA: 0s - loss: 0.6925 - acc: 0.518 - 0s 116us/step - loss: 0.6925 - acc: 0.5181 - val_loss: 0.6914 - val_acc: 0.5333\n",
      "Epoch 453/500\n",
      "3424/3424 [==============================] - ETA: 0s - loss: 0.6916 - acc: 0.530 - ETA: 0s - loss: 0.6916 - acc: 0.530 - ETA: 0s - loss: 0.6920 - acc: 0.524 - ETA: 0s - loss: 0.6919 - acc: 0.526 - ETA: 0s - loss: 0.6923 - acc: 0.521 - ETA: 0s - loss: 0.6924 - acc: 0.519 - 0s 98us/step - loss: 0.6925 - acc: 0.5181 - val_loss: 0.6914 - val_acc: 0.5333\n",
      "Epoch 454/500\n",
      "3424/3424 [==============================] - ETA: 0s - loss: 0.6938 - acc: 0.500 - ETA: 0s - loss: 0.6918 - acc: 0.528 - ETA: 0s - loss: 0.6909 - acc: 0.539 - ETA: 0s - loss: 0.6913 - acc: 0.533 - ETA: 0s - loss: 0.6919 - acc: 0.526 - ETA: 0s - loss: 0.6920 - acc: 0.524 - ETA: 0s - loss: 0.6924 - acc: 0.519 - 0s 108us/step - loss: 0.6925 - acc: 0.5181 - val_loss: 0.6914 - val_acc: 0.5327\n",
      "Epoch 455/500\n",
      "3424/3424 [==============================] - ETA: 0s - loss: 0.6916 - acc: 0.530 - ETA: 0s - loss: 0.6911 - acc: 0.536 - ETA: 0s - loss: 0.6913 - acc: 0.534 - ETA: 0s - loss: 0.6918 - acc: 0.526 - ETA: 0s - loss: 0.6923 - acc: 0.520 - 0s 94us/step - loss: 0.6925 - acc: 0.5181 - val_loss: 0.6914 - val_acc: 0.5333\n",
      "Epoch 456/500\n",
      "3424/3424 [==============================] - ETA: 0s - loss: 0.6924 - acc: 0.520 - ETA: 0s - loss: 0.6925 - acc: 0.518 - ETA: 0s - loss: 0.6940 - acc: 0.497 - ETA: 0s - loss: 0.6939 - acc: 0.498 - ETA: 0s - loss: 0.6933 - acc: 0.507 - ETA: 0s - loss: 0.6929 - acc: 0.511 - 0s 100us/step - loss: 0.6925 - acc: 0.5181 - val_loss: 0.6914 - val_acc: 0.5333\n",
      "Epoch 457/500\n",
      "3424/3424 [==============================] - ETA: 0s - loss: 0.6896 - acc: 0.560 - ETA: 0s - loss: 0.6921 - acc: 0.524 - ETA: 0s - loss: 0.6929 - acc: 0.512 - ETA: 0s - loss: 0.6931 - acc: 0.509 - ETA: 0s - loss: 0.6931 - acc: 0.510 - ETA: 0s - loss: 0.6929 - acc: 0.512 - 0s 99us/step - loss: 0.6925 - acc: 0.5181 - val_loss: 0.6914 - val_acc: 0.5333\n",
      "Epoch 458/500\n",
      "3424/3424 [==============================] - ETA: 0s - loss: 0.6952 - acc: 0.480 - ETA: 0s - loss: 0.6928 - acc: 0.514 - ETA: 0s - loss: 0.6923 - acc: 0.521 - ETA: 0s - loss: 0.6918 - acc: 0.527 - ETA: 0s - loss: 0.6924 - acc: 0.520 - 0s 73us/step - loss: 0.6925 - acc: 0.5181 - val_loss: 0.6913 - val_acc: 0.5327\n",
      "Epoch 459/500\n",
      "3424/3424 [==============================] - ETA: 0s - loss: 0.7016 - acc: 0.400 - ETA: 0s - loss: 0.6943 - acc: 0.494 - ETA: 0s - loss: 0.6931 - acc: 0.510 - ETA: 0s - loss: 0.6932 - acc: 0.508 - ETA: 0s - loss: 0.6929 - acc: 0.512 - 0s 91us/step - loss: 0.6925 - acc: 0.5181 - val_loss: 0.6914 - val_acc: 0.5333\n",
      "Epoch 460/500\n",
      "3424/3424 [==============================] - ETA: 0s - loss: 0.6952 - acc: 0.480 - ETA: 0s - loss: 0.6908 - acc: 0.542 - ETA: 0s - loss: 0.6922 - acc: 0.523 - ETA: 0s - loss: 0.6929 - acc: 0.513 - ETA: 0s - loss: 0.6930 - acc: 0.511 - 0s 80us/step - loss: 0.6925 - acc: 0.5181 - val_loss: 0.6914 - val_acc: 0.5333\n",
      "Epoch 461/500\n",
      "3424/3424 [==============================] - ETA: 0s - loss: 0.6931 - acc: 0.510 - ETA: 0s - loss: 0.6896 - acc: 0.556 - ETA: 0s - loss: 0.6912 - acc: 0.536 - ETA: 0s - loss: 0.6913 - acc: 0.533 - ETA: 0s - loss: 0.6920 - acc: 0.524 - ETA: 0s - loss: 0.6925 - acc: 0.518 - 0s 91us/step - loss: 0.6925 - acc: 0.5181 - val_loss: 0.6913 - val_acc: 0.5327\n",
      "Epoch 462/500\n",
      "3424/3424 [==============================] - ETA: 0s - loss: 0.6954 - acc: 0.480 - ETA: 0s - loss: 0.6944 - acc: 0.493 - ETA: 0s - loss: 0.6943 - acc: 0.494 - ETA: 0s - loss: 0.6936 - acc: 0.502 - ETA: 0s - loss: 0.6932 - acc: 0.509 - ETA: 0s - loss: 0.6928 - acc: 0.514 - 0s 97us/step - loss: 0.6925 - acc: 0.5181 - val_loss: 0.6914 - val_acc: 0.5333\n",
      "Epoch 463/500\n",
      "3424/3424 [==============================] - ETA: 0s - loss: 0.6994 - acc: 0.420 - ETA: 0s - loss: 0.6935 - acc: 0.504 - ETA: 0s - loss: 0.6923 - acc: 0.520 - ETA: 0s - loss: 0.6929 - acc: 0.512 - 0s 70us/step - loss: 0.6925 - acc: 0.5181 - val_loss: 0.6914 - val_acc: 0.5333\n",
      "Epoch 464/500\n",
      "3424/3424 [==============================] - ETA: 0s - loss: 0.6909 - acc: 0.540 - ETA: 0s - loss: 0.6927 - acc: 0.515 - ETA: 0s - loss: 0.6934 - acc: 0.506 - ETA: 0s - loss: 0.6926 - acc: 0.516 - ETA: 0s - loss: 0.6926 - acc: 0.517 - ETA: 0s - loss: 0.6927 - acc: 0.515 - ETA: 0s - loss: 0.6928 - acc: 0.514 - 0s 115us/step - loss: 0.6925 - acc: 0.5181 - val_loss: 0.6914 - val_acc: 0.5333\n",
      "Epoch 465/500\n",
      "3424/3424 [==============================] - ETA: 0s - loss: 0.6901 - acc: 0.550 - ETA: 0s - loss: 0.6925 - acc: 0.518 - ETA: 0s - loss: 0.6918 - acc: 0.527 - ETA: 0s - loss: 0.6926 - acc: 0.517 - ETA: 0s - loss: 0.6923 - acc: 0.520 - 0s 79us/step - loss: 0.6925 - acc: 0.5181 - val_loss: 0.6914 - val_acc: 0.5327\n",
      "Epoch 466/500\n",
      "3424/3424 [==============================] - ETA: 0s - loss: 0.6954 - acc: 0.480 - ETA: 0s - loss: 0.6930 - acc: 0.512 - ETA: 0s - loss: 0.6926 - acc: 0.517 - ETA: 0s - loss: 0.6923 - acc: 0.521 - 0s 64us/step - loss: 0.6925 - acc: 0.5181 - val_loss: 0.6914 - val_acc: 0.5327\n",
      "Epoch 467/500\n",
      "3424/3424 [==============================] - ETA: 0s - loss: 0.6977 - acc: 0.450 - ETA: 0s - loss: 0.6924 - acc: 0.520 - ETA: 0s - loss: 0.6926 - acc: 0.516 - ETA: 0s - loss: 0.6927 - acc: 0.515 - ETA: 0s - loss: 0.6923 - acc: 0.521 - 0s 87us/step - loss: 0.6925 - acc: 0.5181 - val_loss: 0.6914 - val_acc: 0.5327\n",
      "Epoch 468/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3424/3424 [==============================] - ETA: 0s - loss: 0.6954 - acc: 0.480 - ETA: 0s - loss: 0.6930 - acc: 0.511 - ETA: 0s - loss: 0.6927 - acc: 0.515 - ETA: 0s - loss: 0.6925 - acc: 0.517 - ETA: 0s - loss: 0.6927 - acc: 0.515 - 0s 74us/step - loss: 0.6925 - acc: 0.5181 - val_loss: 0.6914 - val_acc: 0.5333\n",
      "Epoch 469/500\n",
      "3424/3424 [==============================] - ETA: 0s - loss: 0.6939 - acc: 0.500 - ETA: 0s - loss: 0.6945 - acc: 0.491 - ETA: 0s - loss: 0.6935 - acc: 0.505 - ETA: 0s - loss: 0.6931 - acc: 0.510 - ETA: 0s - loss: 0.6931 - acc: 0.509 - ETA: 0s - loss: 0.6925 - acc: 0.518 - 0s 99us/step - loss: 0.6925 - acc: 0.5181 - val_loss: 0.6914 - val_acc: 0.5333\n",
      "Epoch 470/500\n",
      "3424/3424 [==============================] - ETA: 0s - loss: 0.6916 - acc: 0.530 - ETA: 0s - loss: 0.6915 - acc: 0.531 - ETA: 0s - loss: 0.6918 - acc: 0.527 - ETA: 0s - loss: 0.6917 - acc: 0.529 - ETA: 0s - loss: 0.6920 - acc: 0.524 - 0s 93us/step - loss: 0.6925 - acc: 0.5181 - val_loss: 0.6913 - val_acc: 0.5327\n",
      "Epoch 471/500\n",
      "3424/3424 [==============================] - ETA: 0s - loss: 0.6931 - acc: 0.510 - ETA: 0s - loss: 0.6934 - acc: 0.506 - ETA: 0s - loss: 0.6921 - acc: 0.523 - ETA: 0s - loss: 0.6928 - acc: 0.514 - ETA: 0s - loss: 0.6924 - acc: 0.520 - 0s 79us/step - loss: 0.6925 - acc: 0.5181 - val_loss: 0.6914 - val_acc: 0.5333\n",
      "Epoch 472/500\n",
      "3424/3424 [==============================] - ETA: 0s - loss: 0.6857 - acc: 0.610 - ETA: 0s - loss: 0.6906 - acc: 0.544 - ETA: 0s - loss: 0.6924 - acc: 0.519 - ETA: 0s - loss: 0.6927 - acc: 0.515 - ETA: 0s - loss: 0.6924 - acc: 0.518 - 0s 82us/step - loss: 0.6925 - acc: 0.5181 - val_loss: 0.6914 - val_acc: 0.5333\n",
      "Epoch 473/500\n",
      "3424/3424 [==============================] - ETA: 0s - loss: 0.6945 - acc: 0.490 - ETA: 0s - loss: 0.6930 - acc: 0.511 - ETA: 0s - loss: 0.6931 - acc: 0.509 - ETA: 0s - loss: 0.6931 - acc: 0.510 - ETA: 0s - loss: 0.6924 - acc: 0.519 - 0s 81us/step - loss: 0.6925 - acc: 0.5181 - val_loss: 0.6914 - val_acc: 0.5333\n",
      "Epoch 474/500\n",
      "3424/3424 [==============================] - ETA: 0s - loss: 0.6902 - acc: 0.550 - ETA: 0s - loss: 0.6926 - acc: 0.517 - ETA: 0s - loss: 0.6926 - acc: 0.516 - ETA: 0s - loss: 0.6922 - acc: 0.522 - ETA: 0s - loss: 0.6925 - acc: 0.518 - 0s 76us/step - loss: 0.6925 - acc: 0.5181 - val_loss: 0.6914 - val_acc: 0.5333\n",
      "Epoch 475/500\n",
      "3424/3424 [==============================] - ETA: 0s - loss: 0.6989 - acc: 0.430 - ETA: 0s - loss: 0.6920 - acc: 0.527 - ETA: 0s - loss: 0.6932 - acc: 0.508 - ETA: 0s - loss: 0.6928 - acc: 0.514 - 0s 67us/step - loss: 0.6925 - acc: 0.5181 - val_loss: 0.6914 - val_acc: 0.5333\n",
      "Epoch 476/500\n",
      "3424/3424 [==============================] - ETA: 0s - loss: 0.6924 - acc: 0.520 - ETA: 0s - loss: 0.6924 - acc: 0.520 - ETA: 0s - loss: 0.6932 - acc: 0.507 - ETA: 0s - loss: 0.6923 - acc: 0.520 - 0s 63us/step - loss: 0.6925 - acc: 0.5181 - val_loss: 0.6914 - val_acc: 0.5333\n",
      "Epoch 477/500\n",
      "3424/3424 [==============================] - ETA: 0s - loss: 0.6924 - acc: 0.520 - ETA: 0s - loss: 0.6927 - acc: 0.516 - ETA: 0s - loss: 0.6931 - acc: 0.509 - ETA: 0s - loss: 0.6926 - acc: 0.516 - 0s 69us/step - loss: 0.6925 - acc: 0.5181 - val_loss: 0.6914 - val_acc: 0.5333\n",
      "Epoch 478/500\n",
      "3424/3424 [==============================] - ETA: 0s - loss: 0.6887 - acc: 0.570 - ETA: 0s - loss: 0.6920 - acc: 0.524 - ETA: 0s - loss: 0.6917 - acc: 0.528 - ETA: 0s - loss: 0.6924 - acc: 0.519 - ETA: 0s - loss: 0.6924 - acc: 0.519 - 0s 85us/step - loss: 0.6925 - acc: 0.5181 - val_loss: 0.6914 - val_acc: 0.5327\n",
      "Epoch 479/500\n",
      "3424/3424 [==============================] - ETA: 0s - loss: 0.6946 - acc: 0.490 - ETA: 0s - loss: 0.6943 - acc: 0.494 - ETA: 0s - loss: 0.6930 - acc: 0.511 - ETA: 0s - loss: 0.6922 - acc: 0.521 - ETA: 0s - loss: 0.6923 - acc: 0.520 - ETA: 0s - loss: 0.6927 - acc: 0.515 - 0s 95us/step - loss: 0.6925 - acc: 0.5181 - val_loss: 0.6914 - val_acc: 0.5327\n",
      "Epoch 480/500\n",
      "3424/3424 [==============================] - ETA: 0s - loss: 0.6976 - acc: 0.450 - ETA: 0s - loss: 0.6932 - acc: 0.509 - ETA: 0s - loss: 0.6926 - acc: 0.517 - ETA: 0s - loss: 0.6926 - acc: 0.517 - ETA: 0s - loss: 0.6925 - acc: 0.517 - ETA: 0s - loss: 0.6923 - acc: 0.520 - 0s 99us/step - loss: 0.6925 - acc: 0.5181 - val_loss: 0.6913 - val_acc: 0.5327\n",
      "Epoch 481/500\n",
      "3424/3424 [==============================] - ETA: 0s - loss: 0.6900 - acc: 0.550 - ETA: 0s - loss: 0.6927 - acc: 0.515 - ETA: 0s - loss: 0.6928 - acc: 0.513 - ETA: 0s - loss: 0.6928 - acc: 0.514 - ETA: 0s - loss: 0.6924 - acc: 0.519 - ETA: 0s - loss: 0.6923 - acc: 0.520 - 0s 100us/step - loss: 0.6925 - acc: 0.5181 - val_loss: 0.6913 - val_acc: 0.5327\n",
      "Epoch 482/500\n",
      "3424/3424 [==============================] - ETA: 0s - loss: 0.6970 - acc: 0.460 - ETA: 0s - loss: 0.6912 - acc: 0.535 - ETA: 0s - loss: 0.6909 - acc: 0.539 - ETA: 0s - loss: 0.6916 - acc: 0.529 - ETA: 0s - loss: 0.6922 - acc: 0.521 - ETA: 0s - loss: 0.6925 - acc: 0.517 - 0s 92us/step - loss: 0.6925 - acc: 0.5181 - val_loss: 0.6914 - val_acc: 0.5333\n",
      "Epoch 483/500\n",
      "3424/3424 [==============================] - ETA: 0s - loss: 0.7006 - acc: 0.410 - ETA: 0s - loss: 0.6941 - acc: 0.496 - ETA: 0s - loss: 0.6924 - acc: 0.520 - ETA: 0s - loss: 0.6923 - acc: 0.521 - ETA: 0s - loss: 0.6923 - acc: 0.521 - 0s 78us/step - loss: 0.6925 - acc: 0.5181 - val_loss: 0.6914 - val_acc: 0.5333\n",
      "Epoch 484/500\n",
      "3424/3424 [==============================] - ETA: 0s - loss: 0.6916 - acc: 0.530 - ETA: 0s - loss: 0.6916 - acc: 0.530 - ETA: 0s - loss: 0.6924 - acc: 0.518 - ETA: 0s - loss: 0.6924 - acc: 0.519 - 0s 68us/step - loss: 0.6925 - acc: 0.5181 - val_loss: 0.6914 - val_acc: 0.5333\n",
      "Epoch 485/500\n",
      "3424/3424 [==============================] - ETA: 0s - loss: 0.6880 - acc: 0.580 - ETA: 0s - loss: 0.6909 - acc: 0.540 - ETA: 0s - loss: 0.6918 - acc: 0.528 - ETA: 0s - loss: 0.6924 - acc: 0.519 - ETA: 0s - loss: 0.6926 - acc: 0.517 - 0s 81us/step - loss: 0.6925 - acc: 0.5181 - val_loss: 0.6914 - val_acc: 0.5333\n",
      "Epoch 486/500\n",
      "3424/3424 [==============================] - ETA: 0s - loss: 0.6952 - acc: 0.480 - ETA: 0s - loss: 0.6948 - acc: 0.485 - ETA: 0s - loss: 0.6931 - acc: 0.509 - ETA: 0s - loss: 0.6927 - acc: 0.515 - ETA: 0s - loss: 0.6926 - acc: 0.517 - 0s 72us/step - loss: 0.6925 - acc: 0.5181 - val_loss: 0.6915 - val_acc: 0.5333\n",
      "Epoch 487/500\n",
      "3424/3424 [==============================] - ETA: 0s - loss: 0.6951 - acc: 0.480 - ETA: 0s - loss: 0.6938 - acc: 0.499 - ETA: 0s - loss: 0.6922 - acc: 0.522 - ETA: 0s - loss: 0.6925 - acc: 0.518 - 0s 63us/step - loss: 0.6925 - acc: 0.5181 - val_loss: 0.6914 - val_acc: 0.5333\n",
      "Epoch 488/500\n",
      "3424/3424 [==============================] - ETA: 0s - loss: 0.6916 - acc: 0.530 - ETA: 0s - loss: 0.6915 - acc: 0.532 - ETA: 0s - loss: 0.6920 - acc: 0.524 - ETA: 0s - loss: 0.6924 - acc: 0.519 - 0s 64us/step - loss: 0.6925 - acc: 0.5181 - val_loss: 0.6914 - val_acc: 0.5333\n",
      "Epoch 489/500\n",
      "3424/3424 [==============================] - ETA: 0s - loss: 0.6967 - acc: 0.460 - ETA: 0s - loss: 0.6916 - acc: 0.530 - ETA: 0s - loss: 0.6923 - acc: 0.520 - ETA: 0s - loss: 0.6923 - acc: 0.520 - 0s 58us/step - loss: 0.6925 - acc: 0.5181 - val_loss: 0.6914 - val_acc: 0.5333\n",
      "Epoch 490/500\n",
      "3424/3424 [==============================] - ETA: 0s - loss: 0.6909 - acc: 0.540 - ETA: 0s - loss: 0.6920 - acc: 0.525 - ETA: 0s - loss: 0.6922 - acc: 0.522 - ETA: 0s - loss: 0.6922 - acc: 0.522 - 0s 60us/step - loss: 0.6925 - acc: 0.5181 - val_loss: 0.6914 - val_acc: 0.5333\n",
      "Epoch 491/500\n",
      "3424/3424 [==============================] - ETA: 0s - loss: 0.6866 - acc: 0.600 - ETA: 0s - loss: 0.6910 - acc: 0.538 - ETA: 0s - loss: 0.6918 - acc: 0.528 - ETA: 0s - loss: 0.6925 - acc: 0.518 - 0s 61us/step - loss: 0.6925 - acc: 0.5181 - val_loss: 0.6914 - val_acc: 0.5333\n",
      "Epoch 492/500\n",
      "3424/3424 [==============================] - ETA: 0s - loss: 0.6896 - acc: 0.560 - ETA: 0s - loss: 0.6928 - acc: 0.514 - ETA: 0s - loss: 0.6924 - acc: 0.519 - ETA: 0s - loss: 0.6925 - acc: 0.517 - 0s 58us/step - loss: 0.6925 - acc: 0.5181 - val_loss: 0.6915 - val_acc: 0.5333\n",
      "Epoch 493/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3424/3424 [==============================] - ETA: 0s - loss: 0.6937 - acc: 0.500 - ETA: 0s - loss: 0.6924 - acc: 0.519 - ETA: 0s - loss: 0.6928 - acc: 0.513 - ETA: 0s - loss: 0.6928 - acc: 0.514 - ETA: 0s - loss: 0.6925 - acc: 0.517 - 0s 76us/step - loss: 0.6925 - acc: 0.5181 - val_loss: 0.6914 - val_acc: 0.5333\n",
      "Epoch 494/500\n",
      "3424/3424 [==============================] - ETA: 0s - loss: 0.6874 - acc: 0.590 - ETA: 0s - loss: 0.6936 - acc: 0.503 - ETA: 0s - loss: 0.6924 - acc: 0.519 - ETA: 0s - loss: 0.6928 - acc: 0.514 - ETA: 0s - loss: 0.6926 - acc: 0.516 - 0s 74us/step - loss: 0.6925 - acc: 0.5181 - val_loss: 0.6914 - val_acc: 0.5333\n",
      "Epoch 495/500\n",
      "3424/3424 [==============================] - ETA: 0s - loss: 0.6873 - acc: 0.590 - ETA: 0s - loss: 0.6924 - acc: 0.520 - ETA: 0s - loss: 0.6928 - acc: 0.514 - ETA: 0s - loss: 0.6923 - acc: 0.521 - ETA: 0s - loss: 0.6927 - acc: 0.515 - 0s 85us/step - loss: 0.6925 - acc: 0.5181 - val_loss: 0.6914 - val_acc: 0.5333\n",
      "Epoch 496/500\n",
      "3424/3424 [==============================] - ETA: 0s - loss: 0.6938 - acc: 0.500 - ETA: 0s - loss: 0.6923 - acc: 0.521 - ETA: 0s - loss: 0.6923 - acc: 0.520 - ETA: 0s - loss: 0.6920 - acc: 0.525 - 0s 66us/step - loss: 0.6925 - acc: 0.5181 - val_loss: 0.6914 - val_acc: 0.5333\n",
      "Epoch 497/500\n",
      "3424/3424 [==============================] - ETA: 0s - loss: 0.6938 - acc: 0.500 - ETA: 0s - loss: 0.6938 - acc: 0.500 - ETA: 0s - loss: 0.6930 - acc: 0.511 - ETA: 0s - loss: 0.6926 - acc: 0.517 - 0s 61us/step - loss: 0.6925 - acc: 0.5181 - val_loss: 0.6915 - val_acc: 0.5333\n",
      "Epoch 498/500\n",
      "3424/3424 [==============================] - ETA: 0s - loss: 0.6917 - acc: 0.530 - ETA: 0s - loss: 0.6928 - acc: 0.514 - ETA: 0s - loss: 0.6927 - acc: 0.514 - ETA: 0s - loss: 0.6922 - acc: 0.522 - 0s 59us/step - loss: 0.6925 - acc: 0.5181 - val_loss: 0.6914 - val_acc: 0.5333\n",
      "Epoch 499/500\n",
      "3424/3424 [==============================] - ETA: 0s - loss: 0.6902 - acc: 0.550 - ETA: 0s - loss: 0.6936 - acc: 0.502 - ETA: 0s - loss: 0.6932 - acc: 0.508 - ETA: 0s - loss: 0.6928 - acc: 0.513 - 0s 64us/step - loss: 0.6925 - acc: 0.5181 - val_loss: 0.6914 - val_acc: 0.5333\n",
      "Epoch 500/500\n",
      "3424/3424 [==============================] - ETA: 0s - loss: 0.6952 - acc: 0.480 - ETA: 0s - loss: 0.6937 - acc: 0.501 - ETA: 0s - loss: 0.6927 - acc: 0.515 - ETA: 0s - loss: 0.6926 - acc: 0.516 - ETA: 0s - loss: 0.6930 - acc: 0.511 - 0s 92us/step - loss: 0.6925 - acc: 0.5181 - val_loss: 0.6914 - val_acc: 0.5333\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x1968f206fd0>"
      ]
     },
     "execution_count": 496,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_gender.fit(X_train_input, Y_train_gender, epochs=500, batch_size=100, validation_data=(X_val_input, Y_val_gender))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 495,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Error when checking : expected dense_125_input to have shape (None, 136) but got array with shape (136, 1)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-495-806fdd61d2a2>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mmodel_gender\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0marray\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX_train_input\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\keras\\models.py\u001b[0m in \u001b[0;36mpredict\u001b[1;34m(self, x, batch_size, verbose)\u001b[0m\n\u001b[0;32m   1004\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbuilt\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1005\u001b[0m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbuild\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1006\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mbatch_size\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mverbose\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mverbose\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1007\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1008\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mpredict_on_batch\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mx\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\keras\\engine\\training.py\u001b[0m in \u001b[0;36mpredict\u001b[1;34m(self, x, batch_size, verbose, steps)\u001b[0m\n\u001b[0;32m   1770\u001b[0m         x = _standardize_input_data(x, self._feed_input_names,\n\u001b[0;32m   1771\u001b[0m                                     \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_feed_input_shapes\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1772\u001b[1;33m                                     check_batch_axis=False)\n\u001b[0m\u001b[0;32m   1773\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mstateful\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1774\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mx\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m>\u001b[0m \u001b[0mbatch_size\u001b[0m \u001b[1;32mand\u001b[0m \u001b[0mx\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m%\u001b[0m \u001b[0mbatch_size\u001b[0m \u001b[1;33m!=\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\keras\\engine\\training.py\u001b[0m in \u001b[0;36m_standardize_input_data\u001b[1;34m(data, names, shapes, check_batch_axis, exception_prefix)\u001b[0m\n\u001b[0;32m    151\u001b[0m                             \u001b[1;34m' to have shape '\u001b[0m \u001b[1;33m+\u001b[0m \u001b[0mstr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mshapes\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m+\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    152\u001b[0m                             \u001b[1;34m' but got array with shape '\u001b[0m \u001b[1;33m+\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 153\u001b[1;33m                             str(array.shape))\n\u001b[0m\u001b[0;32m    154\u001b[0m     \u001b[1;32mreturn\u001b[0m \u001b[0marrays\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    155\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mValueError\u001b[0m: Error when checking : expected dense_125_input to have shape (None, 136) but got array with shape (136, 1)"
     ]
    }
   ],
   "source": [
    "model_gender.predict(X_train_input[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 493,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([104, 193, 103, 233, 105, 275, 114, 315, 133, 348, 162, 375, 196,\n",
       "       396, 230, 411, 261, 412, 285, 401, 297, 374, 309, 347, 321, 321,\n",
       "       331, 293, 340, 265, 341, 238, 337, 212, 166, 179, 188, 171, 211,\n",
       "       169, 233, 174, 254, 184, 292, 190, 303, 182, 316, 176, 328, 174,\n",
       "       335, 182, 274, 208, 277, 229, 282, 249, 286, 271, 247, 282, 261,\n",
       "       286, 275, 291, 286, 289, 294, 282, 191, 200, 205, 195, 219, 196,\n",
       "       231, 207, 217, 208, 202, 207, 286, 209, 298, 199, 312, 197, 322,\n",
       "       204, 314, 210, 300, 211, 206, 311, 233, 309, 257, 309, 271, 313,\n",
       "       280, 310, 291, 311, 298, 313, 289, 338, 278, 350, 267, 351, 252,\n",
       "       350, 229, 337, 213, 313, 256, 316, 270, 318, 280, 317, 292, 316,\n",
       "       278, 334, 268, 337, 254, 335])"
      ]
     },
     "execution_count": 493,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train_input[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 269,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "a = [[1,2,3],[2,3,4],[6,7,8]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = np.vstack((a[:1],a[2:]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1, 2, 3],\n",
       "       [6, 7, 8]])"
      ]
     },
     "execution_count": 91,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a"
   ]
=======
   "source": []
>>>>>>> 5be6589eb73edd4cf96d0baea41a7ddc63f0aa24
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
